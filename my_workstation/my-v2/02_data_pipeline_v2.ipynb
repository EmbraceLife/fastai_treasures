{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp data.pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from local.imports import *\n",
    "from local.test import *\n",
    "from local.core import *\n",
    "from local.notebook.showdoc import show_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "torch.cuda.set_device(int(os.environ.get('DEFAULT_GPU') or 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transforms and Pipeline\n",
    "\n",
    "> Low-level transform pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classes here provide functionality for creating *partially reversible functions*, which we call `Transform`s. By \"partially reversible\" we mean that a transform can be `decode`d, creating a form suitable for display. This is not necessarily identical to the original form (e.g. a transform that changes a byte tensor to a float tensor does not recreate a byte tensor when decoded, since that may lose precision, and a float tensor can be displayed already.)\n",
    "\n",
    "Classes are also provided and for composing transforms, and mapping them over collections. The following functionality is provided:\n",
    "\n",
    "- A `Transform` is created with an `encodes` and potentially `decodes` function. \n",
    "- `Pipeline` is a transform which composes transforms\n",
    "- `TfmdList` takes a collection and a transform, and provides an indexer (`__getitem__`) which dynamically applies the transform to the collection items."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convenience functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_func(t, name, *args, **kwargs):\n",
    "    \"Get the `t.name` (potentially partial-ized with `args` and `kwargs`) or `noop` if not defined\"\n",
    "    f = getattr(t, name, noop)\n",
    "    return f if not (args or kwargs) else partial(f, *args, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This works for any kind of `t` supporting `getattr`, so a class or a module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(get_func(operator, 'neg', 2)(), -2)\n",
    "test_eq(get_func(operator.neg, '__call__')(2), -2)\n",
    "test_eq(get_func(list, 'foobar')([2]), [2])\n",
    "t = get_func(torch, 'zeros', dtype=torch.int64)(5)\n",
    "test_eq(t.dtype, torch.int64)\n",
    "a = [2,1]\n",
    "get_func(list, 'sort')(a)\n",
    "test_eq(a, [1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def show_title(o, ax=None, ctx=None):\n",
    "    \"Set title of `ax` to `o`, or print `o` if `ax` is `None`\"\n",
    "    ax = ifnone(ax,ctx)\n",
    "    if ax is None: print(o)\n",
    "    else: ax.set_title(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_stdout(lambda: show_title(\"title\"), \"title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Func -"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tranforms, data augmentation in particular, are built in fastai around patching some types. For instance a `TensorImage` object isn't flipped the same way as a `TensorPoints` or a `TensorBBox` object, so we will want to access the `flip` attribute of each of those classes. The following class allows us to create a generic object associated to that `flip` name that will then look for this attribute in the type (or list of types) we feed it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Func():\n",
    "    \"Basic wrapper around a `name` with `args` and `kwargs` to call on a given type\"\n",
    "    def __init__(self, name, *args, **kwargs): self.name,self.args,self.kwargs = name,args,kwargs\n",
    "    def __repr__(self): return f'sig: {self.name}({self.args}, {self.kwargs})'\n",
    "    def _get(self, t): return get_func(t, self.name, *self.args, **self.kwargs)\n",
    "    def __call__(self,t): return L(t).mapped(self._get) if is_listy(t) else self._get(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can call the `Func` object on any module name or type, even a list of types. It will return the corresponding function (with a default to `noop` if nothing is found) or list of functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(Func('sqrt')(math), math.sqrt)\n",
    "test_eq(Func('sqrt')(torch), torch.sqrt)\n",
    "\n",
    "@patch\n",
    "def powx(x:math, a): return math.pow(x,a)\n",
    "@patch\n",
    "def powx(x:torch, a): return torch.pow(x,a)\n",
    "tst = Func('powx',a=2)([math, torch])\n",
    "test_eq([f.func for f in tst], [math.powx, torch.powx])\n",
    "for t in tst: test_eq(t.keywords, {'a': 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class _Sig():\n",
    "    def __getattr__(self,k):\n",
    "        def _inner(*args, **kwargs): return Func(k, *args, **kwargs)\n",
    "        return _inner\n",
    "\n",
    "Sig = _Sig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"<code>Sig</code>\" class=\"doc_header\"><code>Sig</code><a href=\"https://github.com/fastai/fastai_docs/tree/master/dev/__main__.py#L4\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>Sig</code>(**\\*`args`**, **\\*\\*`kwargs`**)\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Sig, name=\"Sig\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Sig` is just sugar-syntax to create a `Func` object more easily with the syntax `Sig.name(*args, **kwargs)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = Sig.sqrt()\n",
    "test_eq(f(math), math.sqrt)\n",
    "test_eq(f(torch), torch.sqrt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class SelfFunc():\n",
    "    \"Search for `name` attribute and call it with `args` and `kwargs` on any object it's passed.\"\n",
    "    def __init__(self, nm, *args, **kwargs): self.nm,self.args,self.kwargs = nm,args,kwargs\n",
    "    def __repr__(self): return f'self: {self.nm}({self.args}, {self.kwargs})'\n",
    "    def __call__(self, o):\n",
    "        if not is_listy(o): return getattr(o,self.nm)(*self.args, **self.kwargs)\n",
    "        else: return [getattr(o_,self.nm)(*self.args, **self.kwargs) for o_ in o]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The difference between `Func` and `SelfFunc` is that `Func` will generate a function when you call it on a type. On the other hand, `SelfFunc` is already a function and each time you call it on an object it looks for the `name` attribute and call it on `args` and `kwargs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst = SelfFunc('sqrt')\n",
    "x = torch.tensor([4.])\n",
    "test_eq(tst(x), torch.tensor([2.]))\n",
    "assert isinstance(tst(x), Tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class _SelfFunc():\n",
    "    def __getattr__(self,k):\n",
    "        def _inner(*args, **kwargs): return SelfFunc(k, *args, **kwargs)\n",
    "        return _inner\n",
    "    \n",
    "Self = _SelfFunc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"<code>Self</code>\" class=\"doc_header\"><code>Self</code><a href=\"https://github.com/fastai/fastai_docs/tree/master/dev/__main__.py#L4\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>Self</code>(**\\*`args`**, **\\*\\*`kwargs`**)\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Self, name=\"Self\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Self` is just syntax sugar to create a `SelfFunc` object more easily with the syntax `Self.name(*args, **kwargs)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = Self.sqrt()\n",
    "x = torch.tensor([4.])\n",
    "test_eq(f(x), torch.tensor([2.]))\n",
    "assert isinstance(f(x), Tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def positional_annotations(f):\n",
    "    \"Get list of annotated types for all positional params, or None if no annotation\"\n",
    "    sig = inspect.signature(f)\n",
    "    return [p.annotation if p.annotation != inspect._empty else None \n",
    "            for p in sig.parameters.values() if p.default == inspect._empty and p.kind != inspect._VAR_KEYWORD]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multimethod import multimeta,DispatchError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Transform(metaclass=multimeta):\n",
    "    order,filt,t = 0,None,None\n",
    "    def __init__(self,encodes=None,decodes=None):\n",
    "        self.encodes = getattr(self, 'encodes', noop) if encodes is None else encodes \n",
    "        self.decodes = getattr(self, 'decodes', noop) if decodes is None else decodes\n",
    "    \n",
    "    def _apply(self, fs, x, filt):\n",
    "        if self.filt is not None and self.filt!=filt: return x\n",
    "        if self.t: \n",
    "            gs = self._get_func(fs, self.t)\n",
    "            if is_listy(self.t) and len(positional_annotations(gs)) != len(self.t):\n",
    "                gs = [self._get_func(fs,t_) for t_ in self.t]\n",
    "                if len(gs) == 1: gs = gs[0]\n",
    "        else: gs=fs\n",
    "        if is_listy(gs): return tuple(f(x_) for f,x_ in zip(gs,x))\n",
    "        return gs(*L(x))\n",
    "\n",
    "    def _get_func(self,f,t):\n",
    "        idx = (object,) + tuple(t) if is_listy(t) else (object,t)\n",
    "        try: f = f.__func__[idx]\n",
    "        except DispatchError: return noop\n",
    "        return partial(f,self)\n",
    "    \n",
    "    def accept_types(self, t):\n",
    "        # We can't create encodes/decodes here since patching might change things later\n",
    "        # So we call _get_func in _apply instead\n",
    "        self.t = t\n",
    "\n",
    "    def __call__(self, x, filt=None): return self._apply(self.encodes, x, filt)\n",
    "    def decode  (self, x, filt=None): return self._apply(self.decodes, x, filt)\n",
    "    def __getitem__(self, x): return self(x) # So it can be used as a `Dataset`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class TransformOld(PrePostInit):\n",
    "    \"A function that `encodes` if `filt` matches, and optionally `decodes`\"\n",
    "    order,filt = 0,None\n",
    "    def __init__(self,encodes=None,decodes=None):\n",
    "        self.encodes = getattr(self, 'encodes', noop) if encodes is None else encodes \n",
    "        self.decodes = getattr(self, 'decodes', noop) if decodes is None else decodes \n",
    "    \n",
    "    def _apply(self, fs, x, filt):\n",
    "        if self.filt is not None and self.filt!=filt: return x\n",
    "        if is_listy(fs): return tuple(f(x_) for f,x_ in zip(fs,x))\n",
    "        return fs(*L(x))\n",
    "    \n",
    "    def __call__(self, x, filt=None): return self._apply(self.encodes, x, filt)\n",
    "    def decode  (self, x, filt=None): return self._apply(self.decodes, x, filt)\n",
    "    def __getitem__(self, x): return self(x) # So it can be used as a `Dataset`\n",
    "\n",
    "    def _filter_with_type(self, t):\n",
    "        if is_listy(t): self.encodes = _filter_with_type(self.encodes, t)\n",
    "        if is_listy(t): self.decodes = _filter_with_type(self.decodes, t)\n",
    "            \n",
    "add_docs(TransformOld,\n",
    "         __call__=\"Call `self.encodes` unless `filt` is passed and it doesn't match `self.filt`\",\n",
    "         decode  =\"Call `self.decodes` unless `filt` is passed and it doesn't match `self.filt`\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a transformation pipeline some steps need to be reversible - for instance, if you turn a string (such as *dog*) into an int (such as *1*) for modeling, then for display purposes you'll want to turn it back to a string again (e.g. when you have a prediction). In addition, you may wish to only run the transformation for a particular data subset, such as the training set.\n",
    "\n",
    "`Transform` provides all this functionality. `filt` is some dataset index (e.g. provided by `DataSource`), and you provide `encodes` and optional `decodes` functions for your code. You can pass `encodes` and `decodes` functions directly to the constructor for quickly creating simple transforms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfm = Transform(operator.neg, decodes=operator.neg)\n",
    "start = 4\n",
    "t = tfm(start)\n",
    "test_eq(t, -4)\n",
    "test_eq(t, tfm[start]) #You can use a transform as a dataset\n",
    "test_eq(tfm.decode(t), start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _AddOne(Transform):\n",
    "    filt=1\n",
    "    def encodes(self, x): return x+1\n",
    "    def decodes(self, x): return x-1\n",
    "\n",
    "addt = _AddOne()\n",
    "test_eq(addt(start,filt=1), 5)\n",
    "test_eq(addt(start,filt=0), start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At some point in the data-collection pipeline, your objects will be tuples (usually input,label). There are then different behaviors you might want your `Transform` to adopt such as:\n",
    "- being applied to the tuple and returning a new tuple\n",
    "- being applied to each part of the tuple\n",
    "- being applied to some parts of the tuple but not all\n",
    "\n",
    "You can control which behavior will be used with the signature of your `encodes` function. If it accepts several arguments (without defaults), then the transform will be applied on the tuple and expected to return a tuple. If your `encodes` function only accepts one argument, it will be applied on every part of the tuple. You can even control which part of the tuples with a type annotation: the tranform will only be applied to the items in the tuple that correspond to that type.\n",
    "\n",
    "All of this is enabled the private method `_filter_with_type` that is called in the setup of a `Pipeline` (so out of the blue your transform object won't have this behavior). The `Pipeline` will analyze the type of objects (as given by the return annotation of any transform) and pass them along, wich tells the transform it will receive a given type (or a tuple of given types)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply on the tuple as a whole\n",
    "class _Add(Transform):\n",
    "    def encodes(self, x, y): return (x+y,y)\n",
    "    def decodes(self, x, y): return (x-y,y)\n",
    "\n",
    "addt = _Add()\n",
    "addt.accept_types([float,float])\n",
    "t = addt([1,2])\n",
    "test_eq(t, (3,2))\n",
    "test_eq(addt.decode(t), (1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply on all part of the tuple\n",
    "class _AddOne(Transform):\n",
    "    def encodes(self, x): return x+1\n",
    "    def decodes(self, x): return x-1\n",
    "\n",
    "addt = _AddOne()\n",
    "addt.accept_types([float,float])\n",
    "t = addt([1,2])\n",
    "test_eq(t, (2,3))\n",
    "test_eq(addt.decode(t), (1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply on all integers of the tuple\n",
    "#Also note that your tuples can have more than two elements\n",
    "class _AddOne(Transform):\n",
    "    def encodes(self, x:numbers.Integral): return x+1\n",
    "    def encodes(self, x:float): return x*2\n",
    "    def decodes(self, x:numbers.Integral): return x-1\n",
    "\n",
    "addt = _AddOne()\n",
    "addt.accept_types([float, int, float])\n",
    "start = [1,2,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(cls):\n",
    "    def _inner(f):\n",
    "        if   f.__name__=='encodes': cls.encodes.register(f)\n",
    "        elif f.__name__=='decodes': cls.decodes.register(f)\n",
    "        else: raise Exception('Function must be \"encodes\" or \"decodes\"')\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "@transform(_AddOne)\n",
    "def decodes(self, x:float): return x/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = addt(start)\n",
    "test_eq(t, (2,3,6))\n",
    "test_eq(addt.decode(t), start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def compose_tfms(x, tfms, func_nm='__call__', reverse=False, **kwargs):\n",
    "    \"Apply all `func_nm` attribute of `tfms` on `x`, naybe in `reverse` order\"\n",
    "    if reverse: tfms = reversed(tfms)\n",
    "    for tfm in tfms: x = getattr(tfm,func_nm,noop)(x, **kwargs)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _AddOne(Transform):\n",
    "    def encodes(self, x): return x+1\n",
    "    def decodes(self, x): return x-1\n",
    "    \n",
    "tfms = [_AddOne(), Transform(torch.sqrt)]\n",
    "t = compose_tfms(tensor([3.]), tfms)\n",
    "test_eq(t, tensor([2.]))\n",
    "test_eq(compose_tfms(t, tfms, 'decodes'), tensor([1.]))\n",
    "test_eq(compose_tfms(tensor([4.]), tfms, reverse=True), tensor([3.]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _get_ret(func):\n",
    "    \"Get the return annotation of `func`\"\n",
    "    ann = getattr(func,'__annotations__', None)\n",
    "    if not ann: return None\n",
    "    return ann.get('return')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Pipeline():\n",
    "    \"A pipeline of composed (for encode/decode) transforms, setup with types\"\n",
    "    def __init__(self, funcs=None, t=None): \n",
    "        self.raws,self.fs,self.t_show = L(funcs),[],None\n",
    "        if len(self.raws) == 0: self.final_t = t\n",
    "        else:\n",
    "            for i,f in enumerate(self.raws.sorted(key='order')):\n",
    "                if not isinstance(f,Transform): f = Transform(f)\n",
    "                f.accept_types(t)\n",
    "                self.fs.append(f)\n",
    "                if hasattr(t, 'show') and self.t_show is None:\n",
    "                    self.t_idx,self.t_show = i,t\n",
    "                t = _get_ret(f.encodes) or t\n",
    "            if hasattr(t, 'show') and self.t_show is None:\n",
    "                self.t_idx,self.t_show = i+1,t\n",
    "            self.final_t = t\n",
    "    \n",
    "    def new(self, t=None): return Pipeline(self.raws, t)\n",
    "    def __repr__(self): return f\"Pipeline over {self.fs}\"\n",
    "    \n",
    "    def setup(self, items=None):\n",
    "        assert hasattr(self, 'fs'), \"Call `setup_types` before `setup`\"\n",
    "        tfms,self.fs = self.fs,[]\n",
    "        for t in tfms:\n",
    "            self.fs.append(t)\n",
    "            if hasattr(t, 'setup'): t.setup(items)\n",
    "                \n",
    "    def __call__(self, o, **kwargs): return compose_tfms(o, self.fs)\n",
    "    def decode  (self, i, **kwargs): return compose_tfms(i, self.fs, func_nm='decode', reverse=True)\n",
    "    \n",
    "    def show(self, o, ctx=None, **kwargs):\n",
    "        if self.t_show is None: return self.decode(o)\n",
    "        o = compose_tfms(o, self.fs[self.t_idx:], func_nm='decode', reverse=True)\n",
    "        return self.t_show.show(o, ctx=ctx, **kwargs)\n",
    "    #def __getitem__(self, x): return self(x)\n",
    "    #def decode_at(self, idx): return self.decode(self[idx])\n",
    "    #def show_at(self, idx): return self.show(self[idx])\n",
    "\n",
    "add_docs(Pipeline,\n",
    "         __call__=\"Compose `__call__` of all `tfms` on `o`\",\n",
    "         decode=\"Compose `decode` of all `tfms` on `i`\",\n",
    "         new=\"Create a new `Pipeline`with the same `tfms` and a new initial `t`\",\n",
    "         show=\"Show item `o`\",\n",
    "         setup=\"Go through the transforms in order and call their potential setup on `items`\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A list of transforms are often applied in a particular order, and decoded by applying in the reverse order. `Pipeline` provides this functionality, and also ensures during `setup` that each transform get the proper functions according to the type of the previous transform. If any transform provides a type with a return annotation, this type is passed along to the next tranforms (until being overwritten by a new return annotation). Such a type can be useful when transforms filter depending on a given type (usually for data augmentation) or to provide a show method.\n",
    "\n",
    "> Warning: `setup` must be run before encoding/decoding.\n",
    "\n",
    "Here's some simple examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empty pipeline is noop\n",
    "pipe = Pipeline()\n",
    "test_eq(pipe(1), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check a standard pipeline\n",
    "class String():\n",
    "    @staticmethod\n",
    "    def show(o, ctx=None, **kwargs): return show_title(str(o), ctx=ctx)\n",
    "    \n",
    "class floatTfm(Transform):\n",
    "    def encodes(self, x): return float(x)\n",
    "    def decodes(self, x): return int(x)\n",
    "\n",
    "float_tfm=floatTfm()\n",
    "def neg(x) -> String: return -x\n",
    "neg_tfm = Transform(neg, neg)\n",
    "    \n",
    "pipe = Pipeline([neg_tfm, float_tfm])\n",
    "\n",
    "start = 2\n",
    "t = pipe(2)\n",
    "test_eq(t, -2.0)\n",
    "test_eq(type(t), float)\n",
    "#test_eq(t, pipe[2])\n",
    "test_eq(pipe.decode(t), start)\n",
    "#show decodes up to the point of the first transform that introduced the type that shows, not included\n",
    "test_stdout(lambda:pipe.show(t), '-2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check opposite order\n",
    "pipe = Pipeline([float_tfm,neg_tfm])\n",
    "t = pipe(2)\n",
    "test_eq(t, -2.0)\n",
    "# `show` comes from String on the last transform so nothing is decoded\n",
    "test_stdout(lambda:pipe.show(t), '-2.0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"<code>Pipeline.__call__</code>\" class=\"doc_header\"><code>Pipeline.__call__</code><a href=\"https://nbviewer.jupyter.org/github/fastai/fastai_docs/blob/master/dev/02_data_pipeline_v2.ipynb#Pipeline--\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>Pipeline.__call__</code>(**`o`**, **\\*\\*`kwargs`**)\n",
       "\n",
       "Compose `__call__` of all `tfms` on `o`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Pipeline.__call__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"<code>Pipeline.decode</code>\" class=\"doc_header\"><code>Pipeline.decode</code><a href=\"https://nbviewer.jupyter.org/github/fastai/fastai_docs/blob/master/dev/02_data_pipeline_v2.ipynb#Pipeline--\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>Pipeline.decode</code>(**`i`**, **\\*\\*`kwargs`**)\n",
       "\n",
       "Compose `decode` of all `tfms` on `i`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Pipeline.decode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"<code>Pipeline.new</code>\" class=\"doc_header\"><code>Pipeline.new</code><a href=\"https://nbviewer.jupyter.org/github/fastai/fastai_docs/blob/master/dev/02_data_pipeline_v2.ipynb#Pipeline--\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>Pipeline.new</code>(**`t`**=*`None`*)\n",
       "\n",
       "Create a new [`Pipeline`](/data.pipeline.v2.html#Pipeline)with the same `tfms` and a new initial `t`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Pipeline.new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"<code>Pipeline.setup</code>\" class=\"doc_header\"><code>Pipeline.setup</code><a href=\"https://nbviewer.jupyter.org/github/fastai/fastai_docs/blob/master/dev/02_data_pipeline_v2.ipynb#Pipeline--\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>Pipeline.setup</code>(**`items`**=*`None`*)\n",
       "\n",
       "Go through the transforms in order and call their potential setup on `items`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Pipeline.setup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PipedList -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "@docs\n",
    "class PipedList(GetAttr):\n",
    "    \"A transform applied to a collection of `items`\"\n",
    "    _xtra = 'decode __call__ show'.split()\n",
    "    \n",
    "    def __init__(self, items, pipe, do_setup=True):\n",
    "        self.items = L(items)\n",
    "        self.default = self.pipe = pipe\n",
    "        if do_setup: self.setup()\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        \"Transformed item(s) at `i`\"\n",
    "        its = self.items[i]\n",
    "        return its.mapped(self.pipe) if is_iter(i) else self.pipe(its)\n",
    "\n",
    "    def setup(self): self.pipe.setup(self)\n",
    "    def subset(self, idxs): return self.__class__(self.items[idxs], self.pipe, do_setup=False)\n",
    "    def decode_at(self, idx): return self.decode(self[idx])\n",
    "    def show_at(self, idx): return self.show(self[idx])\n",
    "    def __eq__(self, b): return all_equal(self, b)\n",
    "    def __len__(self): return len(self.items)\n",
    "    def __iter__(self): return (self[i] for i in range_of(self))\n",
    "    def __repr__(self): return f\"{self.__class__.__name__}: {self.items}\\ntfms - {self.pipe}\"\n",
    "    \n",
    "    _docs = dict(setup=\"Transform setup with self\",\n",
    "                 decode_at=\"Decoded item at `idx`\",\n",
    "                 show_at=\"Show item at `idx`\",\n",
    "                 subset=\"New `TfmdList` that only includes items at `idxs`\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PipedList: (#3) [1,2,3]\n",
       "tfms - Pipeline over [<__main__.Transform object at 0x7f5fe639e5c0>, <__main__.floatTfm object at 0x7f5fe639e5f8>]"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline([neg_tfm, float_tfm])\n",
    "\n",
    "tl = PipedList([1,2,3], pipe)\n",
    "t = tl[1]\n",
    "test_eq(t, -2.0)\n",
    "test_eq(type(t), float)\n",
    "test_eq(tl.decode_at(1), 2)\n",
    "test_eq(tl.decode(t), 2)\n",
    "test_stdout(lambda: tl.show_at(2), '-3')\n",
    "tl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "p2 = tl.subset([0,2])\n",
    "test_eq(p2, [-1.,-3.])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's how we can use `TfmdList.setup` to implement a simple category list, getting labels from a mock file list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PipedList: (#5) [dog_0.jpg,cat_0.jpg,cat_2.jpg,cat_1.jpg,dog_1.jpg]\n",
       "tfms - Pipeline over [<__main__.Transform object at 0x7f5fed443be0>, <__main__._Cat object at 0x7f5fed4438d0>]"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class _Cat(Transform):\n",
    "    order = 1\n",
    "    def encodes(self, o): return self.o2i[o] if hasattr(self, 'o2i') else o\n",
    "    def decodes(self, o): return self.vocab[o]\n",
    "    def setup(self, items): self.vocab,self.o2i = uniqueify(items, sort=True, bidir=True)\n",
    "\n",
    "def _lbl(o) -> String: return o.split('_')[0]\n",
    "\n",
    "test_fns = ['dog_0.jpg','cat_0.jpg','cat_2.jpg','cat_1.jpg','dog_1.jpg']\n",
    "tcat = _Cat()\n",
    "pipe = Pipeline([tcat,_lbl])\n",
    "tl = PipedList(test_fns, pipe)\n",
    "\n",
    "test_eq(tcat.vocab, ['cat','dog'])\n",
    "test_eq([1,0,0,0,1], tl)\n",
    "test_eq(1, tl[-1])\n",
    "test_eq([1,0], tl[0,1])\n",
    "t = list(tl)\n",
    "test_eq([1,0,0,0,1], t)\n",
    "test_eq(['dog','cat','cat','cat','dog'], map(tl.decode,t))\n",
    "test_stdout(lambda:tl.show_at(0), \"dog\")\n",
    "tl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"<code>PipedList.__getitem__</code>\" class=\"doc_header\"><code>PipedList.__getitem__</code><a href=\"https://github.com/fastai/fastai_docs/tree/master/dev/__main__.py#L11\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>PipedList.__getitem__</code>(**`i`**)\n",
       "\n",
       "Transformed item(s) at `i`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(PipedList.__getitem__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cat'"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tl.decode(tl[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(tl.decode_at(1),'cat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"<code>TfmdList.show_at</code>\" class=\"doc_header\"><code>TfmdList.show_at</code><a href=\"https://nbviewer.jupyter.org/github/fastai/fastai_docs/blob/master/dev/02_data_pipeline.ipynb#TfmdList--\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>TfmdList.show_at</code>(**`idx`**)\n",
       "\n",
       "Show item at `idx`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(TfmdList.show_at)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat\n"
     ]
    }
   ],
   "source": [
    "tl.show_at(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TfmOver -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class TfmOver(Transform):\n",
    "    \"Create tuple containing each of `tfms` applied to each of `o`\"\n",
    "    def __init__(self, tfms=None):\n",
    "        if tfms is None: tfms = [None]\n",
    "        self.activ,self.tfms = None,L(tfms).mapped(Pipeline)\n",
    "\n",
    "    def __call__(self, o, *args, **kwargs):\n",
    "        \"List of output of each of `tfms` on `o`\"\n",
    "        if self.activ is not None: return self.tfms[self.activ](o[self.activ], *args, **kwargs)\n",
    "        return [t(p, *args, **kwargs) for p,t in zip(o,self.tfms)]\n",
    "    \n",
    "    def show(self, o, ctx=None, **kwargs):\n",
    "        \"Show result of `show` from each of `tfms`\"\n",
    "        for p,t in zip(o,self.tfms): ctx = t.show(p, ctx=ctx, **kwargs)\n",
    "        return ctx\n",
    "\n",
    "    def decode(self, o, **kwargs): return [t.decode(p, **kwargs) for p,t in zip(o,self.tfms)]\n",
    "    def __repr__(self): return f'TfmOver({self.tfms})'\n",
    "\n",
    "    def setups(self, o=None):\n",
    "        \"Setup each of `tfms` independently\"\n",
    "        for i,tfm in enumerate(self.tfms):\n",
    "            self.activ = i\n",
    "            tfm.setup(o)\n",
    "        self.activ=None\n",
    "    \n",
    "    @property\n",
    "    def assoc(self): return self.tfms.attrgot('assoc')\n",
    "    \n",
    "    @classmethod\n",
    "    def piped(cls, tfms=None, final_tfms=None):\n",
    "        \"`Pipeline` that duplicates input, then maps `TfmOver` over `tfms`, optionally followed by any `final_tfms`\"\n",
    "        tfms = L(ifnone(tfms,[None]))\n",
    "        init_tfm = partial(replicate,match=tfms)\n",
    "        return Pipeline([init_tfm,cls(tfms)] + _set_tupled(final_tfms))\n",
    "\n",
    "    xt,yt = add_props(lambda i,x:x.tfms[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _TNorm(Transform):\n",
    "    assoc=Item\n",
    "    def __init__(self): self.m,self.s = 0,1\n",
    "    def encodes(self, o): return (o-self.m)/self.s\n",
    "    def decodes(self, o): return (o*self.s)+self.m\n",
    "    def setup(self, items):\n",
    "        its = tensor(items)\n",
    "        self.m,self.s = its.mean(),its.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = [1,2,3,4]\n",
    "tl = TfmdList(items, TfmOver.piped([negtfm(), [negtfm(),_TNorm()]]))\n",
    "x,y = zip(*tl)\n",
    "test_close(tensor(y).mean(), 0)\n",
    "test_close(tensor(y).std(), 1)\n",
    "test_eq(x, [-1,-2,-3,-4])\n",
    "test_stdout(lambda:tl.show_at(1), 'tensor(-2.)')\n",
    "test_eq(tl.tfm.assoc, [None,Item])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b  [(-1, -2, -3, -4), (tensor(1.1619), tensor(0.3873), tensor(-0.3873), tensor(-1.1619))]\n",
      "bd (#2) [(#4) [1,2,3,4],(#4) [tensor(1.),tensor(2.),tensor(3.),tensor(4.)]]\n"
     ]
    }
   ],
   "source": [
    "# Create a \"batch\"\n",
    "b = list(zip(*tl))\n",
    "bd = tl.decode_batch(b)\n",
    "\n",
    "test_eq(len(bd),2)\n",
    "test_eq(bd[0],items)\n",
    "test_eq(bd[1],items)\n",
    "test_eq(type(bd[1][0]),Tensor)\n",
    "print('b ',b)\n",
    "print('bd',bd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empty tuplify\n",
    "tp = TfmOver()\n",
    "tp.setup()\n",
    "test_eq(tp([1]), [1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_test.ipynb.\n",
      "Converted 01_core.ipynb.\n",
      "Converted 02_data_pipeline.ipynb.\n",
      "Converted 02_data_pipeline_v2.ipynb.\n",
      "Converted 03_data_external.ipynb.\n",
      "Converted 04_data_core.ipynb.\n",
      "Converted 05_data_source.ipynb.\n",
      "Converted 06_vision_core.ipynb.\n",
      "Converted 07_pets_tutorial-meta.ipynb.\n",
      "Converted 07_pets_tutorial-oo.ipynb.\n",
      "Converted 07_pets_tutorial-oo1.ipynb.\n",
      "Converted 07_pets_tutorial-oo2-meta.ipynb.\n",
      "Converted 07_pets_tutorial.ipynb.\n",
      "Converted 08_augmentation.ipynb.\n",
      "Converted 10_layers.ipynb.\n",
      "Converted 11_optimizer.ipynb.\n",
      "Converted 12_learner.ipynb.\n",
      "Converted 13_callback_schedule.ipynb.\n",
      "Converted 14_callback_hook.ipynb.\n",
      "Converted 15_callback_progress.ipynb.\n",
      "Converted 16_callback_tracker.ipynb.\n",
      "Converted 17_callback_fp16.ipynb.\n",
      "Converted 90_notebook_core.ipynb.\n",
      "Converted 91_notebook_export.ipynb.\n",
      "Converted 92_notebook_showdoc.ipynb.\n",
      "Converted 93_notebook_export2html.ipynb.\n",
      "Converted 94_index.ipynb.\n",
      "Converted 95_synth_learner.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from local.notebook.export import notebook2script\n",
    "notebook2script(all_fs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
