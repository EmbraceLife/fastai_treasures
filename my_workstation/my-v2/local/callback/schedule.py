#AUTOGENERATED! DO NOT EDIT! File to edit: dev/13_callback_schedule.ipynb (unless otherwise specified).

__all__ = ['annealer', 'sched_lin', 'sched_cos', 'sched_no', 'sched_exp', 'combine_scheds']

from ..imports import *
from ..test import *
from ..core import *
from ..layers import *
from ..data.pipeline import *
from ..data.source import *
from ..data.core import *
from ..data.external import *
from ..notebook.showdoc import show_doc
from ..optimizer import *
from ..learner import *

def annealer(f):
    "Decorator to make `f` return itself partially applied."
    def _inner(start, end): return partial(f, start, end)
    return _inner

@annealer
def sched_lin(start, end, pos): return start + pos*(end-start)
@annealer
def sched_cos(start, end, pos): return start + (1 + math.cos(math.pi*(1-pos))) * (end-start) / 2
@annealer
def sched_no (start, end, pos): return start
@annealer
def sched_exp(start, end, pos): return start * (end/start) ** pos

sched_lin.__doc__ = "Linear schedule function from `start` to `end`"
sched_cos.__doc__ = "Cosine schedule function from `start` to `end`"
sched_no .__doc__ = "Constant schedule function with `start` value"
sched_exp.__doc__ = "Exponential schedule function from `start` to `end`"

def combine_scheds(pcts, scheds):
    "Combine `scheds` according to `pcts` in one function"
    assert sum(pcts) == 1.
    pcts = tensor([0] + L(pcts))
    assert torch.all(pcts >= 0)
    pcts = torch.cumsum(pcts, 0)
    def _inner(pos):
        if pos == 1.: return scheds[-1](1.)
        idx = (pos >= pcts).nonzero().max()
        actual_pos = (pos-pcts[idx]) / (pcts[idx+1]-pcts[idx])
        return scheds[idx](actual_pos)
    return _inner