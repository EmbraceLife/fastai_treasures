{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp data.core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from local.imports import *\n",
    "from local.test import *\n",
    "from local.core import *\n",
    "from local.data.transform import *\n",
    "from local.data.pipeline import *\n",
    "from local.data.external import *\n",
    "from local.notebook.showdoc import show_doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions for processing data\n",
    "\n",
    "> Functions for getting, splitting, and labeling data, etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get, split, and label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For most data source creation we need functions to get a list of items, split them in to train/valid sets, and label them. fastai provides functions to make each of these steps easy (especially when combined with `fastai.data.blocks`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we'll look at functions that *get* a list of items (generally file names).\n",
    "\n",
    "We'll use *tiny MNIST* (a subset of MNIST with just two classes, `7`s and `3`s) for our examples/tests throughout this page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/home/jhoward/git/fastai_docs/dev/data/mnist_tiny/train/3'),\n",
       " PosixPath('/home/jhoward/git/fastai_docs/dev/data/mnist_tiny/train/7')]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = untar_data(URLs.MNIST_TINY)\n",
    "(path/'train').ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def _get_files(p, fs, extensions=None):\n",
    "    p = Path(p)\n",
    "    res = [p/f for f in fs if not f.startswith('.')\n",
    "           and ((not extensions) or f'.{f.split(\".\")[-1].lower()}' in extensions)]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def get_files(path, extensions=None, recurse=True, include=None):\n",
    "    \"Get all the files in `path` with optional `extensions`, optionally with `recurse`.\"\n",
    "    path = Path(path)\n",
    "    extensions = setify(extensions)\n",
    "    extensions = {e.lower() for e in extensions}\n",
    "    if recurse:\n",
    "        res = []\n",
    "        for i,(p,d,f) in enumerate(os.walk(path)): # returns (dirpath, dirnames, filenames)\n",
    "            if include is not None and i==0: d[:] = [o for o in d if o in include]\n",
    "            else:                            d[:] = [o for o in d if not o.startswith('.')]\n",
    "            res += _get_files(p, f, extensions)\n",
    "    else:\n",
    "        f = [o.name for o in os.scandir(path) if o.is_file()]\n",
    "        res = _get_files(path, f, extensions)\n",
    "    return L(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the most general way to grab a bunch of file names from disk. If you pass `extensions` (including the `.`) then returned file names are filtered by that list. Only those files directly in `path` are included, unless you pass `recurse`, in which case all child folders are also searched recursively. `include` is an optional list of directories to limit the search to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#709) [/home/jhoward/git/fastai_docs/dev/data/mnist_tiny/train/3/8055.png,/home/jhoward/git/fastai_docs/dev/data/mnist_tiny/train/3/9466.png,/home/jhoward/git/fastai_docs/dev/data/mnist_tiny/train/3/7778.png,/home/jhoward/git/fastai_docs/dev/data/mnist_tiny/train/3/8824.png,/home/jhoward/git/fastai_docs/dev/data/mnist_tiny/train/3/8228.png,/home/jhoward/git/fastai_docs/dev/data/mnist_tiny/train/3/9620.png,/home/jhoward/git/fastai_docs/dev/data/mnist_tiny/train/3/8790.png,/home/jhoward/git/fastai_docs/dev/data/mnist_tiny/train/3/7497.png,/home/jhoward/git/fastai_docs/dev/data/mnist_tiny/train/3/7383.png,/home/jhoward/git/fastai_docs/dev/data/mnist_tiny/train/3/9324.png...]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t3 = get_files(path/'train'/'3', extensions='.png', recurse=False)\n",
    "t7 = get_files(path/'train'/'7', extensions='.png', recurse=False)\n",
    "t  = get_files(path/'train', extensions='.png', recurse=True)\n",
    "test_eq(len(t), len(t3)+len(t7))\n",
    "test_eq(len(get_files(path/'train'/'3', extensions='.jpg', recurse=False)),0)\n",
    "test_eq(len(t), len(get_files(path, extensions='.png', recurse=True, include='train')))\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "test_eq(len(get_files(path/'train'/'3', recurse=False)),346)\n",
    "test_eq(len(get_files(path, extensions='.png', recurse=True, include=['train', 'test'])),729)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's often useful to be able to create functions with customized behavior. `fastai.data` generally uses functions named as CamelCase verbs ending in `er` to create these functions. `FileGetter` is a simple example of such a function creator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def FileGetter(suf='', extensions=None, recurse=True, include=None):\n",
    "    \"Create `get_files` partial function that searches path suffix `suf` and passes along args\"\n",
    "    def _inner(o, extensions=extensions, recurse=recurse, include=include): return get_files(o/suf, extensions, recurse, include)\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpng = FileGetter(extensions='.png', recurse=False)\n",
    "test_eq(len(t7), len(fpng(path/'train'/'7')))\n",
    "test_eq(len(t), len(fpng(path/'train', recurse=True)))\n",
    "fpng_r = FileGetter(extensions='.png', recurse=True)\n",
    "test_eq(len(t), len(fpng_r(path/'train')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "image_extensions = set(k for k,v in mimetypes.types_map.items() if v.startswith('image/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_image_files(path, recurse=True, include=None):\n",
    "    \"Get image files in `path` recursively.\"\n",
    "    return get_files(path, extensions=image_extensions, recurse=recurse, include=include)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is simply `get_files` called with a list of standard image extensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(len(t), len(get_image_files(path, recurse=True, include='train')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def ImageGetter(suf='', recurse=True, include=None):\n",
    "    \"Create `get_image_files` partial function that searches path suffix `suf` and passes along `kwargs`\"\n",
    "    def _inner(o, recurse=recurse, include=include): return get_image_files(o/suf, recurse, include)\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same as `FileGetter`, but for image extensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(len(get_files(path/'train', extensions='.png', recurse=True, include='3')),\n",
    "        len(ImageGetter(   'train',                    recurse=True, include='3')(path)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next set of functions are used to *split* data into training and validation sets. The functions return two lists - a list of indices or masks for each of training and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def RandomSplitter(valid_pct=0.2, seed=None, **kwargs):\n",
    "    \"Create function that splits `items` between train/val with `valid_pct` randomly.\"\n",
    "    def _inner(o, **kwargs):\n",
    "        if seed is not None: torch.manual_seed(seed)\n",
    "        rand_idx = L(int(i) for i in torch.randperm(len(o)))\n",
    "        cut = int(valid_pct * len(o))\n",
    "        return rand_idx[cut:],rand_idx[:cut]\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = list(range(30))\n",
    "f = RandomSplitter(seed=42)\n",
    "trn,val = f(src)\n",
    "assert 0<len(trn)<len(src)\n",
    "assert all(o not in val for o in trn)\n",
    "test_eq(len(trn), len(src)-len(val))\n",
    "# test random seed consistency\n",
    "test_eq(f(src)[0], trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def _grandparent_idxs(items, name): return mask2idxs(Path(o).parent.parent.name == name for o in items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def GrandparentSplitter(train_name='train', valid_name='valid'):\n",
    "    \"Split `items` from the grand parent folder names (`train_name` and `valid_name`).\"\n",
    "    def _inner(o, **kwargs):\n",
    "        return _grandparent_idxs(o, train_name),_grandparent_idxs(o, valid_name)\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = [path/'train/3/9932.png', path/'valid/7/7189.png', \n",
    "         path/'valid/7/7320.png', path/'train/7/9833.png',  \n",
    "         path/'train/3/7666.png', path/'valid/3/925.png',\n",
    "         path/'train/7/724.png', path/'valid/3/93055.png']\n",
    "splitter = GrandparentSplitter()\n",
    "test_eq(splitter(items),[[0,3,4,6],[1,2,5,7]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final set of functions is used to *label* a single item of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def parent_label(o, **kwargs):\n",
    "    \"Label `item` with the parent folder name.\"\n",
    "    return o.parent.name if isinstance(o, Path) else o.split(os.path.sep)[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `parent_label` doesn't have anything customize, so it doesn't return a function - you can just use it directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3', '7', '7', '7', '3', '3', '7', '3']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_eq(parent_label(items[0]), '3')\n",
    "[parent_label(o) for o in items]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def RegexLabeller(pat):\n",
    "    \"Label `item` with regex `pat`.\"\n",
    "    pat = re.compile(pat)\n",
    "    def _inner(o, **kwargs):\n",
    "        res = pat.search(str(o))\n",
    "        assert res,f'Failed to find \"{pat}\" in \"{o}\"'\n",
    "        return res.group(1)\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`RegexLabeller` is a very flexible function since it handles any regex search of the stringified item. For instance, here's an example the replicates the previous `parent_label` results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3', '7', '7', '7', '3', '3', '7', '3']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = RegexLabeller(r'/(\\d)/')\n",
    "test_eq(parent_label(items[0]), '3')\n",
    "[f(o) for o in items]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorize -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class Categorize(ItemTransform):\n",
    "    \"Reversible transform of category string to `vocab` id\"\n",
    "    order=1\n",
    "    def __init__(self, vocab=None, subset_idx=None):\n",
    "        self.vocab,self.subset_idx = vocab,subset_idx\n",
    "        self.o2i = None if vocab is None else {v:k for k,v in enumerate(vocab)}\n",
    "        \n",
    "    def setup(self, dsrc):\n",
    "        if not dsrc: return\n",
    "        if self.vocab is None:\n",
    "            dsrc = getattr(dsrc,'train',dsrc)\n",
    "            self.vocab,self.o2i = uniqueify(dsrc, sort=True, bidir=True)\n",
    "\n",
    "    def encodes(self, o)->int: return self.o2i[o]\n",
    "    def decodes(self, o)->Str: return self.vocab[o]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = Categorize(subset_idx=[0,1,2])\n",
    "tds = TfmdDS(['cat', 'dog', 'cat'], type_tfms=[cat])\n",
    "test_eq(cat.vocab, ['cat', 'dog'])\n",
    "test_eq(cat('cat'), 0)\n",
    "test_eq(cat.decode(1), 'dog')\n",
    "test_stdout(lambda: tds.show_at(2), 'cat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multicategorize -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class MultiCategory(L):\n",
    "    def show(self, ctx=None, sep=';', **kwargs): return show_title(sep.join(self.mapped(str)), ctx=ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class MultiCategorize(Categorize):\n",
    "    \"Reversible transform of multi-category strings to `vocab` id\"\n",
    "    def setup(self, dsrc):\n",
    "        if not dsrc: return\n",
    "        if self.vocab is None:\n",
    "            dsrc1 = getattr(dsrc,'train',dsrc)\n",
    "            vals = set()\n",
    "            for b in dsrc1: vals = vals.union(set(b))\n",
    "            self.vocab,self.o2i = uniqueify(list(vals), sort=True, bidir=True)\n",
    "        setattr(dsrc, 'vocab', self.vocab)\n",
    "\n",
    "    def encodes(self, o):                return [self.o2i  [o_] for o_ in o]\n",
    "    def decodes(self, o)->MultiCategory: return [self.vocab[o_] for o_ in o]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = MultiCategorize()\n",
    "tds = TfmdDS([['b', 'c'], ['a'], ['a', 'c']], type_tfms=[cat])\n",
    "test_eq(cat.vocab, ['a', 'b', 'c'])\n",
    "test_eq(cat(['a', 'c']), [0,2])\n",
    "test_eq(cat([]), [])\n",
    "test_eq(cat.decode([1]), ['b'])\n",
    "test_stdout(lambda: tds.show_at(2), 'a;c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export core\n",
    "def one_hot(x, c):\n",
    "    \"One-hot encode `x` with `c` classes.\"\n",
    "    res = torch.zeros(c, dtype=torch.uint8)\n",
    "    res[L(x)] = 1.\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(one_hot([1,4], 5), tensor(0,1,0,0,1).byte())\n",
    "test_eq(one_hot([], 5), tensor(0,0,0,0,0).byte())\n",
    "test_eq(one_hot(2, 5), tensor(0,0,1,0,0).byte())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def one_hot_decode(x, vocab=None):\n",
    "    return L(vocab[i] if vocab else i for i,x_ in enumerate(x) if x_==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(one_hot_decode(tensor(0,1,0,0,1)), [1,4])\n",
    "test_eq(one_hot_decode(tensor(0,0,0,0,0)), [   ])\n",
    "test_eq(one_hot_decode(tensor(0,0,1,0,0)), [2  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class OneHotEncode(Transform):\n",
    "    \"One-hot encodes targets and optionally decodes with `vocab`\"\n",
    "    order=2\n",
    "    def __init__(self, do_encode=True, vocab=None): self.do_encode,self.vocab = do_encode,vocab\n",
    "    \n",
    "    def setup(self, dsrc):\n",
    "        if self.vocab is not None:  self.c = len(self.vocab)\n",
    "        else: self.c = len(L(getattr(dsrc, 'vocab', None)))\n",
    "        if not self.c: warn(\"Couldn't infer the number of classes, please pass a `vocab` at init\")\n",
    "\n",
    "    def encodes(self, o)->Tensor: return one_hot(o, self.c) if self.do_encode else tensor(o).byte()\n",
    "    def decodes(self, o)->L: return one_hot_decode(o, self.vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Work in conjunction with ` MultiCategorize` or on its own if you have one-hot encoded targets (pass a `vocab` for decoding and `do_encode=False` in this case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_tfm = OneHotEncode(vocab=['a', 'b', 'c'])\n",
    "tds = TfmdDS([[1,2], [0], [0, 1]], type_tfms=[_tfm])\n",
    "test_eq(_tfm([0,2]), tensor([1, 0, 1]).byte())\n",
    "test_eq(_tfm.decode(tensor([0,1,1])), ['b','c'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_tfm = OneHotEncode(vocab=['a', 'b', 'c'], do_encode=False)\n",
    "tds = TfmdDS([[0,1,1], [1,0,0], [1,1,0]], type_tfms=[_tfm])\n",
    "test_eq(_tfm([1,0,1]), tensor([1, 0, 1]).byte())\n",
    "test_eq(_tfm.decode(tensor([0,1,1])), ['b','c'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tds = TfmdDS([['b', 'c'], ['a'], ['a', 'c']], [[MultiCategorize(), OneHotEncode()]])\n",
    "test_eq(tds[1], [tensor([1, 0, 0]).byte()])\n",
    "test_eq(tds.decode([tensor([0,1,1])]), [['b','c']])\n",
    "test_stdout(lambda: tds.show_at(2), 'a;c')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End-to-end dataset example with MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([PosixPath('/home/jhoward/git/fastai_docs/dev/data/mnist_tiny/train/3/8055.png'),\n",
       "  PosixPath('/home/jhoward/git/fastai_docs/dev/data/mnist_tiny/train/3/9466.png'),\n",
       "  PosixPath('/home/jhoward/git/fastai_docs/dev/data/mnist_tiny/train/3/7778.png')],\n",
       " [PosixPath('/home/jhoward/git/fastai_docs/dev/data/mnist_tiny/valid/3/957.png'),\n",
       "  PosixPath('/home/jhoward/git/fastai_docs/dev/data/mnist_tiny/valid/3/9073.png'),\n",
       "  PosixPath('/home/jhoward/git/fastai_docs/dev/data/mnist_tiny/valid/3/8939.png')])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items = get_image_files(path)\n",
    "splits = splitter(items)\n",
    "train,valid = (items[i] for i in splits)\n",
    "train[:3],valid[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "def open_img(fn:Path)->Image.Image: return Image.open(fn).copy()\n",
    "def img2tensor(im:Image.Image)->TensorImage: return array(im)[None]\n",
    "\n",
    "tfms = [[open_img, img2tensor],\n",
    "        [parent_label, Categorize()]]\n",
    "datasets = TfmdDS(items, tfms)\n",
    "\n",
    "# NB: `DataSource` is an easier way to handle this common case\n",
    "train_ds,valid_ds = map(datasets.subset, splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = train_ds[3]\n",
    "xd,yd = train_ds.decode_at(3)\n",
    "test_eq(parent_label(train[3]),yd)\n",
    "test_eq(array(Image.open(train[3])),xd[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFkAAABlCAYAAAAms095AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAABLlJREFUeJzt3E+ozWkcx/HX41IUovwp+VMmpaZMShgKWZjFEFKaCQtlIwtkw0LURSmrWcxGogwlQ1IoC81iiMXYIGOaMCVEiDLyZ/xmYc497uWMuZz7/M79zfddt3tPv3vO8+3d537Pc773OScVRSHoWfqUXcD/gZCcgZCcgZCcgZCcgZCcgZCcgcpJTin9kFK6k1J6klL6LaW0qvSaqvZiJKX0OX4viuJ5SmkifsLXRVH8UlZNlUtyURRXiqJ4Xrv5z9dnJZZUPcmQUvo+pfQnfsUdnCy1nqq1ixoppTZ8iTnYWRTFy7JqqWSSoSiKv4qi+BmjsbrMWior+S36ip7cPFJKI1JK36SUBqaU2lJKX+FbnCm1rir15JTScPyIL7wJ0B/4riiK3aXWVSXJrUql2kWrEpIzEJIzEJIz0DfzelV+lk2NLkSSMxCSMxCSMxCSMxCSMxCSMxCSM5B7n5yNp0+fgj179oC1a9eCpUuXgoMHD4K2trYeryWSnIHco84eXezs2bPg2bNndu7cCc6cef+8/sqVK2DixInNWj5e8ZVJr+7J9+/fB/v37webNm0Cr169+uB9L1++jKYmuSGR5Az0yp584MABsGXLFnDjxo1O14cOHdrx86NHjzpdGzduHLh27Rro169fM0oienK59Mqe/ODBA7yb4JUrV4L169fbuHEjOHmy8wmtDRs2oKkJ/iCR5Az0yiSvWbMGXLp0CSxYsADMmzcPtLe3v5PgQYMGgfnz5+cqs4NIcgZ65e6iK9evXwc7duwAe/fu7bg2ZMgQcPHiRdR3Fz1A7C7KpBJJHjhwIN7MLLpSm13Mnj27J5Z+m0hymVQiyQMGDAAvXrx459qwYcPA6tVvzoHPnTsXzJw5E02dJ0eSy6TySW7E1KlTwa5du8Do0aPxSbuPhkmuhOSrV6+CY8eOgYULF3Zc27dvH7hw4UKn+9y6dQvcvHkTLFq0CBw5cuRjy4h2USaVSPLH8PDhQzBnzhzUh061xNfaRzeIJJdJr0hyrcba9z59mpeNWnJnzJgBHSPS7du3d/ehIsll0tKjzuPHj4Pbt2+DxYsXg5EjRzZtjRMnTnS6ffr0aXxUkhsSSc5AS/fkKVOmgOHDh4NTp041rZC7d++CyZMng3v37oFz586BadOmdfchoyeXSUv25PPnz6N+lKq2l/0UXr9+DbZu3Qp2737zTuBagmt9ftSoUZ+8VlciyRloySRPmjQJjB07FvVkr1ixAmzevLnT70+YMAH1OcTLl/XPD6kd4ao9RqMDiMuXLwdjxoz55Pq7EknOQEvvLpYsWYL6dK0Ry5YtA0ePHsX7/w3Vldow/9ChQ2D69Omgf//+3SnxbWJ3USYtneQnT56g/taD9vZ28PjxY/y3xNbmHCNGjED9r2PdunVg/Pjx3Snp34gkl0lLJ7kRtQPc27ZtA4cPHwazZs0Cq1bVPzly8ODBqB/l6kEiyWXSK5PcokSSyyQkZyAkZyAkZyAkZyAkZyAkZyD3PLnhXrLKRJIzEJIzEJIzEJIzEJIzEJIzEJIzEJIzEJIzEJIzEJIzEJIzEJIzEJIzEJIzEJIzEJIzEJIzEJIzEJIzEJIzEJIzEJIz8Dd4eV5dWUTvDwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = train_ds.show_at(3, cmap=\"Greys\", figsize=(1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert ax.title.get_text() in ('3','7')\n",
    "test_fig_exists(ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TfmdDL -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _DataLoader__getattr(self,k):\n",
    "    try: return getattr(self.dataset, k)\n",
    "    except AttributeError: raise AttributeError(k) from None\n",
    "DataLoader.__getattr__ = _DataLoader__getattr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If `x` isn't of type `t`, then cast it\n",
    "def _cast_tensor(x, t): return t(x) if not isinstance(x, t) and issubclass(t, Tensor) else x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@docs\n",
    "class TfmdDL(GetAttr):\n",
    "    \"Transformed `DataLoader` using a `Pipeline` of `tfm`\"\n",
    "    _xtra = 'batch_size num_workers dataset sampler pin_memory'.split()\n",
    "    \n",
    "    def __init__(self, dataset, tfms=None, bs=16, shuffle=False, num_workers=1, **kwargs):\n",
    "        self.dl = DataLoader(dataset, bs, shuffle, num_workers=num_workers, **kwargs)\n",
    "        self.default,self.tfms = self.dl,Pipeline(tfms, as_item=False)\n",
    "        self.tfms.setup(self)\n",
    "    \n",
    "    def __len__(self): return len(self.dl)\n",
    "    def one_batch(self): return next(iter(self))\n",
    "    def __iter__(self): \n",
    "        return (self.tfms(self._retain_cls(b), filt=getattr(self.dataset, 'filt', None)) for b in self.dl)\n",
    "    \n",
    "    def decode(self, b): \n",
    "        f = getattr(self.dataset,'decode_batch',noop)\n",
    "        return f(self.tfms.decode(b, filt=getattr(self.dataset, 'filt', None)))\n",
    "\n",
    "    def show_batch(self, b=None, max_rows=1000, ctxs=None, **kwargs):\n",
    "        \"Show `b` (defaults to `one_batch`), a list of lists of pipeline outputs (i.e. output of a `DataLoader`)\"\n",
    "        if b is None: b=self.one_batch()\n",
    "        b = self.tfms.decode(b, filt=getattr(self.dataset, 'filt', None))\n",
    "        if ctxs is None: ctxs = [None] * len(b[0] if is_iter(b[0]) else b)\n",
    "        for o,ctx in zip(batch_to_samples(b, max_rows),ctxs): \n",
    "            self.dataset.show(self._retain_cls(o), ctx=ctx)\n",
    "    \n",
    "    @functools.lru_cache()\n",
    "    def _ds_types(self): return L(self.dataset[0]).mapped(type)\n",
    "    def _retain_cls(self, b): return tuple(_cast_tensor(*o) for o in L(b,self._ds_types()).zipped())\n",
    "\n",
    "    _docs = dict(decode=\"Decode `b` using `ds_tfm` and `tfm`\",\n",
    "                 show_batch=\"Show each item of `b`\",\n",
    "                 one_batch=\"Grab first batch of `dl`\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NegTfm(Transform):\n",
    "    def encodes(self, x): return -x\n",
    "    def decodes(self, x): return -x\n",
    "    \n",
    "tdl = TfmdDL(train_ds, NegTfm(), bs=4)\n",
    "b = next(iter(tdl))\n",
    "test_eq(type(b[0]), TensorImage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class A(Transform): \n",
    "    def encodes(self, x): return x \n",
    "    def decodes(self, x)->Int: return x \n",
    "\n",
    "start = range(50)\n",
    "tds = TfmdDS(start, [A()])\n",
    "tdl = TfmdDL(tds, NegTfm(), bs=4)\n",
    "test_eq(*tdl.dataset[0], start[0])\n",
    "test_eq(len(tdl), (len(tds)-1)//4+1)\n",
    "test_eq(tdl.batch_size, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"<code>TfmdDL.one_batch</code>\" class=\"doc_header\"><code>TfmdDL.one_batch</code><a href=\"https://nbviewer.jupyter.org/github/fastai/fastai_docs/blob/master/dev/04_data_core.ipynb#TfmdDL--\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>TfmdDL.one_batch</code>()\n",
       "\n",
       "Grab first batch of `dl`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(TfmdDL.one_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = tdl.one_batch()\n",
    "test_eq(tensor([0,-1,-2,-3]), b[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"<code>TfmdDL.decode</code>\" class=\"doc_header\"><code>TfmdDL.decode</code><a href=\"https://nbviewer.jupyter.org/github/fastai/fastai_docs/blob/master/dev/04_data_core.ipynb#TfmdDL--\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>TfmdDL.decode</code>(**`b`**)\n",
       "\n",
       "Decode `b` using `ds_tfm` and `tfm`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(TfmdDL.decode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(*tdl.decode(b), tensor([0,1,2,3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"<code>TfmdDL.show_batch</code>\" class=\"doc_header\"><code>TfmdDL.show_batch</code><a href=\"https://nbviewer.jupyter.org/github/fastai/fastai_docs/blob/master/dev/04_data_core.ipynb#TfmdDL--\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>TfmdDL.show_batch</code>(**`b`**=*`None`*, **`max_rows`**=*`1000`*, **`ctxs`**=*`None`*, **\\*\\*`kwargs`**)\n",
       "\n",
       "Show each item of `b`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(TfmdDL.show_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_stdout(tdl.show_batch, \"0\\n1\\n2\\n3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cuda -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@docs\n",
    "class Cuda(Transform):\n",
    "    \"Move batch to `device` (defaults to `defaults.device`)\"\n",
    "    def __init__(self,device=None): \n",
    "        self.device=default_device() if device is None else device\n",
    "        super().__init__(filt=None, as_item=False)\n",
    "    def encodes(self, b): return to_device(b, self.device)\n",
    "    def decodes(self, b): return to_cpu(b)\n",
    "    \n",
    "    _docs=dict(encodes=\"Move batch to `device`\", decodes=\"Return batch to CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"<code>{'object': 'encodes'}</code>\" class=\"doc_header\"><code>{'object': 'encodes'}</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "Move batch to [`device`](https://pytorch.org/docs/stable/tensor_attributes.html#torch-device)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Cuda.encodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that, like all `Transform`s, `encodes` is called by `tfm()` and `decodes` is called by `tfm.decode()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfm = Cuda()\n",
    "t = tfm((tensor(1),))\n",
    "test_eq(*t,1)\n",
    "test_eq(t[0].type(),'torch.cuda.LongTensor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"<code>{'object': 'decodes'}</code>\" class=\"doc_header\"><code>{'object': 'decodes'}</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "Return batch to CPU"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Cuda.decodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = tfm.decode(t)\n",
    "test_eq(*t,1)\n",
    "test_eq(t[0].type(),'torch.LongTensor')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ByteToFloatTensor -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class ByteToFloatTensor(Transform):\n",
    "    \"Transform image to float tensor, optionally dividing by 255 (e.g. for images).\"\n",
    "    order = 20 #Need to run after CUDA if on the GPU\n",
    "    def __init__(self, div=True, div_mask=False, filt=None, as_item=True):\n",
    "        super().__init__(filt=filt,as_item=as_item)\n",
    "        self.div,self.div_mask = div,div_mask\n",
    "\n",
    "    def encodes(self, o:TensorImage): return o.float().div_(255.) if self.div else o.float()\n",
    "    def decodes(self, o:TensorImage): return o.clamp(0., 1.) if self.div else o\n",
    "    def encodes(self, o:TensorMask)->TensorMask: return o.div_(255.).long() if self.div_mask else o.long()\n",
    "    def decodes(self, o:TensorMask): return o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = (TensorImage(tensor(1)),tensor(2).long(),TensorMask(tensor(3)))\n",
    "tfm = ByteToFloatTensor(as_item=False)\n",
    "ft = tfm(t)\n",
    "test_eq(ft, [1./255, 2, 3])\n",
    "test_eq(type(ft[0]), TensorImage)\n",
    "test_eq(type(ft[2]), TensorMask)\n",
    "test_eq(ft[0].type(),'torch.FloatTensor')\n",
    "test_eq(ft[1].type(),'torch.LongTensor')\n",
    "test_eq(ft[2].type(),'torch.LongTensor')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@docs\n",
    "class Normalize(Transform):\n",
    "    \"Normalize/denorm batch of `TensorImage`\"\n",
    "    order=99\n",
    "    def __init__(self, mean, std): self.mean,self.std = mean,std   \n",
    "    def encodes(self, x:TensorImage): return (x-self.mean) / self.std\n",
    "    def decodes(self, x:TensorImage): return (x*self.std ) + self.mean\n",
    "    \n",
    "    _docs=dict(encodes=\"Normalize batch\", decodes=\"Denormalize batch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def broadcast_vec(dim, ndim, *t, cuda=True):\n",
    "    \"Make a vector broadcastable over `dim` (out of `ndim` total) by prepending and appending unit axes\"\n",
    "    v = [1]*ndim\n",
    "    v[dim] = -1\n",
    "    f = to_device if cuda else noop\n",
    "    return [f(tensor(o).view(*v)) for o in t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean,std = [0.5]*3,[0.5]*3\n",
    "mean,std = broadcast_vec(1, 4, mean, std)\n",
    "dl_tfms = [Cuda(), ByteToFloatTensor(), Normalize(mean,std)]\n",
    "tdl = TfmdDL(train_ds, dl_tfms, bs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y  = tdl.one_batch()\n",
    "xd,yd = tdl.decode((x,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(x.type(), 'torch.cuda.FloatTensor')\n",
    "test_eq(xd.type(), 'torch.FloatTensor')\n",
    "assert x.mean()<0.0\n",
    "assert x.std()>0.5\n",
    "assert 0<xd.mean()/255.<1\n",
    "assert 0<xd.std()/255.<0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAEICAYAAAB/KknhAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAETZJREFUeJzt3XmoVdUXwPG19YljOaRpVEYommU5Zlpq+RRtNlLTCjIt0sQEZyRohErDCisrrRwIkUzJofzDzIe+DCq1wfKRU1aWhWm+7GdWen5/VMu9T93nvdc7vHvX9wPC2qx3z9l4XN6939lnHxdFkQCwpUa+OwAg9yh8wCAKHzCIwgcMovABgyh8wCAKHzCIwk+Sc+4159z3zrlK59yXzrm7890nZJ6V6+xYwJMc59xFIrIjiqKjzrkLRKRMRK6LomhTfnuGTLJynfnGT1IURZ9HUXT0n+bff1rlsUvIAivXmcJPgXNutnPufyJSISLfi8jbee4SssDCdWaonyLnXE0R6SEiV4nI9CiK/shvj5ANxX6d+cZPURRFx6IoKheRc0Tk3nz3B9lR7NeZwk9fiRTh3A//UpTXmcJPgnPuTOfcMOdcA+dcTefcABG5VUTezXffkDmWrjNz/CQ455qJyBsi0kH++s9yj4jMiqJobl47hoyydJ0pfMAghvqAQRQ+YBCFDxhE4QMGleTyZM45fpNYTURR5LJ1bK5z9ZHoOvONDxhE4QMGUfiAQRQ+YBCFDxhE4QMGUfiAQRQ+YBCFDxhE4QMGUfiAQRQ+YBCFDxiU06fzcqF58+YaL1myJMj16tVL4zlz5gS5pk2barxy5cqEx58/f/4p9hDIP77xAYMofMAgCh8wKKfba+diZ5arrrpK4zVr1gS5GjVO/D93/PjxtI5fXl4etJ944omgXVFRofG3334b5I4dO5bWObOhEHbgKSk58Suo0aNHB7mrr75a43r16gW50tLSTJy+KLADDwBF4QMGFd1Q/7zzztN46dKlQa5Tp04apzvU96cLJzvOxIkTg/asWbPSOmc2FMJQ/5JLLtF48+bNCX9u4cKFQfuZZ57JxOmr9Msvv2i8e/furJ8vXQz1ASgKHzCIwgcMKro5vq9JkyZB21/C26FDhyDXsGHDpI6Zyhz/6NGjQfuHH37Q+K677gpyW7Zs0fjQoUNJ9eVUFNMc/z/Or3G6/779Y/zXcQ4cOKBxt27dgtxXX32V1jmzgTk+AEXhAwYV9VC/KgMGDAja99xzj8Y33nhjws+lMtSvSvw4ffr00Xj9+vVpHTMVhTDUr1OnjsatW7cOcu3bt9fYX8UnItKlSxeN27Vrl9a5TzbU93Xs2DFob926Na1zZgNDfQCKwgcMovABg8zO8dPVs2fPoD1y5Mig7c/34rcMffE5/q5duzRu1arVqXQxKYUwx09XgwYNNK5bt25ax9i3b1/QjtfJnj17NL7iiiuq/Gw+MccHoCh8wKCi22wz2+IbcWzfvj1oT506VeOLL7446eP6m4QOHz48yC1YsCCVLpp3+PDh/4zj/NuFIuHTnPGp2O+//x60Z8+erXF1Gtoni298wCAKHzCIwgcMYo6fovjyzPguPy1btkzruLVr19bY30UI2TNkyJCg7S/jji/FfvLJJ4P2zJkzs9exHOAbHzCIwgcMYuXef+jevXvQHjNmjMbxJ8EaN26c1jnit4u+/vprjeMr/iorK9M6R1WKeeVest58882gff3112v8888/Bzn/aUCRwrmFx8o9AIrCBwyi8AGDuJ33t5tuuknj+fPnB7n69etrnKkdeOLmzJmjcTbm9PhLjx49NO7Xr1/Cn5swYULQLpQ5fbL4xgcMovABg8zezouvjvM3wqjKqQz1/Sf7rrzyyqQ/lw1Wb+ctW7ZM46o2VfVf0V3IuJ0HQFH4gEEUPmBQcUxkMiDd23LxnVn27t2r8eTJk4Pce++9l9Y5kDmbNm3SeODAgQl/Lv40Xvx3Yf5Tmdu2bQtyhXA7lm98wCAKHzCIwgcM4j7+33bs2JHU5+L38Z9++umgPWnSpFPrWI5YvY/fokULjVesWBHkOnfurHEqL83cvXt30N64caPGGzZsCHJvvPGGxvFHf7OB+/gAFIUPGGR2qF+zZs2gPWPGDI3HjRuX8HPxof748eOD9vLlyzX2369W3Vgd6vv8Yb9I+AKUadOmBbnevXundY74lGHdunUa33LLLUHuwIEDaZ2jKgz1ASgKHzCIwgcMMjvHj/NflBF/0cKUKVM0PtljuZ988onG/fv3D3LZmMOlizl+1eKP5V5wwQVB+/zzz9d40KBBQW7w4MEa161bN8j59VZWVpbwc5m61cccH4Ci8AGDCnKo76+6i++c4z8Rl+7Quk2bNkHbf+d9KjvwVFRUBG1/x5edO3em1bdMYaifPU2bNtX4oYceCnKjR49O+Dl/url169aM9IWhPgBF4QMGUfiAQQW/A098jj19+vSEP+vPz1PZcaeqn60qF/9dgb+cN/4SRhQPf5lut27dEubiuzcdO3Ysux3z8I0PGEThAwYV/FC/kLRt2zbfXUCG+Cv3unfvHuTmzp2rcXzl3pEjRzSOPwUa37Qzm/jGBwyi8AGDKHzAoIJcsuvvnnP22WcHOX9+VVpaGuTSvZ2X6BincpxatWql9blMYcmuyFlnnRW0/R146tevH+RGjRoVtP2NOZs0aZLwHNu3bw/a/os6Xn311eQ7myaW7AJQFD5gUEEO9avSvHlzjQcMGBDk5s2bp3Euhvrxp/P8Yd7ChQvTOn+mMNQXWbNmTdDu06ePxqnsqx/n750/duzYILd///5UunjKGOoDUBQ+YBCFDxhUdHN8JIc5fnjrV0RkxIgRGs+cObPKz/ovS1myZEmQ8+fxuayv/8IcH4Ci8AGDGOobxVDfBob6ABSFDxhE4QMGUfiAQRQ+YBCFDxhE4QMGUfiAQRQ+YBCFDxiU0yW7AKoHvvEBgyh8wCAKHzCIwgcMovABgyj8JDnnXnPOfe+cq3TOfemcuzvffULmWbnO3M5LknPuIhHZEUXRUefcBSJSJiLXRVG0Kb89QyZZuc584ycpiqLPoyg6+k/z7z+t8tglZIGV60zhp8A5N9s59z8RqRCR70Xk7Tx3CVlg4Toz1E+Rc66miPQQkatEZHoURX/kt0fIhmK/znzjpyiKomNRFJWLyDkicm+++4PsKPbrTOGnr0SKcO6HfynK60zhJ8E5d6ZzbphzroFzrqZzboCI3Coi7+a7b8gcS9eZOX4SnHPNROQNEekgf/1nuUdEZkVRNLfKD6KgWLrOFD5gEEN9wCAKHzCIwgcMovABg0pyeTJen1x98JpsG3hNNgBF4QMGUfiAQRQ+YBCFDxhE4QMGUfiAQRQ+YBCFDxhE4QMGUfiAQRQ+YBCFDxiU06fzcqFv374a9+rVK8j17NlT49LS0oTHcC58oKmq7clWr14dtDdu3Kjx66+/HuR27typ8fHjxxMeE/l35plnBu1x48YF7fvvv1/jd955J8hde+21Gv/xR/Xcjp9vfMAgCh8wiMIHDMrp9trZ2JnljjvuCNpz557YAr1GjfD/tS1btmj87rvhOxI+/vhjjeNz/A4dOiQ8f4sWLYJ2//79NW7evHmQW7t2rca33XZbkNu/f3/Cc2QDO/CIDB06NGjXq1dP49GjRwe5rl27Jn3cfv36abxu3bo0e5cZ7MADQFH4gEEFOdRv1qyZxl988UWQ89v+LRcRkfLy8kycvkqnn366xkOGDAlyEydO1PjIkSNBrkuXLtntWIyVoX7btm2D9p133qnxhAkTglxJSWbubo8fP17jWbNmZeSY6WKoD0BR+IBBFD5gUEHO8YcNG6bxs88+G+T8Od2BAwcycbqM6dOnj8bxZZ7+7SL/tmO2FPMcf9KkSRqPHTs2yJ177rkJP3fo0KGEuYYNGybM7d27N2j7/wbjv8vJNeb4ABSFDxhUkE/nlZWVafzUU08Fueo2vPdt2LBB44MHDwa5li1bapyLoX4xa9SokcZVDe2XL18etF944QWNH3jggSB3+eWXJzzOvHnzgna+h/fJ4BsfMIjCBwyi8AGDCnKOv2/fPo0ff/zxPPYkNaNGjdK4cePGQW779u257k7RevjhhzVu165dkPNvoy5atCjIzZgxQ+Oq5vQiIr/++qvGq1atSquf+cQ3PmAQhQ8YVJAr9wrFlClTgrY/BI1v0nnzzTfnpE//KOaVe1Xp0aOHxpMnTw5yAwcOTPi5ysrKoO1vuPLhhx9mqHeZx8o9AIrCBwyi8AGDmOOfok6dOgXthQsXatymTZsg5y8JnTp1apA7evRoFnqXmNU5vn8brk6dOkl/bvjw4UH7tddey1ifsok5PgBF4QMGFfVQP74/fpMmTTS+6KKLglzr1q017tatW5Dz98f3380nItKgQYOg/fnnn2v8yCOPBLklS5Yk0+2csDrU/+233zSuVatW0p+LP025ePFijf33JYqE70z8888/U+1iRjHUB6AofMAgCh8wqKjn+GeccUbQ/vHHH5P6XPx3A6n8HX366acajxkzJsh99NFHGuf7venM8VOb46di69atGj/22GNBbteuXRrnYqkvc3wAisIHDCrqoX58ZdZ9992X1Oc++OCDoH348GGNS0tLg1z8Vdj+u9nim23s3r1b40cffTTILViwIKm+ZYrVob5/O/a6664Lcm+//XbCz916661Bu2PHjgl/tmnTphqfc845QW79+vUa++9ZyBaG+gAUhQ8YROEDBhX1HD8fTjvtNI3jO7o8//zzGseX+vobiA4dOjTIlZeXZ7KLImJ3jp8LrVq10jj+ewP/HXzXXHNNkMvGi1SY4wNQFD5gEIUPGMQcP0+mTZsWtB988EGN4y/+vOGGGzTetGlTRs5f6HN8f1l1fIn18ePHs336pA0aNCho+4/svvzyy0HOf+FKpjDHB6AofMAghvrVxKWXXqrxunXrgty2bds0vuyyy4JcusPaQhvq33vvvUG7WbNmGsd3NvL/vvJt9uzZQdsfzsf72b59+4yfn6E+AEXhAwZR+IBBzPGroZdeeilo33333Rr7c1uRf9/6S1ahzfH93YtFRA4dOqTxyd5ln2sXXnihxmVlZUHO3xVqyJAhQW7ZsmUZ7wtzfACKwgcMKsl3B/Bv/o4/lg0ePFhj/4k3EZHNmzfnujuBGjVOfGc+99xzQc7vd3zD1/3792u8Z8+eLPXu5PjGBwyi8AGDKHzAoIKc4/u71xTSfLik5MRfd9u2bYPc7bffrvH48eODnL+EN93bd4XIvxX23XffBTn/padvvfVWkJsxY0bCY/q73MaXP9euXTvh54YNGxa0O3furHHXrl0Tfi5u1apVGmfqSct08I0PGEThAwYVxMo9f4NCEZGKigqNp0+fHuRWr16tsb+6SyTc0DJTWrRoEbT9vvbq1SvIjRgxQuPu3bsHuc8++0zjpUuXBrlXXnlF4/iQN12FtnIv/sRi79690zqO/+8j/kKL+AtY0nXw4EGN49O2FStWaBz/95kNrNwDoCh8wCAKHzCoIOb4/vJIEZFFixZpHH/CyVdZWRm0/Tl+/GmvHTt2aBy/zROfx/viL81s1KiRxlX93cafwBszZkzCn82GQpvjx18+OXLkSI3jf3f+S00yNW+P73T0008/abx27dog5y/hff/99zNy/nQxxwegKHzAoIIY6sf5Q/+ePXsGOb/tb2ApEq748zdLEAmH8/F92jds2KDxyVbOrVy5UuP4360/JPzmm2+CXC6vw9/nK6ihfir69++v8aRJk4Jc3759NY6/q27x4sUJjxlfIfriiy+eShdzhqE+AEXhAwZR+IBBBTnHx6kr5jk+TmCOD0BR+IBBFD5gEIUPGEThAwZR+IBBFD5gEIUPGEThAwZR+IBBFD5gEIUPGEThAwbl9Ok8ANUD3/iAQRQ+YBCFDxhE4QMGUfiAQRQ+YBCFDxhE4QMGUfiAQRQ+YBCFDxhE4QMGUfiAQRQ+YBCFDxhE4QMGUfiAQRQ+YBCFDxhE4QMGUfiAQRQ+YBCFDxj0f7Hcxif/CG0xAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 288x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "_,axs = plt.subplots(2,2, figsize=(4,4))\n",
    "tdl.show_batch((x,y), ctxs=axs.flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataBunch -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@docs\n",
    "class DataBunch(GetAttr):\n",
    "    \"Basic wrapper around several `DataLoader`s.\"\n",
    "    _xtra = 'one_batch show_batch dataset'.split()\n",
    "\n",
    "    def __init__(self, *dls): self.dls,self.default = dls,dls[0]\n",
    "    def __getitem__(self, i): return self.dls[i]\n",
    "\n",
    "    train_dl,valid_dl = add_props(lambda i,x: x[i])\n",
    "    train_ds,valid_ds = add_props(lambda i,x: x[i].dataset)\n",
    "    \n",
    "    _docs=dict(__getitem__=\"Retrieve `DataLoader` at `i` (`0` is training, `1` is validation)\",\n",
    "              train_dl=\"Training `DataLoader`\",\n",
    "              valid_dl=\"Validation `DataLoader`\",\n",
    "              train_ds=\"Training `Dataset`\",\n",
    "              valid_ds=\"Validation `Dataset`\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbch = DataBunch(tdl,tdl)\n",
    "x,y  = dbch.train_dl.one_batch()\n",
    "x2,y2 = next(iter(tdl))\n",
    "test_eq(x,x2)\n",
    "x2,y2 = dbch.one_batch()\n",
    "test_eq(x,x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"<code>DataBunch.__getitem__</code>\" class=\"doc_header\"><code>DataBunch.__getitem__</code><a href=\"https://nbviewer.jupyter.org/github/fastai/fastai_docs/blob/master/dev/04_data_core.ipynb#DataBunch--\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>DataBunch.__getitem__</code>(**`i`**)\n",
       "\n",
       "Retrieve [`DataLoader`](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader) at `i` (`0` is training, `1` is validation)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(DataBunch.__getitem__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2,y2 = dbch[0].one_batch()\n",
    "test_eq(x,x2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"<code>train_dl</code>\" class=\"doc_header\"><code>train_dl</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "Training [`DataLoader`](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(DataBunch.train_dl, name=\"train_dl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"<code>valid_dl</code>\" class=\"doc_header\"><code>valid_dl</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "Validation [`DataLoader`](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(DataBunch.valid_dl, name=\"valid_dl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"<code>train_ds</code>\" class=\"doc_header\"><code>train_ds</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "Training `Dataset`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(DataBunch.train_ds, name=\"train_ds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"<code>valid_ds</code>\" class=\"doc_header\"><code>valid_ds</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "Validation `Dataset`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(DataBunch.valid_ds, name=\"valid_ds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_test.ipynb.\n",
      "Converted 01_core.ipynb.\n",
      "Converted 02_data_pipeline.ipynb.\n",
      "Converted 02_transforms.ipynb.\n",
      "Converted 02a_pipeline.ipynb.\n",
      "Converted 03_data_external.ipynb.\n",
      "Converted 04_data_core.ipynb.\n",
      "Converted 05_data_source.ipynb.\n",
      "Converted 06_vision_core.ipynb.\n",
      "Converted 07_pets_tutorial.ipynb.\n",
      "Converted 08_vision_augment.ipynb.\n",
      "Converted 09_data_block.ipynb.\n",
      "Converted 10_layers.ipynb.\n",
      "Converted 11_optimizer.ipynb.\n",
      "Converted 12_learner.ipynb.\n",
      "Converted 13_callback_schedule.ipynb.\n",
      "Converted 14_callback_hook.ipynb.\n",
      "Converted 15_callback_progress.ipynb.\n",
      "Converted 16_callback_tracker.ipynb.\n",
      "Converted 17_callback_fp16.ipynb.\n",
      "Converted 30_text_core.ipynb.\n",
      "Converted 90_notebook_core.ipynb.\n",
      "Converted 91_notebook_export.ipynb.\n",
      "Converted 92_notebook_showdoc.ipynb.\n",
      "Converted 93_notebook_export2html.ipynb.\n",
      "Converted 94_index.ipynb.\n",
      "Converted 95_synth_learner.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from local.notebook.export import notebook2script\n",
    "notebook2script(all_fs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
