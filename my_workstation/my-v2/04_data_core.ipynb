{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp data.core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from local.imports import *\n",
    "from local.test import *\n",
    "from local.core import *\n",
    "from local.data.pipeline import *\n",
    "from local.data.external import *\n",
    "from local.notebook.showdoc import show_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not exported since we only use it for examples\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions for processing data\n",
    "\n",
    "> Functions for getting, splitting, and labeling data, etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get, split, label, and show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For most data source creation we need functions to get a list of items, split them in to train/valid sets, and label them. fastai provides functions to make each of these steps easy (especially when combined with `fastai.data.blocks`), along with showing data (we'll only define image showing in this section)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we'll look at functions that *get* a list of items (generally file names).\n",
    "\n",
    "We'll use *tiny MNIST* (a subset of MNIST with just two classes, `7`s and `3`s) for our examples/tests throughout this page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/home/jhoward/git/fastai_docs/dev/data/mnist_tiny/train/3'),\n",
       " PosixPath('/home/jhoward/git/fastai_docs/dev/data/mnist_tiny/train/7')]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = untar_data(URLs.MNIST_TINY)\n",
    "(path/'train').ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def _get_files(p, fs, extensions=None):\n",
    "    p = Path(p)\n",
    "    res = [p/f for f in fs if not f.startswith('.')\n",
    "           and ((not extensions) or f'.{f.split(\".\")[-1].lower()}' in extensions)]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def get_files(path, extensions=None, recurse=True, include=None):\n",
    "    \"Get all the files in `path` with optional `extensions`, optionally with `recurse`.\"\n",
    "    path = Path(path)\n",
    "    extensions = setify(extensions)\n",
    "    extensions = {e.lower() for e in extensions}\n",
    "    if recurse:\n",
    "        res = []\n",
    "        for i,(p,d,f) in enumerate(os.walk(path)): # returns (dirpath, dirnames, filenames)\n",
    "            if include is not None and i==0: d[:] = [o for o in d if o in include]\n",
    "            else:                            d[:] = [o for o in d if not o.startswith('.')]\n",
    "            res += _get_files(p, f, extensions)\n",
    "    else:\n",
    "        f = [o.name for o in os.scandir(path) if o.is_file()]\n",
    "        res = _get_files(path, f, extensions)\n",
    "    return L(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the most general way to grab a bunch of file names from disk. If you pass `extensions` (including the `.`) then returned file names are filtered by that list. Only those files directly in `path` are included, unless you pass `recurse`, in which case all child folders are also searched recursively. `include` is an optional list of directories to limit the search to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#709) [/home/jhoward/git/fastai_docs/dev/data/mnist_tiny/train/3/8879.png,/home/jhoward/git/fastai_docs/dev/data/mnist_tiny/train/3/8381.png,/home/jhoward/git/fastai_docs/dev/data/mnist_tiny/train/3/9302.png,/home/jhoward/git/fastai_docs/dev/data/mnist_tiny/train/3/8054.png,/home/jhoward/git/fastai_docs/dev/data/mnist_tiny/train/3/7383.png,/home/jhoward/git/fastai_docs/dev/data/mnist_tiny/train/3/9871.png,/home/jhoward/git/fastai_docs/dev/data/mnist_tiny/train/3/9324.png,/home/jhoward/git/fastai_docs/dev/data/mnist_tiny/train/3/9797.png,/home/jhoward/git/fastai_docs/dev/data/mnist_tiny/train/3/9255.png,/home/jhoward/git/fastai_docs/dev/data/mnist_tiny/train/3/9620.png...]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t3 = get_files(path/'train'/'3', extensions='.png', recurse=False)\n",
    "t7 = get_files(path/'train'/'7', extensions='.png', recurse=False)\n",
    "t  = get_files(path/'train', extensions='.png', recurse=True)\n",
    "test_eq(len(t), len(t3)+len(t7))\n",
    "test_eq(len(get_files(path/'train'/'3', extensions='.jpg', recurse=False)),0)\n",
    "test_eq(len(t), len(get_files(path, extensions='.png', recurse=True, include='train')))\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "test_eq(len(get_files(path/'train'/'3', recurse=False)),346)\n",
    "test_eq(len(get_files(path, extensions='.png', recurse=True, include=['train', 'test'])),729)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's often useful to be able to create functions with customized behavior. `fastai.data` generally uses functions named as CamelCase verbs ending in `er` to create these functions. `FileGetter` is a simple example of such a function creator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def FileGetter(suf='', extensions=None, recurse=True, include=None):\n",
    "    \"Create `get_files` partial function that searches path suffix `suf` and passes along args\"\n",
    "    def _inner(o, extensions=extensions, recurse=recurse, include=include): return get_files(o/suf, extensions, recurse, include)\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpng = FileGetter(extensions='.png', recurse=False)\n",
    "test_eq(len(t7), len(fpng(path/'train'/'7')))\n",
    "test_eq(len(t), len(fpng(path/'train', recurse=True)))\n",
    "fpng_r = FileGetter(extensions='.png', recurse=True)\n",
    "test_eq(len(t), len(fpng_r(path/'train')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "image_extensions = set(k for k,v in mimetypes.types_map.items() if v.startswith('image/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_image_files(path, recurse=True, include=None):\n",
    "    \"Get image files in `path` recursively.\"\n",
    "    return get_files(path, extensions=image_extensions, recurse=recurse, include=include)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is simply `get_files` called with a list of standard image extensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(len(t), len(get_image_files(path, recurse=True, include='train')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def ImageGetter(suf='', recurse=True, include=None):\n",
    "    \"Create `get_image_files` partial function that searches path suffix `suf` and passes along `kwargs`\"\n",
    "    def _inner(o, recurse=recurse, include=include): return get_image_files(o/suf, recurse, include)\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same as `FileGetter`, but for image extensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(len(get_files(path/'train', extensions='.png', recurse=True, include='3')),\n",
    "        len(ImageGetter(  'train',                    recurse=True, include='3')(path)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next set of functions are used to *split* data into training and validation sets. The functions return two lists - a list of indices or masks for each of training and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def RandomSplitter(valid_pct=0.2, seed=None, **kwargs):\n",
    "    \"Create function that splits `items` between train/val with `valid_pct` randomly.\"\n",
    "    def _inner(o, **kwargs):\n",
    "        if seed is not None: torch.manual_seed(seed)\n",
    "        rand_idx = L(int(i) for i in torch.randperm(len(o)))\n",
    "        cut = int(valid_pct * len(o))\n",
    "        return rand_idx[cut:],rand_idx[:cut]\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((#24) [10,18,16,23,28,26,20,7,21,22...], (#6) [12,0,6,25,8,15])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src = list(range(30))\n",
    "f = RandomSplitter(seed=42)\n",
    "trn,val = f(src)\n",
    "assert 0<len(trn)<len(src)\n",
    "assert all(o not in val for o in trn)\n",
    "test_eq(len(trn), len(src)-len(val))\n",
    "# test random seed consistency\n",
    "test_eq(f(src)[0], trn)\n",
    "trn,val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def _grandparent_idxs(items, name): return mask2idxs(Path(o).parent.parent.name == name for o in items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def GrandparentSplitter(train_name='train', valid_name='valid'):\n",
    "    \"Split `items` from the grand parent folder names (`train_name` and `valid_name`).\"\n",
    "    def _inner(o, **kwargs):\n",
    "        return _grandparent_idxs(o, train_name),_grandparent_idxs(o, valid_name)\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = [path/'train/3/9932.png', path/'valid/7/7189.png', \n",
    "         path/'valid/7/7320.png', path/'train/7/9833.png',  \n",
    "         path/'train/3/7666.png', path/'valid/3/925.png',\n",
    "         path/'train/7/724.png', path/'valid/3/93055.png']\n",
    "splitter = GrandparentSplitter()\n",
    "test_eq(splitter(items),[[0,3,4,6],[1,2,5,7]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final set of functions is used to *label* a single item of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def parent_label(o, **kwargs):\n",
    "    \"Label `item` with the parent folder name.\"\n",
    "    return o.parent.name if isinstance(o, Path) else o.split(os.path.sep)[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `parent_label` doesn't have anything customize, so it doesn't return a function - you can just use it directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3', '7', '7', '7', '3', '3', '7', '3']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_eq(parent_label(items[0]), '3')\n",
    "[parent_label(o) for o in items]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def RegexLabeller(pat):\n",
    "    \"Label `item` with regex `pat`.\"\n",
    "    pat = re.compile(pat)\n",
    "    def _inner(o, **kwargs):\n",
    "        res = pat.search(str(o))\n",
    "        assert res,f'Failed to find \"{pat}\" in \"{o}\"'\n",
    "        return res.group(1)\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`RegexLabeller` is a very flexible function since it handles any regex search of the stringified item. For instance, here's an example the replicates the previous `parent_label` results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3', '7', '7', '7', '3', '3', '7', '3']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = RegexLabeller(r'/(\\d)/')\n",
    "test_eq(parent_label(items[0]), '3')\n",
    "[f(o) for o in items]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def show_image(im, ax=None, figsize=None, title=None, ctx=None, **kwargs):\n",
    "    \"Show a PIL image on `ax`.\"\n",
    "    ax = ifnone(ax,ctx)\n",
    "    if ax is None: _,ax = plt.subplots(figsize=figsize)\n",
    "    # Handle pytorch axis order\n",
    "    if isinstance(im,Tensor):\n",
    "        im = to_cpu(im)\n",
    "        if im.shape[0]<5: im=im.permute(1,2,0)\n",
    "    # Handle 1-channel images\n",
    "    if im.shape[-1]==1: im=im[...,0]\n",
    "    ax.imshow(im, **kwargs)\n",
    "    if title is not None: ax.set_title(title)\n",
    "    ax.axis('off')\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`show_image` can show b&w images..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIgAAACMCAYAAACnK+FEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAAZBJREFUeJzt3FEKwjAQQEEj3v/K9QLmfbnYyMwBSgmPhZaw67quB+w8f/0C3JtASAIhCYQkEJJASK+h5x717bzW+vozD/x98PEQTBCSQEgCIQmEJBCSQEgCIQmEJBCSQEgCIQmEJBCSQEgCIQmEJBCSQEgCIQmEJBCSQEgCIQmEJBCSQEgCIQmEJBCSQEgCIQmEJBCSQEgCIQmEJBCSQEgCIQmEJBCSQEgCIY3sap/YfX6a085gt1veBCEJhCQQkkBIAiEJhCQQkkBIAiEJhCQQkkBIAiEJhCQQkkBIAiEJhCQQkkBII5eWdxdg72rigvFpZ7BjgpAEQhIISSAkgZAEQhIISSAkgZAEQhIISSAkgZAEQhIISSAkgZAEQhIISSAkgZAEQhIISSAkgZAEQhIISSAkgZAEQhIISSAkgZAEQhIISSAkgZAEQhIISSAkgZAEQhIIaf3LTnFmmCAkgZAEQhIISSAkgZAEQhIISSAkgZAEQhIISSAkgZAEQhIISSAkgZAEQhIISSAkgZAEQnoDeRQUF0fCbgAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 144x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "im = make_cross_image()\n",
    "ax = show_image(im, cmap=\"Greys\", figsize=(2,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...and color images with standard `c*h*w` dim order..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIgAAACMCAYAAACnK+FEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAAYdJREFUeJzt3MEJAzEMAME4pP+WlQZym5dIDmYKMH4sAoPRmZkHXHn++gL8N4GQBEISCEkgJIGQXhuHnnPu9XbeuO1ZOHPRzHy8sQlCEghJICSBkARCEghJICSBkARCEghJICSBkARCEghJICSBkARCEghJICSBkARCEghJICSBkARCEghJICSBkARCEghJICSBkARCEghJICSBkARCEghJICSBkARCEghJIKSVXe33WtROMUFIAiEJhCQQkkBIAiEJhCQQkkBIAiEJhCQQkkBIAiEJhCQQkkBIAiEJhCQQ0sqn5bNxKKuuPpqbICSBkARCEghJICSBkARCEghJICSBkARCEghJICSBkARCEghJICSBkARCEghJICSBkARCEghJICSBkARCEghJICSBkARCEghJICSBkARCEghJICSBkARCEghJICSBkARCOjNXW7rBBOELgZAEQhIISSAkgZAEQhIISSAkgZAEQhIISSAkgZAEQhIISSAkgZAEQhIISSAkgZAEQnoDIYQOFqYYxq4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 144x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "im2 = make_cross_image(False)\n",
    "ax = show_image(im2, figsize=(2,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...and color images with `h*w*c` dim order..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIgAAACMCAYAAACnK+FEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAAYdJREFUeJzt3MEJAzEMAME4pP+WlQZym5dIDmYKMH4sAoPRmZkHXHn++gL8N4GQBEISCEkgJIGQXhuHnnPu9XbeuO1ZOHPRzHy8sQlCEghJICSBkARCEghJICSBkARCEghJICSBkARCEghJICSBkARCEghJICSBkARCEghJICSBkARCEghJICSBkARCEghJICSBkARCEghJICSBkARCEghJICSBkARCEghJIKSVXe33WtROMUFIAiEJhCQQkkBIAiEJhCQQkkBIAiEJhCQQkkBIAiEJhCQQkkBIAiEJhCQQ0sqn5bNxKKuuPpqbICSBkARCEghJICSBkARCEghJICSBkARCEghJICSBkARCEghJICSBkARCEghJICSBkARCEghJICSBkARCEghJICSBkARCEghJICSBkARCEghJICSBkARCEghJICSBkARCOjNXW7rBBOELgZAEQhIISSAkgZAEQhIISSAkgZAEQhIISSAkgZAEQhIISSAkgZAEQhIISSAkgZAEQnoDIYQOFqYYxq4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 144x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "im3 = im2.permute(1,2,0)\n",
    "ax = show_image(im3, figsize=(2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIgAAACcCAYAAACk/ePfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAA/FJREFUeJzt3LGLHHUYh/HnjUquszAinpCIjWAhNkKUNBJLJTZpFK0sLTQpFEyCWghiEwL6FwS1EFRQhLRBApo/QCGRBONFogY10QjJ+VrMFOG4/Qrh9vbWfT4wxe78dtnZe3bmN3vLVHcjTbJt1i9AW5uBKDIQRQaiyEAUGYgiA1G0kIFU1bNVdbqqrlbVxar6sqr2zPp1bUULF0hVHQCOAm8D9wA7gfeBfeuMvX1zX90W1N0LswB3AleB/RPWvwF8DBwH/gBeBLYzBLUyLkeB7eP4HcDnwG/AZeAksG1c9yrwI3AF+A7YO+vtv5Vl0T4hjwFLwCdhzD5gP/ACQxyvA7uBR4AGPgMOAYeBg8AF4O7xsbuBrqoHgZeAR7t7paruB27b4G3ZFIt2iLkL+KW7b4Qxp7r70+7+p7uvAc8Bb3X3pe7+GXgTeH4cex24F9jV3de7+2QPu49Vhrgeqqo7uvtcd5+d3mZNz6IF8iuw4z/mFj+sub0MnL/p9vnxPoB3gTPAiar6vqpeA+juM8DLDIesS1X1UVUtM4cWLZBTwN/AM2HM2n9vrwC7brq9c7yP7r7S3Qe7+wHgaeBAVe0d133Q3XvGxzbwzsZswuZaqDlId/9eVUeA96rqBnCC4TDxJPAE8Nc6D/sQOFRV3zD8oY8wTGKpqqeAb4GzDJPaVWB1nIPcB3zFEOQ15vXDOOtZ8iwWhnnFaeBP4CfgC+BxhkPC8TVjl4BjwMVxOQYsjeteAc6Nz3MBODze/zDwNcMZzGWGM53lWW/3rSw1bpC0rvnc7WnTGIgiA1FkIIoMRNG0vgeZq1Ojqtrw55zDs8N13wT3IIoMRJGBKDIQRQaiyEAUGYgiA1FkIIoMRJGBKDIQRQaiyEAUGYgiA1FkIIoMRJGBKDIQRQaiyEAUGYgiA1FkIIoMRJGBKDIQRQaiyEAUGYgiA1FkIIoMRJGBKDIQRQaiyEAUGYgiA1FkIIoMRJGBKJrKtdqnce3zeTNv78Gka8u7B1FkIIoMRJGBKDIQRQaiyEAUGYgiA1FkIIoMRJGBKDIQRQaiyEAUGYgiA1FkIIoMRJGBKJrKj5Yn/QB2q5rGD4zn7T2YxD2IIgNRZCCKDESRgSgyEEUGoshAFBmIIgNRZCCKDESRgSgyEEUGoshAFBmIIgNRZCCKDESRgSgyEEUGoshAFBmIIgNRZCCKDESRgSgyEEUGoshAFBmIIgNRZCCKDESRgSgyEEUGoshAFBmIIgNRZCCK6v9yTXFNh3sQRQaiyEAUGYgiA1FkIIoMRJGBKDIQRQaiyEAUGYgiA1FkIIoMRJGBKDIQRQaiyEAUGYgiA1FkIIoMRNG/fYFNCV1f5g0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 144x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = show_image(im, cmap=\"Greys\", figsize=(2,2))\n",
    "show_title(\"Cross\", ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def show_titled_image(o, **kwargs):\n",
    "    \"Call `show_image` destructuring `o` to `(img,title)`\"\n",
    "    show_image(o[0], title=str(o[1]), **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def show_image_batch(b, show=show_titled_image, items=9, cols=3, figsize=None, **kwargs):\n",
    "    \"Display batch `b` in a grid of size `items` with `cols` width\"\n",
    "    rows = (items+cols-1) // cols\n",
    "    if figsize is None: figsize = (cols*3, rows*3)\n",
    "    fig,axs = plt.subplots(rows, cols, figsize=figsize)\n",
    "    for *o,ax in zip(*to_cpu(b), axs.flatten()): show(o, ax=ax, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x216 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_image_batch(([im,im2,im3],['bw','chw','hwc']), items=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ImageItem:\n",
    "    \"An item that `show`s with `show_image`\"\n",
    "    def __init__(self, **kwargs): self.kw = kwargs\n",
    "    def show(self, o, ctx=None, **kwargs): return show_image(o, ax=ctx, **{**kwargs,**self.kw})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class TitledImageItem:\n",
    "    \"An item that `show`s an (image,title) tuple with `show_titled_image`\"\n",
    "    def __init__(self, **kwargs): self.kw = kwargs\n",
    "    def show(self, o, ctx=None, **kwargs): return show_titled_image(o, ax=ctx, **{**kwargs,**self.kw})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorize -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class Categorize(Transform):\n",
    "    \"Reversible transform of category string to `vocab` id\"\n",
    "    order,assoc=1,Item\n",
    "    def __init__(self, vocab=None, train_attr=\"train\", subset_idx=None, mask=None, is_tuple=None):\n",
    "        super().__init__(mask=mask,is_tuple=is_tuple)\n",
    "        self.vocab,self.train_attr,self.subset_idx = vocab,train_attr,subset_idx\n",
    "        self.o2i = None if vocab is None else {v:k for k,v in enumerate(vocab)}\n",
    "        \n",
    "    def setups(self, dsrc):\n",
    "        if not dsrc: return\n",
    "        if self.subset_idx is not None: dsrc = dsrc.subset(self.subset_idx)\n",
    "        elif self.train_attr: dsrc = getattr(dsrc,self.train_attr)\n",
    "        self.vocab,self.o2i = uniqueify(dsrc, sort=True, bidir=True)\n",
    "\n",
    "    def encodes(self, o): return self.o2i[o] if self.o2i else o\n",
    "    def decodes(self, o):  return self.vocab[o]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### End-to-end dataset example with MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((#709) [/home/jhoward/git/fastai_docs/dev/data/mnist_tiny/train/3/8879.png,/home/jhoward/git/fastai_docs/dev/data/mnist_tiny/train/3/8381.png,/home/jhoward/git/fastai_docs/dev/data/mnist_tiny/train/3/9302.png,/home/jhoward/git/fastai_docs/dev/data/mnist_tiny/train/3/8054.png,/home/jhoward/git/fastai_docs/dev/data/mnist_tiny/train/3/7383.png,/home/jhoward/git/fastai_docs/dev/data/mnist_tiny/train/3/9871.png,/home/jhoward/git/fastai_docs/dev/data/mnist_tiny/train/3/9324.png,/home/jhoward/git/fastai_docs/dev/data/mnist_tiny/train/3/9797.png,/home/jhoward/git/fastai_docs/dev/data/mnist_tiny/train/3/9255.png,/home/jhoward/git/fastai_docs/dev/data/mnist_tiny/train/3/9620.png...],\n",
       " (#699) [/home/jhoward/git/fastai_docs/dev/data/mnist_tiny/valid/3/7140.png,/home/jhoward/git/fastai_docs/dev/data/mnist_tiny/valid/3/8346.png,/home/jhoward/git/fastai_docs/dev/data/mnist_tiny/valid/3/8785.png,/home/jhoward/git/fastai_docs/dev/data/mnist_tiny/valid/3/7272.png,/home/jhoward/git/fastai_docs/dev/data/mnist_tiny/valid/3/7995.png,/home/jhoward/git/fastai_docs/dev/data/mnist_tiny/valid/3/9468.png,/home/jhoward/git/fastai_docs/dev/data/mnist_tiny/valid/3/8032.png,/home/jhoward/git/fastai_docs/dev/data/mnist_tiny/valid/3/815.png,/home/jhoward/git/fastai_docs/dev/data/mnist_tiny/valid/3/9409.png,/home/jhoward/git/fastai_docs/dev/data/mnist_tiny/valid/3/9797.png...])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items = get_image_files(path)\n",
    "splits = splitter(items)\n",
    "train,valid = (items[i] for i in splits)\n",
    "train,valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timg = Transform(Image.open, assoc=ImageItem(cmap=\"Greys\", figsize=(1,1)))\n",
    "timg2tensor = Transform(compose(array,tensor))\n",
    "tfms = [[timg,timg2tensor,partial(torch.unsqueeze,dim=0)],\n",
    "        [parent_label, Categorize(subset_idx=splits[0])]]\n",
    "tfm = TfmOver.piped(tfms)\n",
    "datasets = TfmdList(items, tfm)\n",
    "# NB: `DataSource` is an easier way to handle this common case\n",
    "train_ds,valid_ds = map(datasets.subset, splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = train_ds[3]\n",
    "xd,yd = train_ds.decode_at(3)\n",
    "test_eq(parent_label(train[3]),yd)\n",
    "test_eq(array(Image.open(train[3])),xd[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFkAAABlCAYAAAAms095AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAABMJJREFUeJzt2zuIFVccx/HP0dVCo6LgowhYBHQhaFAUjM/gg6ApFKsIohYpjIUgiLhWFhamDRKUYCGmEVL5FiFGjJUEH6hE3UZBgquIq/iMcVKss1eTaHb15szdu/8v3GLvzN7zny+/e+bMf+amoigE/y8Dqi6gPxCSMxCSMxCSMxCSMxCSMxCSM9B0klNKP6SUfk8p3U8pXU0pfVV5Tc12MZJS+hjtRVE8TSm14md8URTFr1XV1HRJLoriUlEUT8s/X74+qrCk5pMMKaXvUkqP8Bt+x+FK62m26aIkpTQQn+IzfFMUxR9V1dKUSYaiKP4siuIXfIivq6ylaSW/QouYk+tHSmlMSunLlNIHKaWBKaXPsQI/VVpXM83JKaXR+BGf6ArQdXxbFMX3ldbVTJIblaaaLhqVkJyBkJyBkJyBlszjNfNZNr1pQyQ5AyE5AyE5AyE5AyE5AyE5AyE5AyE5AyE5AyE5AyE5A7l7F+/FkydPwN69e8HBgwfBgQMHXtuvKAopdbUS9u3bB5YtWwYGDRqUpdZXiSRnIPftp3carL29HcyePRvcvn37X/cbNWoUuHv37j+2bdy4EWzfvh26k15HogtXJQ2d5GvXroF58+aBW7dugVmzZoHFixeD+fPng/Hjx4Pr16+7cuUKWLduHXj8+DE4deoUmDlz5jsewhuJJFdJQya5nIPnzp2LWoIPH+56bnDBggWgpeW/F0fTpk0DZ8+eBVOnTgVnzpzpcdE9JJJcJQ25Tt69ezd48eIFaqmbNGkSepbgN7F06dL3rK73RJIz0JBJLpk8eTJq82hvuHfvHujo6Hjt/bFjx75/Yb0kkpyBhkxy2V8oVxG9pbOz09atW8HNmzfBgAFdeVqzZs1719dbIskZaMh1ck95+PBh14e+PIbTp0+D/fv327lz52v7btmyBWzevBkMHTq0nqXwlnVyn5R8+fJlMGXKFPD8+fMe/2+5/Dt+/DiYOHEiGDlyJBg8ePC7lhUXI1XSJ5NcLs/mzJmDWrLLi5W2tjYTJkwAO3bsAHfu3AGHDh3qKuRvx7127VroPmGOHj26t2VFkqukTya55P79+6g18ceNG4e3n9SuXr2KWvP+xIkT4MaNG2DMmDHg5MmT0P2N6AGR5Crp00muBw8ePAArV65E7eZsW1sb2LZtW08/KpJcJQ15WZ2TYcOGobaqKJNcTyLJGej3Se7s7ASrV69+7f2FCxfWbYxIcgb6bZLLW1sbNmwAly5dAkOGDEGtL1IPIskZ6HdJLhO8a9cusGfPHjB8+HBw5MgRMGLEiLqNGUnOQL9JctnnKB+7Xb9+PWoJLh+cmTFjRt3HjiRnoE/3Lsray6u11tZWsGLFiu59Ll68CFatWgXOnz+P2iqivENShwRH76JK+nSSy5VC+SjtuXPnwJIlS7q3HT16FDx79gxs2rQJLF++HEyfPr1e5USSq6RPJ7nk0aNHqD0M3tHRYdGiReDChQvg2LFjqHXd4ucMTUZTJLlBiCRXSUjOQEjOQO7eRd1P6X2BSHIGQnIGQnIGQnIGQnIGQnIGQnIGQnIGQnIGQnIGQnIGQnIGQnIGQnIGQnIGQnIGQnIGQnIGQnIGQnIGQnIGQnIGQnIG/gJ1IWB63UAZ4gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_ds.show_at(3);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TfmdDL -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _DataLoader__getattr(self,k):\n",
    "    try: return getattr(self.dataset, k)\n",
    "    except AttributeError: raise AttributeError(k) from None\n",
    "DataLoader.__getattr__ = _DataLoader__getattr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@docs\n",
    "class TfmdDL(GetAttr):\n",
    "    \"Transformed `DataLoader` using a `Pipeline` of `tfm`\"\n",
    "    _xtra = 'batch_size num_workers dataset sampler pin_memory'.split()\n",
    "    \n",
    "    def __init__(self, dataset, tfms=None, bs=16, is_tuple=True, shuffle=False,\n",
    "                 sampler=None, batch_sampler=None, num_workers=1, **kwargs):\n",
    "        tfm = Pipeline(tfms)\n",
    "        if is_tuple: tfm.set_tupled()\n",
    "        self.dl = DataLoader(dataset, bs, shuffle, sampler, batch_sampler, num_workers=num_workers)\n",
    "        self.default,self.tfm = self.dl,tfm\n",
    "        for k,v in kwargs.items(): setattr(self,k,v)\n",
    "        tfm.setup(self)\n",
    "        if len(tfm.tfms) > 0 and hasattr(self.dataset, 'tfm'): \n",
    "            tfm.tfms[0].assoc = getattr(self.dataset.tfm,'assoc',None)\n",
    "    \n",
    "    def __len__(self): return len(self.dl)\n",
    "    def __iter__(self): return map(self.tfm, self.dl)\n",
    "    def one_batch(self): return next(iter(self))\n",
    "    def decode(self, b): return getattr(self.dataset,'decode_batch',noop)(self.tfm.decode(b))\n",
    "\n",
    "    def show_batch(self, b=None, max_rows=1000, ctxs=None, **kwargs):\n",
    "        \"Show `b` (defaults to `one_batch`), a list of lists of pipeline outputs (i.e. output of a `DataLoader`)\"\n",
    "        if b is None: b=self.one_batch()\n",
    "        b = self.tfm.decode(b)\n",
    "        rows = itertools.islice(zip(*L(b)), max_rows)\n",
    "        if ctxs is None: ctxs = [None] * len(b[0] if is_iter(b[0]) else b)\n",
    "        for o,ctx in zip(rows,ctxs): self.dataset.show(o, ctx=ctx)\n",
    "\n",
    "    _docs = dict(decode=\"Decode `b` using `ds_tfm` and `tfm`\",\n",
    "                 show_batch=\"Show each item of `b`\",\n",
    "                 one_batch=\"Grab first batch of `dl`\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfm = Transform(torch.neg,decodes=torch.neg)\n",
    "dummy_tfm = Transform(noop,assoc=Item)\n",
    "start = range(50)\n",
    "tl = TfmdList(start, dummy_tfm)\n",
    "tdl = TfmdDL(tl, tfm, is_tuple=False, bs=4)\n",
    "test_eq(start, tdl.dataset)\n",
    "test_eq(len(tdl), (len(tl)-1)//4+1)\n",
    "test_eq(tdl.batch_size, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"<code>TfmdDL.one_batch</code>\" class=\"doc_header\"><code>TfmdDL.one_batch</code><a href=\"https://nbviewer.jupyter.org/github/fastai/fastai_docs/blob/master/dev/04_data_core.ipynb#TfmdDL--\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>TfmdDL.one_batch</code>()\n",
       "\n",
       "Grab first batch of `dl`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(TfmdDL.one_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = tdl.one_batch()\n",
    "test_eq([0,-1,-2,-3], b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"<code>TfmdDL.decode</code>\" class=\"doc_header\"><code>TfmdDL.decode</code><a href=\"https://nbviewer.jupyter.org/github/fastai/fastai_docs/blob/master/dev/04_data_core.ipynb#TfmdDL--\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>TfmdDL.decode</code>(**`b`**)\n",
       "\n",
       "Decode `b` using `ds_tfm` and `tfm`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(TfmdDL.decode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(tdl.decode(b), [[0,1,2,3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"<code>TfmdDL.show_batch</code>\" class=\"doc_header\"><code>TfmdDL.show_batch</code><a href=\"https://nbviewer.jupyter.org/github/fastai/fastai_docs/blob/master/dev/04_data_core.ipynb#TfmdDL--\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>TfmdDL.show_batch</code>(**`b`**=*`None`*, **`max_rows`**=*`1000`*, **`ctxs`**=*`None`*, **\\*\\*`kwargs`**)\n",
       "\n",
       "Show each item of `b`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(TfmdDL.show_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_stdout(tdl.show_batch, \"\"\"(tensor(0),)\n",
    "(tensor(1),)\n",
    "(tensor(2),)\n",
    "(tensor(3),)\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cuda -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@docs\n",
    "class Cuda(Transform):\n",
    "    \"Move batch to `device` (defaults to `defaults.device`)\"\n",
    "    def __init__(self,device=defaults.device):\n",
    "        super().__init__(is_tuple=False)\n",
    "        self.device=device\n",
    "        \n",
    "    def encodes(self, b): return to_device(b, self.device)\n",
    "    def decodes(self, b): return to_cpu(b)\n",
    "    \n",
    "    _docs=dict(encodes=\"Move batch to `device`\", decodes=\"Return batch to CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfm = Cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"<code>Cuda.encodes</code>\" class=\"doc_header\"><code>Cuda.encodes</code><a href=\"https://nbviewer.jupyter.org/github/fastai/fastai_docs/blob/master/dev/04_data_core.ipynb#Cuda--\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>Cuda.encodes</code>(**`b`**)\n",
       "\n",
       "Move batch to [`device`](https://pytorch.org/docs/stable/tensor_attributes.html#torch-device)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Cuda.encodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that, like all `Transform`s, `encodes` is called by `tfm()` and `decodes` is called by `tfm.decode()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = tfm(tensor(1))\n",
    "test_eq(t,1)\n",
    "test_eq(t.type(),'torch.cuda.LongTensor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"<code>Cuda.decodes</code>\" class=\"doc_header\"><code>Cuda.decodes</code><a href=\"https://nbviewer.jupyter.org/github/fastai/fastai_docs/blob/master/dev/04_data_core.ipynb#Cuda--\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>Cuda.decodes</code>(**`b`**)\n",
       "\n",
       "Return batch to CPU"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Cuda.decodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = tfm.decode(t)\n",
    "test_eq(t,1)\n",
    "test_eq(t.type(),'torch.LongTensor')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ByteToFloatTensor -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@docs\n",
    "class ByteToFloatTensor(Transform):\n",
    "    \"Transform image to float tensor, optionally dividing by 255 (e.g. for images).\"\n",
    "    order=20 #Need to run after CUDA if on the GPU\n",
    "    def __init__(self, div=True, mask=None, is_tuple=None):\n",
    "        super().__init__(mask=mask,is_tuple=is_tuple)\n",
    "        self.div = div\n",
    "\n",
    "    def encodes(self, o): return o.float().div_(255.) if self.div else o.float()\n",
    "    def decodes(self, o): return o.clamp(0., 1.) if self.div else o\n",
    "    \n",
    "    _docs=dict(encodes=\"Convert items matching `mask` to float and optionally divide by 255\",\n",
    "               decodes=\"Clamp to (0,1) items matching `mask`\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = (tensor(1),tensor(2))\n",
    "tfm = ByteToFloatTensor(is_tuple=True)\n",
    "ft = tfm(t)\n",
    "test_eq([1./255, 2], ft)\n",
    "test_eq(ft[0].type(),'torch.FloatTensor')\n",
    "test_eq(ft[1].type(),'torch.LongTensor')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@docs\n",
    "class Normalize(Transform):\n",
    "    \"Normalize/denorm batch\"\n",
    "    order=99\n",
    "    def __init__(self, mean, std, mask=None, is_tuple=None):\n",
    "        super().__init__(mask=mask,is_tuple=is_tuple)\n",
    "        self.mean,self.std = mean,std\n",
    "    \n",
    "    def encodes(self, x): return (x-self.mean) / self.std\n",
    "    def decodes(self, x):    return (x*self.std ) + self.mean\n",
    "    \n",
    "    _docs=dict(encodes=\"Normalize batch matching `mask`\", decodes=\"Denormalize batch matching `mask`\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def broadcast_vec(dim, ndim, *t, cuda=True):\n",
    "    \"Make a vector broadcastable over `dim` (out of `ndim` total) by prepending and appending unit axes\"\n",
    "    v = [1]*ndim\n",
    "    v[dim] = -1\n",
    "    f = to_device if cuda else noop\n",
    "    return [f(tensor(o).view(*v)) for o in t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean,std = [0.5]*3,[0.5]*3\n",
    "mean,std = broadcast_vec(1, 4, mean, std)\n",
    "dl_tfms = [Cuda(), ByteToFloatTensor(), Normalize(mean,std)]\n",
    "tdl = TfmdDL(train_ds, dl_tfms, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y  = tdl.one_batch()\n",
    "xd,yd = tdl.decode((x,y))\n",
    "xd = xd.stack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(x.type(), 'torch.cuda.FloatTensor')\n",
    "test_eq(xd.type(), 'torch.FloatTensor')\n",
    "assert x.mean()<0.0\n",
    "assert x.std()>0.5\n",
    "assert 0<xd.mean()<1\n",
    "assert 0<xd.std()<0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAEICAYAAAB/KknhAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAEWlJREFUeJzt3Xuwj9UawPFn5RK1scnJXbpgk+kUM2UXOsQ+TbowkpNmJFGoTJpRfzCjGV2GpKYxSbqNmuSWGtIYJUSlhmKKkEK5zLhMhTDJe/44ndV6Fnv329vvsvfv+X5mzsyz5tl+7zp+nt619nrftVySJALAlrNy3QEA2UfhAwZR+IBBFD5gEIUPGEThAwZR+IBBFH6KnHNvOOf2OOd+dc5tcc4NzXWfkH5WvmfHAzypcc5dKiLfJUly3DlXJCLLRaR3kiRrc9szpJOV75k7foqSJPkmSZLj/2/++b+Lc9glZICV75nCLwfn3PPOud9E5FsR2SMii3PcJWSAhe+ZoX45OeeqiUixiPxLRCYmSfJ7bnuETMj375k7fjklSfJHkiSrRKS5iIzIdX+QGfn+PVP4FVdd8nDuh1Pk5fdM4afAOXe+c+4/zrkC51w159y/ReR2EVmW674hfSx9z8zxU+Cc+4eIzBORf8r//mO5Q0SeS5JkRk47hrSy9D1T+IBBDPUBgyh8wCAKHzCIwgcMqp7Niznn+E1iJZEkicvUZ/M9Vx6lfc/c8QGDKHzAIAofMIjCBwyi8AGDKHzAIAofMIjCBwyi8AGDKHzAIAofMIjCBwyi8AGDsvp2HlBVXHTRRap94YUXqnaLFi18fOWVV6pc7dq1fbx7926Vmz59uo937tx5xv2sKO74gEEUPmAQhQ8YlNXttdmZpfKwugNPYWGhj4cMGaJy999/v48bNGigcnXr1k3L9X/88UcfX3/99Sq3adOmtFwjxA48ADwKHzCI5bw069Chg48feOABlevYsaOPO3XqpHKrV6/28dChQ1Vu8+bN6eyiaa+//rqPe/funfXrh8uA/fr1U7nHHnssa/3gjg8YROEDBlH4gEEs55VT9er61yKjRo1S7QkTJvi4Vq1aKX+uc3+tusRzvwULFpSniymxupxXUlLi41mzZpX6c99++61qL1q0SLXXr1/v4yVLlqhc+F0uXrxY5Xr16nXazxARufzyy0vtT0WxnAfAo/ABg1jOO40rrrhCtcOhd58+fVSuXbt2qh0O88ozjdq+fbuPDx48mPKfQ/msWLHCx507d1a5I0eO+Dh+q648GjVq5OOePXuqXPhvYvny5RW+xpnijg8YROEDBlH4gEFm5/jxUtsjjzzi4/Hjx6tcWXP177//XrUnT57s48cff1zl6tevX+rnhEtC4TwU6XX8+HEfb926NS2fWadOHdVeuXJlSn8ul7/L4Y4PGEThAwaZGuoXFBT4OH5qKt5MMRQu0U2dOlXlnnzySdWeOXOmj+PNHEIjRoxQ7XATRlR+7du39/Frr72mcq1bty71z4VPAM6YMSPt/UoVd3zAIAofMIjCBwwyNcd/+OGHfdyqVSuVC5fspk2bpnKTJk3ycbVq1VTuww8/VO2ioiIf//bbbyo3bNgwH8+bNy/FXiMX4u/5rrvuUu1x48b5uGXLlqV+Tvx2Xrgr0549e86ki2eEOz5gEIUPGGRqqB8uwYRvYomITJkyxcePPvqoyoXLM/GmGG3btlXtX375xcfDhw9XudmzZ5evw0i7evXq+Th+cy7UvXt31R45cmSpP3v48GHVDp/CfPDBB1Vu165dKfUz07jjAwZR+IBBFD5gkKnNNst6lDJ8U6tJkyYqt3HjRh//3Rlq3bp183F4SEZlk8+bbYZLcfEmmV27dvXxOeeck5brhYd0iIjceeedafncdGCzTQAehQ8YZGqoX5YuXbr4uKyNFOL91sOn8UQq9/A+lM9D/fCtyPBYahGR2rVrp/168RN4/fv39/Enn3yS9uuVB0N9AB6FDxhE4QMGmZ3jh+eUi+jHLJs1a6Zyc+fO9XH8OO9PP/2U/s5lQT7P8UPhJqoiesekH374QeXef/99Hy9btkzl4rf1nnnmGR83bdpU5U6cOOHjmjVrlrPH6cUcH4BH4QMGUfiAQWbn+PHrtOFjufFrlrfeequPly5dmtmOZYmVOX6NGjVUOzz84tixYyoX75gUCndaFhEZNWqUj8P5fmzs2LGqHe/KnGnM8QF4FD5gkNmhfnFxsWqvWrXKx/GwbseOHT4eM2aMylXVTTOtDPUrKv43cNVVV6l2WY/injx50sfxv7MvvvgiDb1LHUN9AB6FDxhE4QMGmZ3jx8JDM8P5vsipO/KEqurhl7ma45eUlKh2hw4dfBzudJwLHTt29PHAgQNV7qGHHkr5c8JDNIcMGXLG/ToTzPEBeBQ+YBBD/dOIN9T8/PPPfRxv2Bkv5w0YMCBzHUujXA31N2zYoNrhISf79u1TucmTJ/t44cKFKnfo0CEfl3UGXfym5XXXXefjyy67TOXuu+8+H5999tmlfmZszpw5qh1OC3bv3p3y52QCQ30AHoUPGEThAwaZOjQzVfXr11ftWrVqlfqz7dq1y3R38kr8dmO4nNeoUSOVe+qpp04bi4gcOHDAx+FhKLH4Lcz4u03V119/rdrz58/38RNPPKFyv//+e4WukU3c8QGDKHzAIJbz/hQ+uTdx4kSV69evn4+PHj2qcn379lXtqrJRR2V5O69Pnz4+js+gL+v8+kzYv3+/j9evX69y4VKfiMiWLVuy0qczxXIeAI/CBwyi8AGDTM3xCwoKfNyjRw+VC+fxgwYNUrnw7yg+NDP+nL17955xP7OhsszxQ/F59UVFRT7u3bu3yvXq1cvH8WO5oXiJsHr1v1aw49/HhIelrF279u87XAUwxwfgUfiAQXk31C8sLPRxvKd5+OZcWcPDeKPF8M2wO+64Q+XiPfiriso41M+ESy+9VLXDpzDzZThfFob6ADwKHzCIwgcMqvJz/Pi8+sGDB/u4ZcuWKhf+fw0PPRARWbNmjY/DnV9E9Bz/jz/+qGhXKxUrc3zrmOMD8Ch8wKAqvxFHvJzWokWLUn82XL6ZNWuWypV11DGQb7jjAwZR+IBBFD5gUJVfzkPFsJxnA8t5ADwKHzCIwgcMovABgyh8wCAKHzAoq8t5ACoH7viAQRQ+YBCFDxhE4QMGUfiAQRR+ipxzbzjn9jjnfnXObXHODc11n5B+Vr5nlvNS5Jy7VES+S5LkuHOuSESWi0jvJEny/1QGQ6x8z9zxU5QkyTdJkhz/f/PP/12cwy4hA6x8zxR+OTjnnnfO/SYi34rIHhFZnOMuIQMsfM8M9cvJOVdNRIpF5F8iMjFJkt9z2yNkQr5/z9zxyylJkj+SJFklIs1FZESu+4PMyPfvmcKvuOqSh3M/nCIvv2cKPwXOufOdc/9xzhU456o55/4tIreLyLJc9w3pY+l7Zo6fAufcP0Rknoj8U/73H8sdIvJckiQzctoxpJWl75nCBwxiqA8YROEDBlH4gEEUPmBQVo/J5milyoMjtGzgCC0AHoUPGEThAwZR+IBBFD5gEIUPGEThAwZR+IBBFD5gEIUPGEThAwZR+IBBFD5gEIUPGEThAwZR+IBBFD5gEIUPGEThAwZR+IBBWd1s05omTZqo9p49e3LUk/xWt25d1R41apSPS0pKVK5Lly6lfo5zf+1LGZ8wNXr0aNV+8cUXfXz06NHUO1tJcMcHDKLwAYMofMCgrJ6Wmw8HLTRv3ly1i4uLVTucCzZu3FjlyprjlzW/DM2ePVu1n3vuudI7W4aqfqBGOFdfsGCByjVo0CClz/j5559Vu7CwMOXrv/rqqz4eOnRoyn8u2zhQA4BH4QMGMdRPQbgst2TJEpVr3769aqc6ZI+l+udWrlyp2j169Ej5GqGqNtTv1q2bas+dO9fHDRs2VLn169f7ePny5Sq3atUqH2/evFnl2rZt6+NLLrlE5caPH6/atWrV8vHtt9+ucnPmzDml/7nCUB+AR+EDBlH4gEHM8U/jlltuUe2JEyf6OH4Mt6CgQLXffPNNHz///PMqF84vJ0yYoHLhHPLkyZOl9m3FihWqnc9z/HDJbv78+SoXzuvvuecelXvjjTd8fPz48XR0Rb755hvVLioq8vGmTZtUrkOHDmm5ZjowxwfgUfiAQbyddxrh0F5ED727du2qcm3atFHt6tVL/ysNp1XxlCG8RlnTr3iKkM8GDRrk47PO0veoPn36+Hjp0qUql67hfao++OCDrF4vHbjjAwZR+IBBFD5gEHP80wjfvBIROffcc328YcMGlYvbrVu39vHVV1+tclu2bPHxlClTVO7mm2/2cd++fUvt29q1a0vN5bNt27ap9sKFCzN6vVatWql2/fr1S/3Z/fv3Z7QvmcAdHzCIwgcMYqh/Gp999plqd+zY0cfDhg1TuXHjxql2uFHGiBEjVK527do+Pnz4sMqFmznE17fqxIkTPg6fesyUFi1a+DheNm3UqJFqh8uvTz/9dGY7lgHc8QGDKHzAIAofMMjsHD+cb4uIfPfddz6OH6ctzxuMr7zyio/DJToRvTHmrl27VC5uQ2TkyJFn/Bnnn3++aoc7Hd14440q16tXLx/379+/zM996aWXfFynTh2VqwoHbHDHBwyi8AGDzG7E0axZM9X+8ssvfXzeeeepXLo2zfzoo498PGDAAJU7ePBgytdIh6qwEUdF9ezZ08fvvfeeypX19mRFhcuOIiJDhgzx8bp161Ru586dPj5y5Eja+xJjIw4AHoUPGEThAwaZXc4bOHCgasebZqYqnsN16tSp1J/t3r27j+PlRKTP1q1bfbxjxw6Vu/jii0/7cyIiL7zwgo/D5V0Rkbvvvlu1w98DxW9hzpw5s9S+hQeBxId0xAd8ZBJ3fMAgCh8wiMIHDDK7jh/PscPHNeNdbpo2berj8BVdkVPPvA/Pai/r7/aCCy5Q7Ww/spvP6/ih5s2bq3b49x7uiCQism/fvgpd49prr1Xt0aNH+zj+nU/4b+nAgQMqFz4mHB+cUlGs4wPwKHzAoCox1K9Xr55qh+eRh5tbiuih9+TJkytyuVPUrFnTx/EUYePGjaodvtkXH+wQ7iITb6gZ78iTaVaG+rkWDu1FRN566y0fX3PNNSo3Y8YMHw8fPjwt12eoD8Cj8AGDKHzAoCrxyO60adNU+7bbbvPx22+/rXJjx4494+uVlJSo9pgxY3wcLw/Fu6+GvzNZtGiRyv3dri7IP7t371btSZMm+fjdd9/Ndnc87viAQRQ+YFCVGOrHu9WEw+mvvvpK5cIdcGLFxcU+jofs4YEW4Q4u8fVi8Q4v4Rlr9957b6l/DjaEh3SIlH34xurVqzPdHY87PmAQhQ8YROEDBlWJR3anT5+u2vFuKKG9e/f6ODzYUETPv8vaASf+PUG4JBM+cily6uGK4TWz/RhuefDIbuZUq1bNx/Pnz1e5m266ycfxwRvt27f3cbgb75ngkV0AHoUPGFQllvM+/vhj1Q6X3mLh23HxkD3VZbmFCxeqXPjWFBA76yx9/xw3bpyPw6G9iJ7+xVPWdA3vU8EdHzCIwgcMovABg6rEHH/79u2q/emnn5b6s+Ecv1WrVip36NAhH8dv9YVnsR87dqwCvYQl4SPfw4YNU7lwjh8v6Ya/n5o3b16Gevf3uOMDBlH4gEFV4sm98mjcuLGP46H+r7/+6uN4k0xrrDy5Fy/pTp061cfbtm1TuSlTppT6OfHmLM8++6yP27Ztq3LhE3mDBw9WuWwP73lyD4BH4QMGUfiAQXk3x0dqrMzxwzflRETWrVvn43huHi4Tx78b6Ny5s2rXqFHDxy+//LLKLV682MfvvPNOOXucXszxAXgUPmAQQ32jrAz1Yw0bNvTxsmXLVK6wsNDHa9asUbk2bdqo9g033ODjbB9xXh4M9QF4FD5gEIUPGMQc3yirc3xrmOMD8Ch8wCAKHzCIwgcMovABgyh8wKCsLucBqBy44wMGUfiAQRQ+YBCFDxhE4QMGUfiAQRQ+YBCFDxhE4QMGUfiAQRQ+YBCFDxhE4QMGUfiAQRQ+YBCFDxhE4QMGUfiAQRQ+YBCFDxhE4QMGUfiAQRQ+YNB/Aa26jIdem2SBAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 288x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "_,axs = plt.subplots(2,2, figsize=(4,4))\n",
    "tdl.show_batch((x,y), ctxs=axs.flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataBunch -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@docs\n",
    "class DataBunch(GetAttr):\n",
    "    \"Basic wrapper around several `DataLoader`s.\"\n",
    "    _xtra = 'one_batch show_batch dataset'.split()\n",
    "\n",
    "    def __init__(self, *dls): self.dls,self.default = dls,dls[0]\n",
    "    def __getitem__(self, i): return self.dls[i]\n",
    "\n",
    "    train_dl,valid_dl = add_props(lambda i,x: x[i])\n",
    "    train_ds,valid_ds = add_props(lambda i,x: x[i].dataset)\n",
    "    \n",
    "    _docs=dict(__getitem__=\"Retrieve `DataLoader` at `i` (`0` is training, `1` is validation)\",\n",
    "              train_dl=\"Training `DataLoader`\",\n",
    "              valid_dl=\"Validation `DataLoader`\",\n",
    "              train_ds=\"Training `Dataset`\",\n",
    "              valid_ds=\"Validation `Dataset`\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbch = DataBunch(tdl,tdl)\n",
    "x,y  = dbch.train_dl.one_batch()\n",
    "x2,y2 = next(iter(tdl))\n",
    "test_eq(x,x2)\n",
    "x2,y2 = dbch.one_batch()\n",
    "test_eq(x,x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"<code>DataBunch.__getitem__</code>\" class=\"doc_header\"><code>DataBunch.__getitem__</code><a href=\"https://nbviewer.jupyter.org/github/fastai/fastai_docs/blob/master/dev/04_data_core.ipynb#DataBunch--\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>DataBunch.__getitem__</code>(**`i`**)\n",
       "\n",
       "Retrieve [`DataLoader`](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader) at `i` (`0` is training, `1` is validation)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(DataBunch.__getitem__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2,y2 = dbch[0].one_batch()\n",
    "test_eq(x,x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"<code>train_dl</code>\" class=\"doc_header\"><code>train_dl</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "Training [`DataLoader`](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(DataBunch.train_dl, name=\"train_dl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"<code>valid_dl</code>\" class=\"doc_header\"><code>valid_dl</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "Validation [`DataLoader`](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(DataBunch.valid_dl, name=\"valid_dl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"<code>train_ds</code>\" class=\"doc_header\"><code>train_ds</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "Training `Dataset`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(DataBunch.train_ds, name=\"train_ds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"<code>valid_ds</code>\" class=\"doc_header\"><code>valid_ds</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "Validation `Dataset`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(DataBunch.valid_ds, name=\"valid_ds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_test.ipynb.\n",
      "Converted 01_core.ipynb.\n",
      "Converted 02_data_pipeline.ipynb.\n",
      "Converted 03_data_external.ipynb.\n",
      "Converted 04_data_core.ipynb.\n",
      "Converted 05_data_source.ipynb.\n",
      "Converted 06_vision_core.ipynb.\n",
      "Converted 07_pets_tutorial-Copy1.ipynb.\n",
      "Converted 07_pets_tutorial.ipynb.\n",
      "Converted 08_augmentation.ipynb.\n",
      "Converted 10_layers.ipynb.\n",
      "Converted 11_optimizer.ipynb.\n",
      "Converted 12_learner.ipynb.\n",
      "Converted 13_callback_schedule.ipynb.\n",
      "Converted 14_callback_hook.ipynb.\n",
      "Converted 15_callback_progress.ipynb.\n",
      "Converted 16_callback_tracker.ipynb.\n",
      "Converted 17_callback_fp16.ipynb.\n",
      "Converted 90_notebook_core.ipynb.\n",
      "Converted 91_notebook_export.ipynb.\n",
      "Converted 92_notebook_showdoc.ipynb.\n",
      "Converted 93_notebook_export2html.ipynb.\n",
      "Converted 94_index.ipynb.\n",
      "Converted 95_synth_learner.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from local.notebook.export import notebook2script\n",
    "notebook2script(all_fs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
