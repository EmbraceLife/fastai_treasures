{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp data.pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from local.imports import *\n",
    "from local.test import *\n",
    "from local.core import *\n",
    "from local.notebook.showdoc import show_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "torch.cuda.set_device(int(os.environ.get('DEFAULT_GPU') or 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transforms and Pipeline\n",
    "\n",
    "> Low-level transform pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classes here provide functionality for creating *partially reversible functions*, which we call `Transform`s. By \"partially reversible\" we mean that a transform can be `decode`d, creating a form suitable for display. This is not necessarily identical to the original form (e.g. a transform that changes a byte tensor to a float tensor does not recreate a byte tensor when decoded, since that may lose precision, and a float tensor can be displayed already.)\n",
    "\n",
    "Classes are also provided and for composing transforms, and mapping them over collections. The following functionality is provided:\n",
    "\n",
    "- A `Transform` is created with an `encodes` and potentially `decodes` function. \n",
    "- `Pipeline` is a transform which composes transforms\n",
    "- `TfmdList` takes a collection and a transform, and provides an indexer (`__getitem__`) which dynamically applies the transform to the collection items.\n",
    "- `Tuplify` is a special `Trannsform` that takes a list of list of transforms or a list of `Pipeline`s, then aapplies them to the element it receives to return a tuple."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convenience functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_func(t, name, *args, **kwargs):\n",
    "    \"Get the `t.name` (potentially partial-ized with `args` and `kwargs`) or `noop` if not defined\"\n",
    "    f = getattr(t, name, noop)\n",
    "    return f if not (args or kwargs) else partial(f, *args, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This works for any kind of `t` supporting `getattr`, so a class or a module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(get_func(operator, 'neg', 2)(), -2)\n",
    "test_eq(get_func(operator.neg, '__call__')(2), -2)\n",
    "test_eq(get_func(list, 'foobar')([2]), [2])\n",
    "t = get_func(torch, 'zeros', dtype=torch.int64)(5)\n",
    "test_eq(t.dtype, torch.int64)\n",
    "a = [2,1]\n",
    "get_func(list, 'sort')(a)\n",
    "test_eq(a, [1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def show_title(o, ax=None, ctx=None):\n",
    "    \"Set title of `ax` to `o`, or print `o` if `ax` is `None`\"\n",
    "    ax = ifnone(ax,ctx)\n",
    "    if ax is None: print(o)\n",
    "    else: ax.set_title(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_stdout(lambda: show_title(\"title\"), \"title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Func -"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tranforms, are built with multiple-dispatch: a given function can have several methods depending on the type of the object received. This is done directly with the `multimethod` module and type-annotation in `Transofrm`, but you can also use the following class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Func():\n",
    "    \"Basic wrapper around a `name` with `args` and `kwargs` to call on a given type\"\n",
    "    def __init__(self, name, *args, **kwargs): self.name,self.args,self.kwargs = name,args,kwargs\n",
    "    def __repr__(self): return f'sig: {self.name}({self.args}, {self.kwargs})'\n",
    "    def _get(self, t): return get_func(t, self.name, *self.args, **self.kwargs)\n",
    "    def __call__(self,t): return L(t).mapped(self._get) if is_listy(t) else self._get(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can call the `Func` object on any module name or type, even a list of types. It will return the corresponding function (with a default to `noop` if nothing is found) or list of functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(Func('sqrt')(math), math.sqrt)\n",
    "test_eq(Func('sqrt')(torch), torch.sqrt)\n",
    "\n",
    "@patch\n",
    "def powx(x:math, a): return math.pow(x,a)\n",
    "@patch\n",
    "def powx(x:torch, a): return torch.pow(x,a)\n",
    "tst = Func('powx',a=2)([math, torch])\n",
    "test_eq([f.func for f in tst], [math.powx, torch.powx])\n",
    "for t in tst: test_eq(t.keywords, {'a': 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class _Sig():\n",
    "    def __getattr__(self,k):\n",
    "        def _inner(*args, **kwargs): return Func(k, *args, **kwargs)\n",
    "        return _inner\n",
    "\n",
    "Sig = _Sig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"<code>Sig</code>\" class=\"doc_header\"><code>Sig</code><a href=\"https://github.com/fastai/fastai_docs/tree/master/dev/__main__.py#L4\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>Sig</code>(**\\*`args`**, **\\*\\*`kwargs`**)\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Sig, name=\"Sig\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Sig` is just sugar-syntax to create a `Func` object more easily with the syntax `Sig.name(*args, **kwargs)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = Sig.sqrt()\n",
    "test_eq(f(math), math.sqrt)\n",
    "test_eq(f(torch), torch.sqrt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class SelfFunc():\n",
    "    \"Search for `name` attribute and call it with `args` and `kwargs` on any object it's passed.\"\n",
    "    def __init__(self, nm, *args, **kwargs): self.nm,self.args,self.kwargs = nm,args,kwargs\n",
    "    def __repr__(self): return f'self: {self.nm}({self.args}, {self.kwargs})'\n",
    "    def __call__(self, o):\n",
    "        if not is_listy(o): return getattr(o,self.nm)(*self.args, **self.kwargs)\n",
    "        else: return [getattr(o_,self.nm)(*self.args, **self.kwargs) for o_ in o]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The difference between `Func` and `SelfFunc` is that `Func` will generate a function when you call it on a type. On the other hand, `SelfFunc` is already a function and each time you call it on an object it looks for the `name` attribute and call it on `args` and `kwargs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst = SelfFunc('sqrt')\n",
    "x = torch.tensor([4.])\n",
    "test_eq(tst(x), torch.tensor([2.]))\n",
    "assert isinstance(tst(x), Tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class _SelfFunc():\n",
    "    def __getattr__(self,k):\n",
    "        def _inner(*args, **kwargs): return SelfFunc(k, *args, **kwargs)\n",
    "        return _inner\n",
    "    \n",
    "Self = _SelfFunc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"<code>Self</code>\" class=\"doc_header\"><code>Self</code><a href=\"https://github.com/fastai/fastai_docs/tree/master/dev/__main__.py#L4\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>Self</code>(**\\*`args`**, **\\*\\*`kwargs`**)\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Self, name=\"Self\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Self` is just syntax sugar to create a `SelfFunc` object more easily with the syntax `Self.name(*args, **kwargs)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = Self.sqrt()\n",
    "x = torch.tensor([4.])\n",
    "test_eq(f(x), torch.tensor([2.]))\n",
    "assert isinstance(f(x), Tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def positional_annotations(f):\n",
    "    \"Get list of annotated types for all positional params, or None if no annotation\"\n",
    "    sig = inspect.signature(f)\n",
    "    return [p.annotation if p.annotation != inspect._empty else None \n",
    "            for p in sig.parameters.values() if p.default == inspect._empty and p.kind != inspect._VAR_KEYWORD]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(x, y:float): return x+y\n",
    "def f2(a, b=2): return a\n",
    "def f3(a:int, b:float=2): return a\n",
    "test_eq(positional_annotations(f1), [None, float])\n",
    "test_eq(positional_annotations(f2), [None])\n",
    "test_eq(positional_annotations(f3), [int])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from multimethod import multimeta,DispatchError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _get_ret(func):\n",
    "    \"Get the return annotation of `func`\"\n",
    "    ann = getattr(func,'__annotations__', None)\n",
    "    if not ann: return None\n",
    "    typ = ann.get('return')\n",
    "    return list(typ.__args__) if getattr(typ, '_name', '')=='Tuple' else typ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "def f1(x) -> float: return x\n",
    "test_eq(_get_ret(f1), float)\n",
    "def f2(x) -> Tuple[float,float]: return x\n",
    "test_eq(_get_ret(f2), [float,float])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def noop_tfm(x,*args,**kwargs): return (x,*args) if len(args) > 0 else x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(noop_tfm(1), 1)\n",
    "test_eq(noop_tfm(1,2,3), (1,2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class PrePostInitMultiMeta(multimeta):\n",
    "    \"Like `PrePostInit` but inherits `multimeta`\"\n",
    "    def __new__(cls, name, bases, dct):\n",
    "        x = super().__new__(cls, name, bases, dct)\n",
    "        def _pass(self, *args,**kwargs): pass\n",
    "        for o in ('__init__', '__pre_init__', '__post_init__'):\n",
    "            if not hasattr(x,o): setattr(x,o,_pass)\n",
    "        old_init = x.__init__\n",
    "        \n",
    "        @functools.wraps(old_init)\n",
    "        def _init(self,*args,**kwargs):\n",
    "            self.__pre_init__()\n",
    "            old_init(self, *args,**kwargs)\n",
    "            self.__post_init__()\n",
    "        setattr(x, '__init__', _init)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Transform(metaclass=PrePostInitMultiMeta):\n",
    "    \"A function that `encodes` if `filt` matches, and optionally `decodes`\"\n",
    "    order,add_before_setup,filt,t,state_args = 0,False,None,None,None\n",
    "    def __init__(self,encodes=None,decodes=None):\n",
    "        self.encodes = getattr(self, 'encodes', noop_tfm) if encodes is None else encodes \n",
    "        self.decodes = getattr(self, 'decodes', noop_tfm) if decodes is None else decodes\n",
    "        self.t = None\n",
    "        \n",
    "    def __post_init__(self):\n",
    "        self.encodes = getattr(self, 'encodes', noop_tfm) \n",
    "        self.decodes = getattr(self, 'decodes', noop_tfm)\n",
    "    \n",
    "    def _apply(self, fs, x, filt):\n",
    "        if self.filt is not None and self.filt!=filt: return x\n",
    "        if self.t: \n",
    "            gs = self._get_func(fs, self.t)\n",
    "            if is_listy(self.t) and len(positional_annotations(gs)) != len(self.t):\n",
    "                gs = [self._get_func(fs,t_) for t_ in self.t]\n",
    "                if len(gs) == 1: gs = gs[0]\n",
    "        else: gs=fs\n",
    "        if is_listy(gs): return tuple(f(x_) for f,x_ in zip(gs,x))\n",
    "        return gs(*L(x)) if is_listy(self.t) else gs(x)\n",
    "\n",
    "    def _get_func(self,f,t,ret_partial=True):\n",
    "        if not hasattr(f,'__func__'): return f\n",
    "        idx = (object,) + tuple(t) if is_listy(t) else (object,t)\n",
    "        try: f = f.__func__[idx]\n",
    "        except DispatchError: return noop_tfm\n",
    "        return partial(f,self) if ret_partial else f\n",
    "    \n",
    "    def accept_types(self, t): self.t = t\n",
    "        # We can't create encodes/decodes here since patching might change things later\n",
    "        # So we call _get_func in _apply instead\n",
    "        \n",
    "    def return_type(self):\n",
    "        g = self._get_func(self.encodes, self.t, False)\n",
    "        if is_listy(self.t) and len(positional_annotations(g))-1 != len(self.t):\n",
    "            return [_get_ret(self._get_func(self.encodes,t_,False)) or t_ for t_ in self.t]\n",
    "        return _get_ret(g) or self.t\n",
    "\n",
    "    def __call__(self, x, filt=None): return self._apply(self.encodes, x, filt)\n",
    "    def decode  (self, x, filt=None): return self._apply(self.decodes, x, filt)\n",
    "    def __getitem__(self, x): return self(x) # So it can be used as a `Dataset`\n",
    "\n",
    "add_docs(Transform,\n",
    "         __call__=\"Dispatch and apply the proper encodes to `x` if `filt` matches\",\n",
    "         decode=\"Dispatch and apply the proper decodes to `x` if `filt` matches\",\n",
    "         accept_types=\"Indicate the type of input received by the transform is `t`\",\n",
    "         return_type=\"Indicate the type of output the tranform returns, depending on `self.t`\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a transformation pipeline some steps need to be reversible - for instance, if you turn a string (such as *dog*) into an int (such as *1*) for modeling, then for display purposes you'll want to turn it back to a string again (e.g. when you have a prediction). In addition, you may wish to only run the transformation for a particular data subset, such as the training set.\n",
    "\n",
    "`Transform` provides all this functionality. `filt` is some dataset index (e.g. provided by `DataSource`), and you provide `encodes` and optional `decodes` functions for your code. You can pass `encodes` and `decodes` functions directly to the constructor for quickly creating simple transforms. You can also create several `encodes` or `decodes` methods for different types of objects with proper type annotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfm = Transform(operator.neg, decodes=operator.neg)\n",
    "start = 4\n",
    "t = tfm(start)\n",
    "test_eq(t, -4)\n",
    "test_eq(t, tfm[start]) #You can use a transform as a dataset\n",
    "test_eq(tfm.decode(t), start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dummy_tfm(x:float,y:float): return [x+y,y]\n",
    "tfm = Transform(dummy_tfm)\n",
    "tfm.accept_types([float,float])\n",
    "test_eq(tfm((2,3)), (5,3))\n",
    "#tfm.accept_types([int,float]) Fails for now and needs a class with encodes\n",
    "#test_eq(tfm((2,3)), (2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _FiltAddOne(Transform):\n",
    "    filt=1\n",
    "    def encodes(self, x): return x+1\n",
    "    def decodes(self, x): return x-1\n",
    "\n",
    "addt = _FiltAddOne()\n",
    "test_eq(addt(start,filt=1), start+1)\n",
    "test_eq(addt(start,filt=0), start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _DummyTfm(Transform):\n",
    "    def __init__(self): pass #Pass init so that decodes isn't defined\n",
    "    def encodes(self, x): return x+1\n",
    "\n",
    "dt = _DummyTfm()\n",
    "t = dt(start)\n",
    "test_eq(t, start+1)\n",
    "test_eq(dt.decode(t), t) #Decodes was still set at post init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"<code>Transform.__call__</code>\" class=\"doc_header\"><code>Transform.__call__</code><a href=\"https://nbviewer.jupyter.org/github/fastai/fastai_docs/blob/master/dev/02_data_pipeline.ipynb#Transform--\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>Transform.__call__</code>(**`x`**, **`filt`**=*`None`*)\n",
       "\n",
       "Dispatch and apply the proper encodes to `x` if `filt` matches"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Transform.__call__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"<code>Transform.decode</code>\" class=\"doc_header\"><code>Transform.decode</code><a href=\"https://nbviewer.jupyter.org/github/fastai/fastai_docs/blob/master/dev/02_data_pipeline.ipynb#Transform--\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>Transform.decode</code>(**`x`**, **`filt`**=*`None`*)\n",
       "\n",
       "Dispatch and apply the proper decodes to `x` if `filt` matches"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Transform.decode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"<code>Transform.accept_types</code>\" class=\"doc_header\"><code>Transform.accept_types</code><a href=\"https://nbviewer.jupyter.org/github/fastai/fastai_docs/blob/master/dev/02_data_pipeline.ipynb#Transform--\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>Transform.accept_types</code>(**`t`**)\n",
       "\n",
       "Indicate the type of input received by the transform is `t`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Transform.accept_types)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At some point in the data-collection pipeline, your objects will be tuples (usually input,label). There are then different behaviors you might want your `Transform` to adopt such as:\n",
    "- being applied to the tuple and returning a new tuple (example: PointScaler takes image and a list of points, as it needs the image size to scale the points)\n",
    "- being applied to each part of the tuple (example: Cuda needs to be applied to each part of the tensor)\n",
    "- being applied to some parts of the tuple but not all, and even have different behavior depending on the type of those parts (example: data augmentation transforms should not be applied on labels, and have different behavior on images vs masks vs points vs bboxes)\n",
    "\n",
    "You can control which behavior will be used with the signature of your `encodes` function. If it accepts several arguments (without defaults), then the transform will be applied on the tuple and expected to return a tuple. If your `encodes` function only accepts one argument, it will be applied on every part of the tuple. You can even control which part of the tuples with a type annotation: the tranform will only be applied to the items in the tuple that correspond to that type.\n",
    "\n",
    "All of this is enabled the method `accept_types` that is called in the setup of a `Pipeline` (so out of the blue your transform object won't have this behavior). The `Pipeline` will analyze the type of objects (as given by the return annotation of any transform) and pass them along, wich tells the transform it will receive a given type (or a tuple of given types)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply on the tuple as a whole\n",
    "class _Add(Transform):\n",
    "    def encodes(self, x, y): return (x+y,y)\n",
    "    def decodes(self, x, y): return (x-y,y)\n",
    "\n",
    "addt = _Add()\n",
    "addt.accept_types([float,float])\n",
    "t = addt((1,2))\n",
    "test_eq(t, (3,2))\n",
    "test_eq(addt.decode(t), (1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply on all part of the tuple\n",
    "class _AddOne(Transform):\n",
    "    def encodes(self, x): return x+1\n",
    "    def decodes(self, x): return x-1\n",
    "\n",
    "addt = _AddOne()\n",
    "addt.accept_types([float,float])\n",
    "t = addt((1,2))\n",
    "test_eq(t, (2,3))\n",
    "test_eq(addt.decode(t), (1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply on all integers of the tuple\n",
    "#Also note that your tuples can have more than two elements\n",
    "class _AddOne(Transform):\n",
    "    def encodes(self, x:numbers.Integral): return x+1\n",
    "    def encodes(self, x:float): return x*2\n",
    "    def decodes(self, x:numbers.Integral): return x-1\n",
    "\n",
    "addt = _AddOne()\n",
    "addt.accept_types(float)\n",
    "start = 1\n",
    "t = addt(start)\n",
    "test_eq(t, 2)\n",
    "test_eq(addt.decode(t), 2)\n",
    "\n",
    "addt.accept_types([float, int, float])\n",
    "start = (1,2,3)\n",
    "t = addt(start)\n",
    "test_eq(t, (2,3,6))\n",
    "test_eq(addt.decode(t), (2,2,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def transform(cls):\n",
    "    \"Decorator for registering a new `encodes` or `decodes` function in a tranform `cls`\"\n",
    "    def _inner(f):\n",
    "        if   f.__name__=='encodes': cls.encodes.register(f)\n",
    "        elif f.__name__=='decodes': cls.decodes.register(f)\n",
    "        else: raise Exception('Function must be \"encodes\" or \"decodes\"')\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@transform(_AddOne)\n",
    "def decodes(self, x:float): return x/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = addt(start)\n",
    "test_eq(t, (2,3,6))\n",
    "test_eq(addt.decode(t), start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#test that addt pickles correctly\n",
    "addt1 = pickle.loads(pickle.dumps(addt))\n",
    "t = addt(start)\n",
    "test_eq(t, (2,3,6))\n",
    "test_eq(addt.decode(t), start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"<code>Transform.return_type</code>\" class=\"doc_header\"><code>Transform.return_type</code><a href=\"https://nbviewer.jupyter.org/github/fastai/fastai_docs/blob/master/dev/02_data_pipeline.ipynb#Transform--\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>Transform.return_type</code>()\n",
       "\n",
       "Indicate the type of output the tranform returns, depending on `self.t`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Transform.return_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check type is properly changed at dispatch\n",
    "class _AddOne(Transform):\n",
    "    def encodes(self, x:int)->str: return x+1\n",
    "    def encodes(self, x:float):       return x*2\n",
    "    def decodes(self, x:int):   return x-1\n",
    "    def decodes(self, x:float): return x/2\n",
    "\n",
    "tfm = _AddOne()\n",
    "tfm.accept_types(float)\n",
    "test_eq(tfm.return_type(), float)\n",
    "tfm.accept_types(int)\n",
    "test_eq(tfm.return_type(), str)\n",
    "tfm.accept_types([int,float])\n",
    "test_eq(tfm.return_type(), [str,float])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using supertype encodes/decodes, we have a hacky way, might want to simplify it.\n",
    "class _AddOne(Transform):\n",
    "    def encodes(self, x:numbers.Integral): return x+1\n",
    "    def encodes(self, x:int): return self._get_func(self.encodes, numbers.Integral)(x)*2\n",
    "    def decodes(self, x:numbers.Integral): return x-1\n",
    "    def decodes(self, x:int): return self._get_func(self.decodes, numbers.Integral)(x/2)\n",
    "    \n",
    "tfm = _AddOne()\n",
    "start = 2\n",
    "tfm.accept_types(numbers.Integral)\n",
    "t = tfm(start)\n",
    "test_eq(t, 3)\n",
    "test_eq(tfm.decode(t), start)\n",
    "tfm.accept_types(int)\n",
    "t = tfm(start)\n",
    "test_eq(t, 6)\n",
    "test_eq(tfm.decode(t), start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def compose_tfms(x, tfms, func_nm='__call__', reverse=False, **kwargs):\n",
    "    \"Apply all `func_nm` attribute of `tfms` on `x`, maybe in `reverse` order\"\n",
    "    if reverse: tfms = reversed(tfms)\n",
    "    for tfm in tfms: x = getattr(tfm,func_nm,noop)(x, **kwargs)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _AddOne(Transform):\n",
    "    def encodes(self, x): return x+1\n",
    "    def decodes(self, x): return x-1\n",
    "    \n",
    "tfms = [_AddOne(), Transform(torch.sqrt)]\n",
    "t = compose_tfms(tensor([3.]), tfms)\n",
    "test_eq(t, tensor([2.]))\n",
    "test_eq(compose_tfms(t, tfms, 'decodes'), tensor([1.]))\n",
    "test_eq(compose_tfms(tensor([4.]), tfms, reverse=True), tensor([3.]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _get_ret(func):\n",
    "    \"Get the return annotation of `func`\"\n",
    "    ann = getattr(func,'__annotations__', None)\n",
    "    if not ann: return None\n",
    "    typ = ann.get('return')\n",
    "    return list(typ.__args__) if getattr(typ, '_name', '')=='Tuple' else typ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "def f1(x) -> float: return x\n",
    "test_eq(_get_ret(f1), float)\n",
    "def f2(x) -> Tuple[float,float]: return x\n",
    "test_eq(_get_ret(f2), [float,float])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Pipeline():\n",
    "    \"A pipeline of composed (for encode/decode) transforms, setup with types\"\n",
    "    def __init__(self, funcs=None, t=None): \n",
    "        if isinstance(funcs, Pipeline): funcs = funcs.raws\n",
    "        self.raws,self.fs,self.t_show = L(funcs),[],None\n",
    "        if len(self.raws) == 0: self.final_t = t\n",
    "        else:\n",
    "            for i,f in enumerate(self.raws.sorted(key='order')):\n",
    "                if not isinstance(f,Transform): f = Transform(f)\n",
    "                f.accept_types(t)\n",
    "                self.fs.append(f)\n",
    "                if self.t_show is None and hasattr(t, 'show'): self.t_idx,self.t_show = i,t\n",
    "                t = f.return_type()\n",
    "            if self.t_show is None and hasattr(t, 'show'): self.t_idx,self.t_show = i+1,t\n",
    "            self.final_t = t\n",
    "    \n",
    "    def new(self, t=None): return Pipeline(self, t)\n",
    "    def __repr__(self): return f\"Pipeline over {self.fs}\"\n",
    "    \n",
    "    def setup(self, items=None):\n",
    "        tfms,raws,self.fs,self.raws = self.fs,self.raws,[],[]\n",
    "        for t,r in zip(tfms,raws.sorted(key='order')):\n",
    "            if t.add_before_setup:     self.fs.append(t) ; self.raws.append(r)\n",
    "            if hasattr(t, 'setup'):    t.setup(items)\n",
    "            if not t.add_before_setup: self.fs.append(t) ; self.raws.append(r)\n",
    "                \n",
    "    def __call__(self, o, filt=None): return compose_tfms(o, self.fs, filt=filt)\n",
    "    def decode  (self, i, filt=None): return compose_tfms(i, self.fs, func_nm='decode', reverse=True, filt=filt)\n",
    "    #def __getitem__(self, x): return self(x)\n",
    "    #def decode_at(self, idx): return self.decode(self[idx])\n",
    "    #def show_at(self, idx):   return self.show(self[idx])\n",
    "    \n",
    "    def show(self, o, ctx=None, filt=None, **kwargs):\n",
    "        if self.t_show is None: return self.decode(o, filt=filt)\n",
    "        o = compose_tfms(o, self.fs[self.t_idx:], func_nm='decode', reverse=True, filt=filt)\n",
    "        return self.t_show.show(o, ctx=ctx, **kwargs)\n",
    "\n",
    "add_docs(Pipeline,\n",
    "         __call__=\"Compose `__call__` of all `tfms` on `o`\",\n",
    "         decode=\"Compose `decode` of all `tfms` on `i`\",\n",
    "         new=\"Create a new `Pipeline`with the same `tfms` and a new initial `t`\",\n",
    "         show=\"Show item `o`\",\n",
    "         setup=\"Go through the transforms in order and call their potential setup on `items`\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A list of transforms are often applied in a particular order, and decoded by applying in the reverse order. `Pipeline` provides this functionality, and also ensures during its initialization that each transform get the proper functions according to the type of the previous transform. If any transform provides a type with a return annotation, this type is passed along to the next tranforms (until being overwritten by a new return annotation). Such a type can be useful when transforms filter depending on a given type (usually for data augmentation) or to provide a show method.\n",
    "\n",
    "Here's some simple examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empty pipeline is noop\n",
    "pipe = Pipeline()\n",
    "test_eq(pipe(1), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check a standard pipeline\n",
    "class String():\n",
    "    @staticmethod\n",
    "    def show(o, ctx=None, **kwargs): return show_title(str(o), ctx=ctx)\n",
    "    \n",
    "class floatTfm(Transform):\n",
    "    def encodes(self, x): return float(x)\n",
    "    def decodes(self, x): return int(x)\n",
    "\n",
    "float_tfm=floatTfm()\n",
    "def neg(x) -> String: return -x\n",
    "neg_tfm = Transform(neg, neg)\n",
    "    \n",
    "pipe = Pipeline([neg_tfm, float_tfm])\n",
    "\n",
    "start = 2\n",
    "t = pipe(2)\n",
    "test_eq(t, -2.0)\n",
    "test_eq(type(t), float)\n",
    "#test_eq(t, pipe[2])\n",
    "test_eq(pipe.decode(t), start)\n",
    "#show decodes up to the point of the first transform that introduced the type that shows, not included\n",
    "test_stdout(lambda:pipe.show(t), '-2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check opposite order\n",
    "pipe = Pipeline([float_tfm,neg_tfm])\n",
    "t = pipe(2)\n",
    "test_eq(t, -2.0)\n",
    "# `show` comes from String on the last transform so nothing is decoded\n",
    "test_stdout(lambda:pipe.show(t), '-2.0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check filtering is properly applied\n",
    "pipe = Pipeline([neg_tfm, float_tfm, _FiltAddOne()])\n",
    "start = 2\n",
    "test_eq(pipe(start), -2)\n",
    "test_eq(pipe(start, filt=1), -1)\n",
    "test_eq(pipe(start, filt=0), -2)\n",
    "for t in [None, 0, 1]: test_eq(pipe.decode(pipe(start, filt=t), filt=t), start)\n",
    "for t in [None, 0, 1]: test_stdout(lambda: pipe.show(pipe(start, filt=t), filt=t), \"-2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check type is properly changed at dispatch\n",
    "class _AddOne(Transform):\n",
    "    def encodes(self, x:int)->String: return x+1\n",
    "    def encodes(self, x:float):       return x*2\n",
    "    def decodes(self, x:int):   return x-1\n",
    "    def decodes(self, x:float): return x/2\n",
    "\n",
    "pipe = Pipeline(_AddOne(), t=int)\n",
    "test_eq(pipe.final_t, String)\n",
    "pipe = Pipeline(_AddOne(), t=float)\n",
    "test_eq(pipe.final_t, float)\n",
    "pipe = Pipeline(_AddOne(), t=[int,float])\n",
    "test_eq(pipe.final_t, [String,float])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"<code>Pipeline.__call__</code>\" class=\"doc_header\"><code>Pipeline.__call__</code><a href=\"https://nbviewer.jupyter.org/github/fastai/fastai_docs/blob/master/dev/02_data_pipeline.ipynb#Pipeline--\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>Pipeline.__call__</code>(**`o`**, **`filt`**=*`None`*)\n",
       "\n",
       "Compose `__call__` of all `tfms` on `o`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Pipeline.__call__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"<code>Pipeline.decode</code>\" class=\"doc_header\"><code>Pipeline.decode</code><a href=\"https://nbviewer.jupyter.org/github/fastai/fastai_docs/blob/master/dev/02_data_pipeline.ipynb#Pipeline--\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>Pipeline.decode</code>(**`i`**, **`filt`**=*`None`*)\n",
       "\n",
       "Compose `decode` of all `tfms` on `i`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Pipeline.decode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"<code>Pipeline.new</code>\" class=\"doc_header\"><code>Pipeline.new</code><a href=\"https://nbviewer.jupyter.org/github/fastai/fastai_docs/blob/master/dev/02_data_pipeline.ipynb#Pipeline--\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>Pipeline.new</code>(**`t`**=*`None`*)\n",
       "\n",
       "Create a new [`Pipeline`](/data.pipeline.html#Pipeline)with the same `tfms` and a new initial `t`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Pipeline.new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"<code>Pipeline.setup</code>\" class=\"doc_header\"><code>Pipeline.setup</code><a href=\"https://nbviewer.jupyter.org/github/fastai/fastai_docs/blob/master/dev/02_data_pipeline.ipynb#Pipeline--\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>Pipeline.setup</code>(**`items`**=*`None`*)\n",
       "\n",
       "Go through the transforms in order and call their potential setup on `items`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Pipeline.setup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During the setup, the `Pipeline` starts with no transform and adds them one at a time, so that during its setup, each transfrom get the items processed up to its point and not after. Depending on the attribute `add_before_setup`, the transform is added after the setup (default behaivor) so it's not called on the items used for the setup, or before (in which case it's called on the values used for setup)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#Test is below with TfmdList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TfmedList -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_samples(b, max_rows):\n",
    "    if isinstance(b, Tensor): return b[:max_rows]\n",
    "    return zip(*L(get_samples(b_, max_rows) if not isinstance(b,Tensor) else b_[:max_rows] for b_ in b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@docs\n",
    "class TfmdList(GetAttr):\n",
    "    \"A `Pipeline` of `tfms` applied to a collection of `items`\"\n",
    "    _xtra = 'decode __call__ show'.split()\n",
    "    \n",
    "    def __init__(self, items, tfms, do_setup=True):\n",
    "        self.items = L(items)\n",
    "        self.default = self.tfms = Pipeline(tfms)\n",
    "        if do_setup: self.setup()\n",
    "\n",
    "    def __getitem__(self, i, filt=None):\n",
    "        \"Transformed item(s) at `i`\"\n",
    "        its = self.items[i]\n",
    "        if is_iter(i):\n",
    "            if not is_iter(filt): filt = L(filt for _ in i)\n",
    "            return L(self.tfms(it, filt=f) for it,f in zip(its,filt))\n",
    "        return self.tfms(its, filt=filt)\n",
    "    \n",
    "    def setup(self): self.tfms.setup(self)\n",
    "    def subset(self, idxs): return self.__class__(self.items[idxs], self.tfms, do_setup=False)\n",
    "    def decode_at(self, idx, filt=None): \n",
    "        return self.decode(self.__getitem__(idx,filt=filt), filt=filt)\n",
    "    def show_at(self, idx, filt=None, **kwargs): \n",
    "        return self.show(self.__getitem__(idx,filt=filt), filt=filt, **kwargs)\n",
    "    def __eq__(self, b): return all_equal(self, b)\n",
    "    def __len__(self): return len(self.items)\n",
    "    def __iter__(self): return (self[i] for i in range_of(self))\n",
    "    def __repr__(self): return f\"{self.__class__.__name__}: {self.items}\\ntfms - {self.tfms}\"\n",
    "    \n",
    "    _docs = dict(setup=\"Transform setup with self\",\n",
    "                 decode_at=\"Decoded item at `idx`\",\n",
    "                 show_at=\"Show item at `idx`\",\n",
    "                 subset=\"New `TfmdList` that only includes items at `idxs`\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tfms` can either be a `Pipeline` or a list of transforms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfmdList: (#3) [1,2,3]\n",
       "tfms - Pipeline over [<__main__.Transform object at 0x7f1b460956a0>, <__main__.floatTfm object at 0x7f1b46095208>]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tl = TfmdList([1,2,3], [neg_tfm, float_tfm])\n",
    "t = tl[1]\n",
    "test_eq(t, -2.0)\n",
    "test_eq(type(t), float)\n",
    "test_eq(tl.decode_at(1), 2)\n",
    "test_eq(tl.decode(t), 2)\n",
    "test_stdout(lambda: tl.show_at(2), '-3')\n",
    "tl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p2 = tl.subset([0,2])\n",
    "test_eq(p2, [-1.,-3.])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's how we can use `TfmdList.setup` to implement a simple category list, getting labels from a mock file list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfmdList: (#5) [dog_0.jpg,cat_0.jpg,cat_2.jpg,cat_1.jpg,dog_1.jpg]\n",
       "tfms - Pipeline over [<__main__.Transform object at 0x7f1b3e438c18>, <__main__._Cat object at 0x7f1b3e438a90>]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class _Cat(Transform):\n",
    "    order = 1\n",
    "    def __init__(self, subset_idx=None): self.subset_idx = subset_idx\n",
    "    def encodes(self, o): return self.o2i[o]\n",
    "    def decodes(self, o): return self.vocab[o]\n",
    "    def setup(self, items): \n",
    "        if self.subset_idx is not None: items = items.subset(self.subset_idx)\n",
    "        self.vocab,self.o2i = uniqueify(items, sort=True, bidir=True)\n",
    "\n",
    "def _lbl(o) -> String: return o.split('_')[0]\n",
    "\n",
    "test_fns = ['dog_0.jpg','cat_0.jpg','cat_2.jpg','cat_1.jpg','dog_1.jpg']\n",
    "tcat = _Cat()\n",
    "tl = TfmdList(test_fns, [tcat,_lbl])\n",
    "\n",
    "test_eq(tcat.vocab, ['cat','dog'])\n",
    "test_eq([1,0,0,0,1], tl)\n",
    "test_eq(1, tl[-1])\n",
    "test_eq([1,0], tl[0,1])\n",
    "t = list(tl)\n",
    "test_eq([1,0,0,0,1], t)\n",
    "test_eq(['dog','cat','cat','cat','dog'], map(tl.decode,t))\n",
    "test_stdout(lambda:tl.show_at(0), \"dog\")\n",
    "tl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tcat = _Cat([0,1,2])\n",
    "tl = TfmdList(test_fns, [tcat,_lbl])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#Test of add_before_setup\n",
    "class _AddSome(Transform):\n",
    "    def __init__(self):   self.a = 2\n",
    "    def encodes(self, x): return x+self.a\n",
    "    def decodes(self, x): return x-self.a\n",
    "    def setup(self, items): self.a = tensor(items).float().mean().item()\n",
    "        \n",
    "tl1 = TfmdList([1,2,3,4], _AddSome())\n",
    "test_eq(tl1.tfms.fs[0].a, 2.5) #Setup on the raw items, mean is 2.5\n",
    "\n",
    "_AddSome.add_before_setup = True\n",
    "tl1 = TfmdList([1,2,3,4], _AddSome())\n",
    "test_eq(tl1.tfms.fs[0].a, 4.5) #Setup on the tfmed items, mean is 4.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#Check filtering is properly applied\n",
    "tl1 = TfmdList([1,2,3,4], [neg_tfm, float_tfm, _FiltAddOne()])\n",
    "test_eq(tl1[2], -3)\n",
    "test_eq(tl1.__getitem__(2, filt=1), -2)\n",
    "test_eq(tl1.__getitem__(2, filt=0), -3)\n",
    "test_eq(tl1.__getitem__([2,2], filt=[0,1]), [-3,-2])\n",
    "for t in [None, 0, 1]: test_eq(tl1.decode(tl1.__getitem__(1, filt=t), filt=t), 2)\n",
    "for t in [None, 0, 1]: test_eq(tl1.decode_at(1, filt=t), 2)\n",
    "for t in [None, 0, 1]: test_stdout(lambda: tl1.show_at(1, filt=t), \"-2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"<code>TfmdList.__getitem__</code>\" class=\"doc_header\"><code>TfmdList.__getitem__</code><a href=\"https://nbviewer.jupyter.org/github/fastai/fastai_docs/blob/master/dev/02_data_pipeline.ipynb#TfmedList--\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>TfmdList.__getitem__</code>(**`i`**, **`filt`**=*`None`*)\n",
       "\n",
       "Transformed item(s) at `i`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(TfmdList.__getitem__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"<code>TfmdList.decode_at</code>\" class=\"doc_header\"><code>TfmdList.decode_at</code><a href=\"https://nbviewer.jupyter.org/github/fastai/fastai_docs/blob/master/dev/02_data_pipeline.ipynb#TfmedList--\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>TfmdList.decode_at</code>(**`idx`**, **`filt`**=*`None`*)\n",
       "\n",
       "Decoded item at `idx`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(TfmdList.decode_at)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(tl.decode_at(1),tl.decode(tl[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"<code>TfmdList.show_at</code>\" class=\"doc_header\"><code>TfmdList.show_at</code><a href=\"https://nbviewer.jupyter.org/github/fastai/fastai_docs/blob/master/dev/02_data_pipeline.ipynb#TfmedList--\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>TfmdList.show_at</code>(**`idx`**, **`filt`**=*`None`*, **\\*\\*`kwargs`**)\n",
       "\n",
       "Show item at `idx`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(TfmdList.show_at)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_stdout(lambda: tl.show_at(1), 'cat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"<code>TfmdList.subset</code>\" class=\"doc_header\"><code>TfmdList.subset</code><a href=\"https://nbviewer.jupyter.org/github/fastai/fastai_docs/blob/master/dev/02_data_pipeline.ipynb#TfmedList--\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>TfmdList.subset</code>(**`idxs`**)\n",
       "\n",
       "New [`TfmdList`](/data.pipeline.html#TfmdList) that only includes items at `idxs`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(TfmdList.subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TfmdDS -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exports\n",
    "def _maybe_flat(t): return t[0] if len(t) == 1 else tuple(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class TfmdDS(TfmdList):\n",
    "    def __init__(self, items, tfms=None, tuple_tfms=None, do_setup=True):\n",
    "        if tfms is None: tfms = [None]\n",
    "        self.tfmd_its = [TfmdList(items, t, do_setup=do_setup) for t in tfms]\n",
    "        self.__post_init__(items, tuple_tfms, do_setup)\n",
    "    \n",
    "    def __post_init__(self, items, tuple_tfms, do_setup):\n",
    "        #To avoid dupe code with DataSource\n",
    "        self.items = items\n",
    "        self.tfms = [it.tfms for it in self.tfmd_its]\n",
    "        self.tuple_tfms = Pipeline(tuple_tfms, t=[it.tfms.final_t for it in self.tfmd_its])\n",
    "        if do_setup: self.setup()\n",
    "        \n",
    "    def __getitem__(self, i, filt=None):\n",
    "        its = _maybe_flat([it.__getitem__(i, filt=filt) for it in self.tfmd_its])\n",
    "        if is_iter(i): \n",
    "            if len(self.tfmd_its) > 1: its = zip(*L(its))\n",
    "            if not is_iter(filt): filt = L(filt for _ in i)\n",
    "            return L(self.tuple_tfms(it, filt=f) for it,f in zip(its,filt))\n",
    "        return self.tuple_tfms(its, filt=filt)\n",
    "\n",
    "    def __getattr__(self,k):\n",
    "        for p in self.tfms+[self.tuple_tfms]:\n",
    "            for f in p.fs:\n",
    "                if k in L(f.state_args): return getattr(f, k)\n",
    "        super().__getattr__(k)\n",
    "        \n",
    "    def __setstate__(self,data): self.__dict__.update(data) #For pickle issues\n",
    "        \n",
    "    def decode(self, o, filt=None):\n",
    "        o = self.tuple_tfms.decode(o, filt=filt)\n",
    "        if not is_iter(o): o = [o]\n",
    "        return _maybe_flat([it.decode(o_, filt=filt) for o_,it in zip(o,self.tfmd_its)])\n",
    "    \n",
    "    def decode_batch(self, b, filt=None): return [self.decode(b_, filt=filt) for b_ in get_samples(b)]\n",
    "    \n",
    "    def show(self, o, ctx=None, filt=None, **kwargs):\n",
    "        if self.tuple_tfms.t_show is not None: return self.tuple_tfms.show(o, ctx=ctx, filt=filt, **kwargs)\n",
    "        o = self.tuple_tfms.decode(o, filt=filt)\n",
    "        if not is_iter(o): o = [o]\n",
    "        for o_,it in zip(o,self.tfmd_its): ctx = it.show(o_, ctx=ctx, filt=filt, **kwargs)\n",
    "        return ctx\n",
    "    \n",
    "    def setup(self): self.tuple_tfms.setup(self)\n",
    "        \n",
    "    def subset(self, idxs): \n",
    "        return self.__class__(self.items[idxs], self.tfms, self.tuple_tfms, do_setup=False)\n",
    "    \n",
    "    def __repr__(self): \n",
    "        return f\"{self.__class__.__name__}: {self.items}\\ntfms - {self.tfms}\\ntuple tfms - {self.tuple_tfms}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "add_docs(TfmdDS,\n",
    "         \"A `Dataset` created from raw `items` by calling each element of `tfms` on them\",\n",
    "         __getitem__=\"Call all `tfms` on `items[i]` then all `tuple_tfms` on the result\",\n",
    "         decode=\"Compose `decode` of all `tuple_tfms` then all `tfms` on `i`\",\n",
    "         decode_batch=\"`decode` all sample in a the batch `b`\",\n",
    "         show=\"Show item `o` in `ctx`\",\n",
    "         setup=\"Go through the transforms in order and call their potential setup on `items`\",\n",
    "         subset=\"New `TfmdDS` that only includes items at `idxs`\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tfms` is a list of objects that can be:\n",
    "- one transform\n",
    "- a list of transforms\n",
    "- a `Pipeline`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _TNorm(Transform):\n",
    "    state_args = ['m', 's']\n",
    "    def encodes(self, o): return (o-self.m)/self.s\n",
    "    def decodes(self, o): return (o*self.s)+self.m\n",
    "    def setup(self, items):\n",
    "        its = tensor(items).float()\n",
    "        self.m,self.s = its.mean(),its.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = [1,2,3,4]\n",
    "#If you pass only a list with one list of tfms/Pipeline, TfmdDS behaves like TfmOver\n",
    "tds = TfmdDS(items, [neg_tfm])\n",
    "test_eq(tds[0], -1)\n",
    "test_eq(tds[[0,1,2]], [-1,-2,-3])\n",
    "test_eq(tds.decode_at(0), 1)\n",
    "test_stdout(lambda:tds.show_at(1), '-2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = [1,2,3,4]\n",
    "tds = TfmdDS(items, [neg_tfm, [neg_tfm,_TNorm()]])\n",
    "x,y = zip(*tds)\n",
    "test_close(tensor(y).mean(), 0)\n",
    "test_close(tensor(y).std(), 1)\n",
    "test_eq(x, [-1,-2,-3,-4])\n",
    "test_stdout(lambda:tds.show_at(1), '-2\\ntensor(-2.)')\n",
    "test_eq(tds.m, tds.tfms[1].fs[1].m)\n",
    "test_eq(tds.s, tds.tfms[1].fs[1].s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#Test if show at the tuple level interrupts decoding\n",
    "class DoubleString():\n",
    "    @staticmethod\n",
    "    def show(o, ctx=None, **kwargs): print(o[0],o[1])\n",
    "\n",
    "class _DummyTfm(Transform):\n",
    "    def encodes(self, x,y)->DoubleString: return [x,y]\n",
    "\n",
    "items = [1,2,3,4]\n",
    "tds = TfmdDS(items, [neg_tfm, neg_tfm], _DummyTfm())\n",
    "test_stdout(lambda: tds.show_at(0), \"-1 -1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#Check filtering is properly applied\n",
    "tds = TfmdDS(items, [neg_tfm, [neg_tfm,_FiltAddOne()]])\n",
    "test_eq(tds[1], [-2,-2])\n",
    "test_eq(tds.__getitem__(1, filt=1), [-2,-1])\n",
    "test_eq(tds.__getitem__(1, filt=0), [-2,-2])\n",
    "test_eq(tds.__getitem__([1,1], filt=[0,1]), [[-2,-2], [-2,-1]])\n",
    "for t in [None, 0, 1]: test_eq(tds.decode(tds.__getitem__(1, filt=t), filt=t), [2,2])\n",
    "for t in [None, 0, 1]: test_eq(tds.decode_at(1, filt=t), [2,2])\n",
    "for t in [None, 0, 1]: test_stdout(lambda: tds.show_at(1, filt=t), \"-2\\n-2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#2) [(#2) [-2,-2],(#2) [-2,-1]]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tds.__getitem__([1,1], filt=[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"<code>TfmdDS.__getitem__</code>\" class=\"doc_header\"><code>TfmdDS.__getitem__</code><a href=\"https://nbviewer.jupyter.org/github/fastai/fastai_docs/blob/master/dev/02_data_pipeline.ipynb#TfmdDS--\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>TfmdDS.__getitem__</code>(**`i`**, **`filt`**=*`None`*)\n",
       "\n",
       "Call all `tfms` on `items[i]` then all `tuple_tfms` on the result"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(TfmdDS.__getitem__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"<code>TfmdDS.decode</code>\" class=\"doc_header\"><code>TfmdDS.decode</code><a href=\"https://nbviewer.jupyter.org/github/fastai/fastai_docs/blob/master/dev/02_data_pipeline.ipynb#TfmdDS--\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>TfmdDS.decode</code>(**`o`**, **`filt`**=*`None`*)\n",
       "\n",
       "Compose `decode` of all `tuple_tfms` then all `tfms` on `i`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(TfmdDS.decode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"<code>TfmdList.decode_at</code>\" class=\"doc_header\"><code>TfmdList.decode_at</code><a href=\"https://nbviewer.jupyter.org/github/fastai/fastai_docs/blob/master/dev/02_data_pipeline.ipynb#TfmedList--\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>TfmdList.decode_at</code>(**`idx`**, **`filt`**=*`None`*)\n",
       "\n",
       "Decoded item at `idx`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(TfmdDS.decode_at)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"<code>TfmdDS.show</code>\" class=\"doc_header\"><code>TfmdDS.show</code><a href=\"https://nbviewer.jupyter.org/github/fastai/fastai_docs/blob/master/dev/02_data_pipeline.ipynb#TfmdDS--\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>TfmdDS.show</code>(**`o`**, **`ctx`**=*`None`*, **`filt`**=*`None`*, **\\*\\*`kwargs`**)\n",
       "\n",
       "Show item `o` in `ctx`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(TfmdDS.show)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"<code>TfmdList.show_at</code>\" class=\"doc_header\"><code>TfmdList.show_at</code><a href=\"https://nbviewer.jupyter.org/github/fastai/fastai_docs/blob/master/dev/02_data_pipeline.ipynb#TfmedList--\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>TfmdList.show_at</code>(**`idx`**, **`filt`**=*`None`*, **\\*\\*`kwargs`**)\n",
       "\n",
       "Show item at `idx`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(TfmdDS.show_at)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"<code>TfmdDS.setup</code>\" class=\"doc_header\"><code>TfmdDS.setup</code><a href=\"https://nbviewer.jupyter.org/github/fastai/fastai_docs/blob/master/dev/02_data_pipeline.ipynb#TfmdDS--\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>TfmdDS.setup</code>()\n",
       "\n",
       "Go through the transforms in order and call their potential setup on `items`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(TfmdDS.setup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"<code>TfmdDS.subset</code>\" class=\"doc_header\"><code>TfmdDS.subset</code><a href=\"https://nbviewer.jupyter.org/github/fastai/fastai_docs/blob/master/dev/02_data_pipeline.ipynb#TfmdDS--\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>TfmdDS.subset</code>(**`idxs`**)\n",
       "\n",
       "New [`TfmdDS`](/data.pipeline.html#TfmdDS) that only includes items at `idxs`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(TfmdDS.subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_test.ipynb.\n",
      "Converted 01_core.ipynb.\n",
      "Converted 02_data_pipeline.ipynb.\n",
      "Converted 03_data_external.ipynb.\n",
      "Converted 04_data_core.ipynb.\n",
      "Converted 05_data_source.ipynb.\n",
      "Converted 06_vision_core.ipynb.\n",
      "Converted 07_pets_tutorial-meta.ipynb.\n",
      "Converted 07_pets_tutorial.ipynb.\n",
      "Converted 08_vision_augment.ipynb.\n",
      "Converted 10_layers.ipynb.\n",
      "Converted 11_optimizer.ipynb.\n",
      "Converted 12_learner.ipynb.\n",
      "Converted 13_callback_schedule.ipynb.\n",
      "Converted 14_callback_hook.ipynb.\n",
      "Converted 15_callback_progress.ipynb.\n",
      "Converted 16_callback_tracker.ipynb.\n",
      "Converted 17_callback_fp16.ipynb.\n",
      "Converted 90_notebook_core.ipynb.\n",
      "Converted 91_notebook_export.ipynb.\n",
      "Converted 92_notebook_showdoc.ipynb.\n",
      "Converted 93_notebook_export2html.ipynb.\n",
      "Converted 94_index.ipynb.\n",
      "Converted 95_synth_learner.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from local.notebook.export import notebook2script\n",
    "notebook2script(all_fs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
