{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from local.imports import *\n",
    "from local.core import compose\n",
    "from local.notebook.export import *\n",
    "from local.notebook.showdoc import *\n",
    "import nbformat\n",
    "from nbconvert.preprocessors import ExecutePreprocessor, Preprocessor\n",
    "from nbconvert import HTMLExporter\n",
    "from nbformat.sign import NotebookNotary\n",
    "from traitlets.config import Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp notebook.export2html\n",
    "# default_cls_lvl 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting notebooks to html\n",
    "\n",
    "> The functions that transform the dev notebooks in the documentation of the library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cell processors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def remove_widget_state(cell):\n",
    "    \"Remove widgets in the output of `cells`\"\n",
    "    if cell['cell_type'] == 'code' and 'outputs' in cell:\n",
    "        cell['outputs'] = [l for l in cell['outputs'] \n",
    "                           if not ('data' in l and 'application/vnd.jupyter.widget-view+json' in l.data)]\n",
    "    return cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "_re_cell_to_hide = r's*show_doc\\(|^\\s*#\\s*export\\s+'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#hide\n",
    "Matches any cell that has a `show_doc` or an `#export` in it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def hide_cells(cell):\n",
    "    \"Hide `cell` that need to be hidden\"\n",
    "    if check_re(cell, _re_cell_to_hide): \n",
    "        cell['metadata'] = {'hide_input': True}\n",
    "    return cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for source in ['show_doc(read_nb)', '# export\\nfrom local.core import *']:\n",
    "    cell = {'cell_type': 'code', 'source': 'show_doc(read_nb)'}\n",
    "    cell1 = hide_cells(cell.copy())\n",
    "    assert 'metadata' in cell1\n",
    "    assert 'hide_input' in cell1['metadata']\n",
    "    assert cell1['metadata']['hide_input']\n",
    "\n",
    "cell = {'cell_type': 'code', 'source': '# exports\\nfrom local.core import *'}\n",
    "assert hide_cells(cell.copy()) == cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "_re_exports = re.compile(r'^#\\s*exports[^\\n]*\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#hide\n",
    "\n",
    "Matches any line containing an #exports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def clean_exports(cell):\n",
    "    \"Remove exports flag from `cell`\"\n",
    "    cell['source'] = _re_exports.sub('', cell['source'])\n",
    "    return cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell = {'cell_type': 'code', 'source': '# exports\\nfrom local.core import *'}\n",
    "assert clean_exports(cell.copy()) == {'cell_type': 'code', 'source': 'from local.core import *'}\n",
    "cell = {'cell_type': 'code', 'source': '# exports core\\nfrom local.core import *'}\n",
    "assert clean_exports(cell.copy()) == {'cell_type': 'code', 'source': 'from local.core import *'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def treat_backticks(cell):\n",
    "    \"Add links to backticks words in `cell`\"\n",
    "    if cell['cell_type'] == 'markdown': cell['source'] = add_doc_links(cell['source'])\n",
    "    return cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell = {'cell_type': 'markdown', 'source': 'This is a `Tensor`'}\n",
    "assert treat_backticks(cell) == {'cell_type': 'markdown',\n",
    "    'source': 'This is a [`Tensor`](https://pytorch.org/docs/stable/tensors.html#torch-tensor)'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "_re_nb_link = re.compile(r'\\[([^\\]]*)\\]\\(([^http][^\\)]*).ipynb\\)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#hide\n",
    "\n",
    "Catches any link to a local notebook and keeps the title in group 1, the link without .ipynb in group 2\n",
    "```\n",
    "\\[           Opening [\n",
    "([^\\]]*)     Catching group for any character except ]\n",
    "\\]\\(         Closing ]\n",
    "([^http]     Catching group that must not begin by html (local notebook)\n",
    "[^\\)]*)      and containing anything but )\n",
    ".ipynb\\)     .ipynb and closing )\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def convert_links(cell):\n",
    "    \"Convert the .ipynb links to .html\"\n",
    "    if cell['cell_type'] == 'markdown':\n",
    "        cell['source'] = _re_nb_link.sub(r'[\\1](\\2.html)', cell['source'])\n",
    "    return cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell = {'cell_type': 'markdown', 'source': \"This is a link to a [notebook](01_core.ipynb).\"}\n",
    "assert convert_links(cell) == {'cell_type': 'markdown', \n",
    "                               'source': \"This is a link to a [notebook](01_core.html).\"}\n",
    "cell = {'cell_type': 'markdown', 'source': \"This is a link to a [page](01_core.html).\"}\n",
    "assert convert_links(cell.copy()) == cell\n",
    "cell = {'cell_type': 'markdown', 'source': \"This is a link to an [external nb](http://01_core.ipynb).\"}\n",
    "assert convert_links(cell.copy()) == cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "_re_block_notes = re.compile(r'>\\s*([^:]*):\\s*([^\\n]*)(?:\\n|$)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#hide\n",
    "\n",
    "Catches any pattern > Title: content with title in group 1 and content in group 2\n",
    "```\n",
    ">\\s*      > followed by any number of whitespace\n",
    "([^:]*)   Catching group for any character but :\n",
    ":\\s*      : then any number of whitespace\n",
    "([^\\n]*)  Catching group for anything but a new line character\n",
    "(?:\\n|$)  Non-catching group for either a new line or the end of the text\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def add_jekyll_notes(cell):\n",
    "    \"Convert block quotes to jekyll notes in `cell`\"\n",
    "    t2style = {'Note': 'info', 'Warning': 'danger', 'Important': 'warning'}\n",
    "    def _inner(m):\n",
    "        title,text = m.groups()\n",
    "        style = t2style.get(title, None)\n",
    "        if style is None: return f\"> {m.groups()[0]}: m.groups()[1]\"\n",
    "        res = f'<div markdown=\"span\" class=\"alert alert-{style}\" role=\"alert\">'\n",
    "        return res + f'<i class=\"fa fa-{style}-circle\"></i> <b>{title}: </b>{text}</div>'\n",
    "    if cell['cell_type'] == 'markdown':\n",
    "        cell['source'] = _re_block_notes.sub(_inner, cell['source'])\n",
    "    return cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supported styles are `Warning`, `Note` and `Important`:\n",
    "\n",
    "> Warning: There will be no second warning!\n",
    "\n",
    "> Important: Pay attention! This is important.\n",
    "\n",
    "> Note: Take note of this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for w,s in zip(['Warning', 'Note', 'Important', 'Bla'], ['danger', 'info', 'warning', 'info']):\n",
    "    cell = {'cell_type': 'markdown', 'source': f\"> {w}: This is my final {w.lower()}!\"}\n",
    "    res = f'<div markdown=\"span\" class=\"alert alert-{s}\" role=\"alert\">'\n",
    "    res += f'<i class=\"fa fa-{s}-circle\"></i> <b>{w}: </b>This is my final {w.lower()}!</div>'\n",
    "    if w != 'Bla': assert add_jekyll_notes(cell) == {'cell_type': 'markdown', 'source': res}\n",
    "    else: assert add_jekyll_notes(cell) == cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"![pixelshuffle](images/pixelshuffle.png)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('images/pixelshuffle.png',)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.search('^!\\[[^\\]]*\\]\\(([^\\)]*)\\)', text).groups()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "_re_image = re.compile(r'^!\\[[^\\]]*\\]\\(([^\\)]*)\\)|<img src=\"([^\"]*)\"', re.MULTILINE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#hide\n",
    "\n",
    "Catches any image file used, either with `![alt](image_file)` or `<img src=\"image_file\">`\n",
    "```\n",
    "^!\\[          Beginning of line (since re.MULTILINE is passed) followed by ![ \n",
    "[^\\]]*        Anything but ]\n",
    "\\]\\(          Closing ] and opening (\n",
    "([^\\)]*)      Catching block with any character but )\n",
    "\\)            Closing )\n",
    "|           OR\n",
    "<img src=\"    <img src=\"\n",
    "([^\"]*)       Catching block with any character except \" \n",
    "\"             Closing \"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def copy_images(cell, fname, dest):\n",
    "    if cell['cell_type'] == 'markdown' and _re_image.search(cell['source']):\n",
    "        grps = _re_image.search(cell['source']).groups()\n",
    "        src = grps[0] or grps[1]\n",
    "        os.makedirs((Path(dest)/src).parent, exist_ok=True)\n",
    "        shutil.copy(Path(fname).parent/src, Path(dest)/src)\n",
    "    return cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dest_img = Path('docs')/'images'/'pixelshuffle.png' \n",
    "dest_bak = Path('docs')/'images'/'pixelshuffle.bak'\n",
    "if dest_img.exists(): shutil.move(dest_img, dest_bak)\n",
    "for text in ['Text\\n![Alt](images/pixelshuffle.png)', \n",
    "             'Text\\n<img src=\"images/pixelshuffle.png\" alt=\"Pixelshuffle\" style=\"width: 100%; height: auto;\"/>']:\n",
    "    cell = {'cell_type': 'markdown', 'source': text}\n",
    "    cell = copy_images(cell, Path('10_layers.ipynb'), Path('docs'))\n",
    "    #Function doesn't touch cell\n",
    "    assert cell == cell\n",
    "    #Image has been copied\n",
    "    assert dest_img.exists()\n",
    "    os.remove(dest_img)\n",
    "if dest_bak.exists(): shutil.move(dest_bak, dest_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "_re_cell_to_remove = re.compile(r'^\\s*#\\s*(hide|default_exp|default_cls_lvl)\\s+')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#hide\n",
    "Matches any cell with #hide or #default_exp or #default_cls_lvl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def remove_hidden(cells):\n",
    "    \"Remove in `cells` the ones with a flag `#hide` or `#default_exp`\"\n",
    "    return [c for c in cells if _re_cell_to_remove.search(c['source']) is None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cells = [{'cell_type': 'code', 'source': source} for source in [\n",
    "    '# export\\nfrom local.core import *', \n",
    "    '# hide\\nfrom local.core import *',\n",
    "    '#exports\\nsuper code',\n",
    "    '#default_exp notebook.export',\n",
    "    'show_doc(read_nb)',\n",
    "    '#default_cls_lvl 3']] + [{'cell_type': 'markdown', 'source': source} for source in [\n",
    "    'nice', '#hide\\n\\nto hide']]\n",
    "         \n",
    "cells1 = remove_hidden(cells)\n",
    "assert len(cells1) == 4\n",
    "assert cells1[0] == cells[0]\n",
    "assert cells1[1] == cells[2]\n",
    "assert cells1[2] == cells[4]\n",
    "assert cells1[3] == cells[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "_re_default_cls_lvl = re.compile(r'^\\s*#\\s*default_cls_lvl\\s*(\\d*)\\s*$', re.IGNORECASE | re.MULTILINE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#hide\n",
    "\n",
    "Catches a cell with #default_cls_lvl and the number after in group 1\n",
    "```\n",
    "^                  Beginning of line (since re.MULTILINE is passed)\n",
    "\\s*#\\s*            Any number of whitespace, #, any number of whitespace\n",
    "default_cls_lvl    default_cls_lvl\n",
    "\\s*                Any number of whitespace\n",
    "(\\d*)              Catching group for any number of digits\n",
    "\\s*$               Any number of whitespace and end of line (since re.MULTILINE is passed)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def find_default_level(cells):\n",
    "    \"Find in `cells` the default export module.\"\n",
    "    for cell in cells:\n",
    "        tst = check_re(cell, _re_default_cls_lvl)\n",
    "        if tst: return int(tst.groups()[0])\n",
    "    return 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst_nb = read_nb('91_notebook_export.ipynb')\n",
    "assert find_default_level(tst_nb['cells']) == 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "_re_export = re.compile(r'^\\s*#\\s*exports?\\s*', re.IGNORECASE | re.MULTILINE)\n",
    "_re_show_doc = re.compile(r'show_doc\\s*\\(\\s*([^,\\)\\s]*)[,\\)\\s]', re.MULTILINE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#hide\n",
    "\n",
    "First one catches any cell with a #export or #exports, second one catches any show_doc and get the first argument in group 1\n",
    "```\n",
    "show_doc      show_doc \n",
    "\\s*\\(\\s*      Any number of whitespace, opening (, any number of whitespace\n",
    "([^,\\)\\s]*)   Catching group for any character but a comma, a closing ) or a whitespace\n",
    "[,\\)\\s]       A comma, a closing ) or a whitespace\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _show_doc_cell(name, cls_lvl=None):\n",
    "    return {'cell_type': 'code',\n",
    "            'execution_count': None,\n",
    "            'metadata': {},\n",
    "            'outputs': [],\n",
    "            'source': f\"show_doc({name}{'' if cls_lvl is None else f', default_cls_level={cls_lvl}'})\"}\n",
    "\n",
    "def add_show_docs(cells, cls_lvl=None):\n",
    "    \"Add `show_doc` for each exported function or class\"\n",
    "    documented = [_re_show_doc.search(cell['source']).groups()[0] for cell in cells \n",
    "                  if cell['cell_type']=='code' and _re_show_doc.search(cell['source']) is not None]\n",
    "    res = []\n",
    "    for cell in cells:\n",
    "        res.append(cell)\n",
    "        if check_re(cell, _re_export):\n",
    "            names = export_names(cell['source'], func_only=True)\n",
    "            for n in names: \n",
    "                if n not in documented: res.append(_show_doc_cell(n, cls_lvl=cls_lvl))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,cell in enumerate(tst_nb['cells']):\n",
    "    if cell['source'].startswith('#export\\ndef read_nb'): break\n",
    "tst_cells = [c.copy() for c in tst_nb['cells'][i-1:i+1]]\n",
    "added_cells = add_show_docs(tst_cells, cls_lvl=3)\n",
    "assert len(added_cells) == 3\n",
    "assert added_cells[0] == tst_nb['cells'][i-1]\n",
    "assert added_cells[1] == tst_nb['cells'][i]\n",
    "assert added_cells[2] == _show_doc_cell('read_nb', cls_lvl=3)\n",
    "assert added_cells[2]['source'] == 'show_doc(read_nb, default_cls_level=3)'\n",
    "\n",
    "#Check show_doc isn't added if it was already there.\n",
    "tst_cells1 = [{'cell_type':'code', 'source': '#export\\ndef my_func(x):\\n    return x'},\n",
    "              {'cell_type':'code', 'source': 'show_doc(my_func)'}]\n",
    "assert add_show_docs(tst_cells1) == tst_cells1\n",
    "tst_cells1 = [{'cell_type':'code', 'source': '#export\\ndef my_func(x):\\n    return x'},\n",
    "              {'cell_type':'markdown', 'source': 'Some text'},\n",
    "              {'cell_type':'code', 'source': 'show_doc(my_func, title_level=3)'}]\n",
    "assert add_show_docs(tst_cells1) == tst_cells1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "_re_fake_header = re.compile(r'#+\\s+.*-\\s*$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#hide\n",
    "\n",
    "Matches any fake header (one that ends with -)\n",
    "```\n",
    "#+     One or more #\n",
    "\\s+    One or more of whitespace\n",
    ".*     Any char\n",
    "-\\s*   A dash followed by any number of white space\n",
    "$      End of text\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def remove_fake_headers(cells):\n",
    "    \"Remove in `cells` the fake header\"\n",
    "    return [c for c in cells if c['cell_type']=='code' or _re_fake_header.search(c['source']) is None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cells = [{'cell_type': 'markdown',\n",
    "          'metadata': {},\n",
    "          'source': '### Fake-'}] + tst_nb['cells'][:10]\n",
    "cells1 = remove_fake_headers(cells)\n",
    "assert len(cells1) == len(cells)-1\n",
    "assert cells1[0] == cells[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def remove_empty(cells):\n",
    "    \"Remove in `cells` the empty cells\"\n",
    "    return [c for c in cells if len(c['source']) >0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grabbing metada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "_re_title_summary = re.compile('^\\s*#\\s+([^\\n]*)\\n+>\\s*([^\\n]*)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#hide\n",
    "\n",
    "Catches the title and summary of the notebook, presented as # Title > summary, with title in group 1 and summary in group 2\n",
    "```\n",
    "^\\s*       Beginning of text followe by any number of whitespace\n",
    "#\\s+       # followed by one or more of whitespace\n",
    "([^\\n]*)   Catching group for any character except a new line\n",
    "\\n+        One or more new lines\n",
    ">\\s*       > followed by any number of whitespace\n",
    "([^\\n]*)   Catching group for any character except a new line\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def get_metadata(cells):\n",
    "    \"Find the cell with title and summary in `cells`.\"\n",
    "    pat = re.compile('^\\s*#\\s*([^\\n]*)\\n*>\\s*([^\\n]*)')\n",
    "    for i,cell in enumerate(cells):\n",
    "        if cell['cell_type'] == 'markdown':\n",
    "            match = re.match(pat, cell['source'])\n",
    "            if match: \n",
    "                cells.pop(i)\n",
    "                return {'keywords': 'fastai',\n",
    "                        'summary' : match.groups()[1],\n",
    "                        'title'   : match.groups()[0]}\n",
    "    return {'keywords': 'fastai',\n",
    "            'summary' : 'summary',\n",
    "            'title'   : 'Title'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst_nb = read_nb('91_notebook_export.ipynb')\n",
    "assert get_metadata(tst_nb['cells']) == {\n",
    "    'keywords': 'fastai',\n",
    "    'summary': 'The functions that transform the dev notebooks in the fastai library',\n",
    "    'title': 'Converting notebooks to modules'}\n",
    "#The cell with the metada is poped out, so if we do it a second time we get the default.\n",
    "assert get_metadata(tst_nb['cells']) == {'keywords': 'fastai',\n",
    "            'summary' : 'summary',\n",
    "            'title'   : 'Title'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Executing show_doc cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "_re_cell_to_execute = re.compile(r\"^\\s*show_doc\\(([^\\)]*)\\)|^\\s*#\\s*exports?\\s*\", re.MULTILINE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#hide\n",
    "\n",
    "Catches any cell with a show_doc or an export/exports hashtag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class ExecuteShowDocPreprocessor(ExecutePreprocessor):\n",
    "    \"An `ExecutePreprocessor` that only executes `show_doc` and `import` cells\"\n",
    "    def preprocess_cell(self, cell, resources, index):\n",
    "        if 'source' in cell and cell['cell_type'] == \"code\":\n",
    "            if _re_cell_to_execute.search(cell['source']):\n",
    "                return super().preprocess_cell(cell, resources, index)\n",
    "        return cell, resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def _import_show_doc_cell(name=None):\n",
    "    \"Add an import show_doc cell + deal with the _file_ hack if necessary.\"\n",
    "    source = f\"#export\\nfrom local.notebook.showdoc import show_doc\"\n",
    "    if name: source += f\"\\nfrom pathlib import Path\\n_file_ = {name}\"\n",
    "    return {'cell_type': 'code',\n",
    "            'execution_count': None,\n",
    "            'metadata': {'hide_input': True},\n",
    "            'outputs': [],\n",
    "            'source': source}\n",
    "\n",
    "def execute_nb(nb, metadata=None, show_doc_only=True, name=None):\n",
    "    \"Execute `nb` (or only the `show_doc` cells) with `metadata`\"\n",
    "    nb['cells'].insert(0, _import_show_doc_cell(name))\n",
    "    ep_cls = ExecuteShowDocPreprocessor if show_doc_only else ExecutePreprocessor\n",
    "    ep = ep_cls(timeout=600, kernel_name='python3')\n",
    "    metadata = metadata or {}\n",
    "    pnb = nbformat.from_dict(nb)\n",
    "    ep.preprocess(pnb, metadata)\n",
    "    return pnb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_nb = {k:v for k,v in tst_nb.items() if k != 'cells'}\n",
    "fake_nb['cells'] = [tst_nb['cells'][0].copy()] + added_cells\n",
    "fake_nb = execute_nb(fake_nb)\n",
    "assert len(fake_nb['cells'][-1]['outputs']) > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#Tricking jupyter notebook to have a __file__ attribute. All _file_ will be replaced by __file__\n",
    "_file_ = Path('local').absolute()/'notebook'/'export.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def _exporter():\n",
    "    exporter = HTMLExporter(Config())\n",
    "    exporter.exclude_input_prompt=True\n",
    "    exporter.exclude_output_prompt=True\n",
    "    exporter.template_file = 'jekyll.tpl'\n",
    "    exporter.template_path.append(str(Path(_file_).parent))\n",
    "    return exporter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "process_cells = [remove_fake_headers, remove_hidden, remove_empty]\n",
    "process_cell  = [hide_cells, remove_widget_state, treat_backticks, add_jekyll_notes, convert_links]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "_re_file = re.compile(r'^_file_\\s*=\\s*(\\S*)\\s*$', re.MULTILINE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#hide\n",
    "\n",
    "Catches a cell with \\_file\\_ = something and put that something in group 1\n",
    "```\n",
    "^_file_   _file_ at the beginning of a line (since re.MULTILINE is passed)\n",
    "\\s*=\\s*   Any number of whitespace, =, any number of whitespace\n",
    "(\\S*)     Catching group for any non-whitespace characters\n",
    "\\s*$      Any number of whitespace then the end of line\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def _find_file(cells):\n",
    "    \"Find in `cells` if a _file_ is defined.\"\n",
    "    for cell in cells:\n",
    "        if cell['cell_type']=='code' and _re_file.search(cell['source']): \n",
    "            return _re_file.search(cell['source']).groups()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "tst_nb = read_nb('91_notebook_export.ipynb')\n",
    "assert _find_file(tst_nb['cells']) == \"Path('local').absolute()/'notebook'/'export.py'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def convert_nb(fname, dest_path='docs'):\n",
    "    \"Convert a notebook `fname` to html file in `dest_path`.\"\n",
    "    fname = Path(fname).absolute()\n",
    "    nb = read_nb(fname)\n",
    "    cls_lvl = find_default_level(nb['cells'])\n",
    "    _name = _find_file(nb['cells'])\n",
    "    nb['cells'] = compose(*process_cells,partial(add_show_docs, cls_lvl=cls_lvl))(nb['cells'])\n",
    "    nb['cells'] = [compose(partial(copy_images, fname=fname, dest=dest_path), *process_cell)(c) \n",
    "                    for c in nb['cells']]\n",
    "    fname = Path(fname).absolute()\n",
    "    dest_name = '.'.join(fname.with_suffix('.html').name.split('_')[1:])\n",
    "    meta_jekyll = get_metadata(nb['cells'])\n",
    "    meta_jekyll['nb_path'] = f'{fname.parent.name}/{fname.name}'\n",
    "    nb = execute_nb(nb, name=_name)\n",
    "    nb['cells'] = [clean_exports(c) for c in nb['cells']]\n",
    "    with open(f'{dest_path}/{dest_name}','w') as f:\n",
    "        f.write(_exporter().from_notebook_node(nb, resources=meta_jekyll)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def convert_all(path='.', dest_path='docs', force_all=False):\n",
    "    \"Convert all notebooks in `path` to html files in `dest_path`.\"\n",
    "    path = Path(path)\n",
    "    changed_cnt = 0\n",
    "    for fname in path.glob(\"*.ipynb\"):\n",
    "        # only rebuild modified files\n",
    "        if fname.name.startswith('_'): continue\n",
    "        fname_out = Path(dest_path)/'.'.join(fname.with_suffix('.html').name.split('_')[1:])\n",
    "        if not force_all and fname_out.exists() and os.path.getmtime(fname) < os.path.getmtime(fname_out): \n",
    "            continue\n",
    "        print(f\"converting: {fname} => {fname_out}\")\n",
    "        changed_cnt += 1\n",
    "        try: convert_nb(fname, dest_path=dest_path)\n",
    "        except: print(\"Failed\")\n",
    "    if changed_cnt==0: print(\"No notebooks were modified\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting: 04_data_core.ipynb => docs/data.core.html\n",
      "converting: 95_synth_learner.ipynb => docs/synth.learner.html\n",
      "converting: 01_core.ipynb => docs/core.html\n",
      "converting: 15_callback_progress.ipynb => docs/callback.progress.html\n",
      "converting: 08_augmentation.ipynb => docs/augmentation.html\n",
      "converting: 17_callback_fp16.ipynb => docs/callback.fp16.html\n",
      "converting: 13_callback_schedule.ipynb => docs/callback.schedule.html\n",
      "Failed\n",
      "converting: 91_notebook_export.ipynb => docs/notebook.export.html\n",
      "converting: 92_notebook_showdoc.ipynb => docs/notebook.showdoc.html\n",
      "converting: 12_learner.ipynb => docs/learner.html\n",
      "converting: 11_optimizer.ipynb => docs/optimizer.html\n",
      "converting: 05_data_source.ipynb => docs/data.source.html\n",
      "converting: 10_layers.ipynb => docs/layers.html\n",
      "converting: 16_callback_tracker.ipynb => docs/callback.tracker.html\n",
      "converting: 06_vision_core.ipynb => docs/vision.core.html\n",
      "converting: 02_data_pipeline.ipynb => docs/data.pipeline.html\n",
      "converting: 00_test.ipynb => docs/test.html\n",
      "converting: 07_pets_tutorial.ipynb => docs/pets.tutorial.html\n",
      "converting: 14_callback_hook.ipynb => docs/callback.hook.html\n",
      "converting: 93_notebook_export2html.ipynb => docs/notebook.export2html.html\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "convert_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_nb('13_callback_schedule.ipynb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_test.ipynb.\n",
      "Converted 01_core.ipynb.\n",
      "Converted 02_data_pipeline.ipynb.\n",
      "Converted 03_data_external.ipynb.\n",
      "Converted 04_data_core.ipynb.\n",
      "Converted 05_data_source.ipynb.\n",
      "Converted 06_vision_core.ipynb.\n",
      "Converted 07_pets_tutorial.ipynb.\n",
      "Converted 08_augmentation.ipynb.\n",
      "Converted 10_layers.ipynb.\n",
      "Converted 11_optimizer.ipynb.\n",
      "Converted 12_learner.ipynb.\n",
      "Converted 90_notebook_core.ipynb.\n",
      "Converted 91_notebook_export.ipynb.\n",
      "Converted 92_notebook_showdoc.ipynb.\n",
      "Converted 93_notebook_export2html.ipynb.\n",
      "Converted 94_index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "notebook2script(all_fs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "def debug_nb(fname, dest=None):\n",
    "    fname = Path(fname).absolute()\n",
    "    nb = read_nb(fname)\n",
    "    cls_lvl = find_default_level(nb['cells'])\n",
    "    _name = _find_file(nb['cells'])\n",
    "    nb['cells'] = compose(*process_cells, partial(add_show_docs, cls_lvl=cls_lvl))(nb['cells'])\n",
    "    nb['cells'] = [compose(*process_cell)(c) for c in nb['cells']]\n",
    "    fname = Path(fname).absolute()\n",
    "    nb = execute_nb(nb, name=_name)\n",
    "    dest = dest or fname.with_suffix('.dbg.ipynb')\n",
    "    nbformat.write(nbformat.from_dict(nb), open(dest, 'w'), version=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "debug_nb('93_notebook_export2html.ipynb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "if not 1==2: print(\"True\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
