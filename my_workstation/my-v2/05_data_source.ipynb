{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp data.source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from local.imports import *\n",
    "from local.test import *\n",
    "from local.core import *\n",
    "from local.data.core import *\n",
    "from local.data.pipeline import *\n",
    "from local.notebook.showdoc import show_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "torch.cuda.set_device(int(os.environ.get('DEFAULT_GPU') or 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data source\n",
    "> Base container for all the items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convenience functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export core\n",
    "def all_union(sets):\n",
    "    \"Set of union of all `sets` (each `setified` if needed)\"\n",
    "    return set().union(*(map(setify,sets)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sets = [[1,2],[2,3]]\n",
    "test_eq(all_union(sets), {1,2,3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export core\n",
    "def all_disjoint(sets):\n",
    "    \"`True` iif no element appears in more than one item of `sets`\"\n",
    "    return sum(map(len,sets))==len(all_union(sets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert not all_disjoint(sets)\n",
    "assert all_disjoint([[1,2],[3,4]])\n",
    "assert all_disjoint([[1,2],[]])\n",
    "assert all_disjoint([[1,2]])\n",
    "assert all_disjoint([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataSource -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class _FiltTfmdList(TfmdList):\n",
    "    \"Like `TfmdList` but with filters and train/valid attribute, for proper setup\"\n",
    "    def __init__(self, items, tfms, filts, filt_idx, do_setup=True):\n",
    "        self.filts,self.filt_idx = filts,filt_idx\n",
    "        super().__init__(items, tfms, do_setup=do_setup)\n",
    "\n",
    "    def __getitem__(self, i, filt=None): #Has to accept filt because of DataSource.__getitem__ and super behavior\n",
    "        return super().__getitem__(i,self.filt_idx[i] if filt is None else filt)\n",
    "    \n",
    "    @property\n",
    "    def n_subsets(self): return len(self.filts)\n",
    "    def len(self,filt): return len(self.filts[filt])\n",
    "    def subset(self, i): return DsrcSubset(self, i)\n",
    "    def subsets(self): return map(self.subset, range(self.n_subsets))\n",
    "    \n",
    "_FiltTfmdList.train,_FiltTfmdList.valid = add_props(lambda i,x: x.subset(i), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@docs\n",
    "class DataSource(TfmdDS):\n",
    "    \"Applies a `tfm` to filtered subsets of `items`\"\n",
    "    def __init__(self, items, tfms=None, tuple_tfms=None, filts=None, do_setup=True):\n",
    "        if filts is None: filts = [range_of(items)]\n",
    "        self.filts = L(mask2idxs(filt) for filt in filts)\n",
    "        # Create map from item id to filter id\n",
    "        assert all_disjoint(self.filts)\n",
    "        self.filt_idx = L([None]*len(items))\n",
    "        for i,f in enumerate(self.filts): self.filt_idx[f] = i\n",
    "        if tfms is None: tfms = [None]\n",
    "        self.items = items\n",
    "        self.tfmd_its = [_FiltTfmdList(items, t, self.filts, self.filt_idx, do_setup=do_setup) for t in tfms]\n",
    "        self.tfms = [it.tfms for it in self.tfmd_its]\n",
    "        self.tuple_tfms = Pipeline(tuple_tfms, t=[it.tfms.final_t for it in self.tfmd_its])\n",
    "        if do_setup: self.setup()\n",
    "\n",
    "    @property\n",
    "    def n_subsets(self): return len(self.filts)\n",
    "    def len(self,filt): return len(self.filts[filt])\n",
    "    def subset(self, i): return DsrcSubset(self, i)\n",
    "    def subsets(self): return map(self.subset, range(self.n_subsets))\n",
    "    def __repr__(self): return '\\n'.join(map(str,self.subsets())) + f'\\ntfm - {self.tfms}'\n",
    "    def __getitem__(self, i): return super().__getitem__(i,self.filt_idx[i])\n",
    "        \n",
    "    _docs = dict(len=\"`len` of subset `filt`\",\n",
    "                 __getitem__=\"Transformed item(s) at `i`, using the appropriate filter\",\n",
    "                 setup=\"Transform setup\",\n",
    "                 subset=\"Filtered `DsrcSubset` `i`\",\n",
    "                 subsets=\"Iterator for all subsets\")\n",
    "\n",
    "DataSource.train,DataSource.valid = add_props(lambda i,x: x.subset(i), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `DataSource` provides filtering and transformation capabilities to a list of items. Although it has all the attributes of `PipedList` (since it's a subclass) they are mainly used internally; you will generally want to instead access its `subset`s.\n",
    "\n",
    "If you don't pass any filters or transforms, it simply provides a single subset (of type `DsrcSubset`) with the same behavior as a `L`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = [0,1,2,3,4]\n",
    "dsrc = DataSource(inp)\n",
    "\n",
    "test_eq(dsrc,inp)            # No filters, so equal to input items\n",
    "test_eq(dsrc.n_subsets, 1)\n",
    "test_ne(dsrc, [0,1,2,3,5])\n",
    "test_eq(dsrc[2], 2)          # Retrieve one item (subset 0 is the default)\n",
    "test_eq(dsrc[1,2], [1,2])    # Retrieve two items by index\n",
    "mask = [True,False,False,True,False]\n",
    "test_eq(dsrc[mask], [0,3])   # Retrieve two items by mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@docs\n",
    "class DsrcSubset():\n",
    "    \"A filtered subset of a `DataSource`\"\n",
    "    def __init__(self, dsrc, filt): \n",
    "        self.dsrc,self.filt,self.filts = dsrc,filt,dsrc.filts[filt]\n",
    "        self.tfms,self.tuple_tfms = dsrc.tfms,getattr(dsrc, 'tuple_tfms', None)\n",
    "    def __getitem__(self,i):             return self.dsrc[self.filts[i]]\n",
    "    def decode(self, o, **kwargs):       return self.dsrc.decode(o, filt=self.filt, **kwargs)\n",
    "    def decode_batch(self, b, **kwargs): return self.dsrc.decode_batch(b, filt=self.filt, **kwargs)\n",
    "    def decode_at(self, i, **kwargs):    return self.decode(self[i], **kwargs)\n",
    "    def show     (self, o, **kwargs):    return self.dsrc.show(o, filt=self.filt, **kwargs)\n",
    "    def show_at  (self, i, **kwargs):    return self.dsrc.show(self[i], filt=self.filt, **kwargs)\n",
    "    def __len__(self):  return len(self.filts)\n",
    "    def __eq__(self,b): return all_equal(b,self)\n",
    "    def __repr__(self): return coll_repr(self)\n",
    "    \n",
    "    _docs = dict(decode=\"Transform decode\",\n",
    "                 show=\"Transform show\",\n",
    "                 decode_batch=\"Transform decode batch\",\n",
    "                 __getitem__=\"Encoded item(s) at `i`\",\n",
    "                 decode_at=\"Decoded item at `i`\",\n",
    "                 show_at=\"Show decoded item at `i`\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Passing `filts` to the `DataSource` constructor allows you to create multiple subsets, each of type `DsrcSubset`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsrc.items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#2) [0,2]\n",
       "(#3) [1,3,4]\n",
       "tfm - [Pipeline over []]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filts can be indices\n",
    "dsrc = DataSource(range(5), filts=[tensor([0,2]), [1,3,4]])\n",
    "\n",
    "test_eq(dsrc.n_subsets, 2)\n",
    "test_eq(dsrc.subset(0), [0,2])\n",
    "test_eq(dsrc.train, [0,2])       # Subset 0 is aliased to `train`\n",
    "test_eq(dsrc.subset(1), [1,3,4])\n",
    "test_eq(dsrc.valid, [1,3,4])     # Subset 1 is aliased to `valid`\n",
    "test_eq(dsrc.valid[2], 4)\n",
    "assert '[1,3,4]' in str(dsrc) and '[0,2]' in str(dsrc)\n",
    "dsrc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filts can be boolean masks (they don't have to cover all items, but must be disjoint)\n",
    "filts = [[False,True,True,False,True], [True,False,False,False,False]]\n",
    "dsrc = DataSource(range(5), filts=filts)\n",
    "\n",
    "test_eq(dsrc.train, [1,2,4])\n",
    "test_eq(dsrc.valid, [0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pass `tfms` to have transformations applied before returning items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply transforms to all items\n",
    "tfm = [[lambda x: x*2,lambda x: x+1]]\n",
    "filts = [[1,2],[0,3,4]]\n",
    "dsrc = DataSource(range(5), tfm, filts=filts)\n",
    "test_eq(dsrc.train,[3,5])\n",
    "test_eq(dsrc.valid,[1,7,9])\n",
    "test_eq(dsrc.train[False,True], [5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The subset index is also passed to your transform, so if it is an instance of `Transform` it will only be applied if the filt idx matches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only transform subset 1\n",
    "class _Tfm(Transform):\n",
    "    filt=1\n",
    "    def encodes(self, x)->String: return x*2\n",
    "    def decodes(self, x): return x//2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#2) [1,2]\n",
       "(#3) [0,6,8]\n",
       "tfm - [Pipeline over [<__main__._Tfm object at 0x7f98cea4fb00>]]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsrc = DataSource(range(5), [_Tfm()], filts=[[1,2],[0,3,4]])\n",
    "test_eq(dsrc.train,[1,2])\n",
    "test_eq(dsrc.valid,[0,6,8])\n",
    "test_eq(dsrc.train[False,True], [2])\n",
    "test_eq(dsrc[1,3], [1,6]) #Items are grabbed properly even if they correspond to different filters\n",
    "dsrc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#Test setup works with train attribute\n",
    "class _Cat(Transform):\n",
    "    order,state_args = 1,'vocab'\n",
    "    def __init__(self, subset_idx=None): self.subset_idx = subset_idx\n",
    "    def encodes(self, o): return self.o2i[o]\n",
    "    def decodes(self, o): return self.vocab[o]\n",
    "    def setup(self, items): \n",
    "        items = items.train\n",
    "        self.vocab,self.o2i = uniqueify(items, sort=True, bidir=True)\n",
    "\n",
    "def _lbl(o) -> String: return o.split('_')[0]\n",
    "\n",
    "test_fns = ['dog_0.jpg','cat_0.jpg','cat_2.jpg','cat_1.jpg','dog_1.jpg']\n",
    "tcat = _Cat()\n",
    "dsrc = DataSource(test_fns, [[tcat,_lbl]], filts=[[1,2,4], [0,3]])\n",
    "test_eq(tcat.vocab, ['cat','dog'])\n",
    "test_eq(dsrc.train, [0,0,1])\n",
    "test_eq(dsrc.valid, [1,0])\n",
    "test_stdout(lambda: dsrc.train.show_at(0), \"cat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cat', 'dog']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsrc.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#Test DataSource pickles\n",
    "dsrc1 = pickle.loads(pickle.dumps(dsrc))\n",
    "test_eq(dsrc.train, dsrc1.train)\n",
    "test_eq(dsrc.valid, dsrc1.valid)\n",
    "test_eq(dsrc1.vocab, ['cat','dog'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsrc = DataSource(range(5), [_Tfm(),mk_string], filts=[[1,2],[0,3,4]])\n",
    "test_eq(dsrc.train,[[1,1],[2,2]])\n",
    "test_eq(dsrc.valid,[[0,0],[6,3],[8,4]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `DataSource` Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You won't need to use many methods of `DataSource`, since normally you'll be accessing subsets, and therefore will be using `DsrcSubset` methods. However there are a few `DataSource` methods that may be useful:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"<code>DataSource.len</code>\" class=\"doc_header\"><code>DataSource.len</code><a href=\"https://nbviewer.jupyter.org/github/fastai/fastai_docs/blob/master/dev/05_data_source.ipynb#DataSource--\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>DataSource.len</code>(**`filt`**)\n",
       "\n",
       "`len` of subset `filt`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(DataSource.len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 3]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[dsrc.len(i) for i in range(2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"<code>DataSource.subset</code>\" class=\"doc_header\"><code>DataSource.subset</code><a href=\"https://nbviewer.jupyter.org/github/fastai/fastai_docs/blob/master/dev/05_data_source.ipynb#DataSource--\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>DataSource.subset</code>(**`i`**)\n",
       "\n",
       "Filtered [`DsrcSubset`](/data.source.html#DsrcSubset) `i`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(DataSource.subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subset 0 is aliased to the `train` property, and subset 1 is aliased to the `valid` property."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#3) [(0, 0),(6, 3),(8, 4)]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsrc.subset(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"<code>DataSource.subsets</code>\" class=\"doc_header\"><code>DataSource.subsets</code><a href=\"https://nbviewer.jupyter.org/github/fastai/fastai_docs/blob/master/dev/05_data_source.ipynb#DataSource--\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>DataSource.subsets</code>()\n",
       "\n",
       "Iterator for all subsets"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(DataSource.subsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subset 0: (#2) [(1, 1),(2, 2)]\n",
      "Subset 1: (#3) [(0, 0),(6, 3),(8, 4)]\n"
     ]
    }
   ],
   "source": [
    "for i,s in enumerate(dsrc.subsets()): print(f\"Subset {i}: {s}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `DsrcSubset` Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"<code>DsrcSubset.__getitem__</code>\" class=\"doc_header\"><code>DsrcSubset.__getitem__</code><a href=\"https://nbviewer.jupyter.org/github/fastai/fastai_docs/blob/master/dev/05_data_source.ipynb#DataSource--\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>DsrcSubset.__getitem__</code>(**`i`**)\n",
       "\n",
       "Encoded item(s) at `i`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(DsrcSubset.__getitem__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(dsrc.valid[1], [6,3])\n",
    "test_eq(dsrc.train[1], [2,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"<code>DsrcSubset.show_at</code>\" class=\"doc_header\"><code>DsrcSubset.show_at</code><a href=\"https://nbviewer.jupyter.org/github/fastai/fastai_docs/blob/master/dev/05_data_source.ipynb#DataSource--\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>DsrcSubset.show_at</code>(**`i`**, **\\*\\*`kwargs`**)\n",
       "\n",
       "Show decoded item at `i`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(DsrcSubset.show_at)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_stdout(lambda:dsrc.valid.show_at(1), '6\\n3')\n",
    "test_stdout(lambda:dsrc.train.show_at(1), '2\\n2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"<code>DsrcSubset.decode_at</code>\" class=\"doc_header\"><code>DsrcSubset.decode_at</code><a href=\"https://nbviewer.jupyter.org/github/fastai/fastai_docs/blob/master/dev/05_data_source.ipynb#DataSource--\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>DsrcSubset.decode_at</code>(**`i`**, **\\*\\*`kwargs`**)\n",
       "\n",
       "Decoded item at `i`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(DsrcSubset.decode_at)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(dsrc.valid.decode_at(1), [3,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"<code>DsrcSubset.decode</code>\" class=\"doc_header\"><code>DsrcSubset.decode</code><a href=\"https://nbviewer.jupyter.org/github/fastai/fastai_docs/blob/master/dev/05_data_source.ipynb#DataSource--\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>DsrcSubset.decode</code>(**`o`**, **\\*\\*`kwargs`**)\n",
       "\n",
       "Transform decode"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(DsrcSubset.decode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = dsrc.valid[1]\n",
    "test_eq(dsrc.valid.decode(t), [3,3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_test.ipynb.\n",
      "Converted 01_core.ipynb.\n",
      "Converted 02_data_pipeline.ipynb.\n",
      "Converted 03_data_external.ipynb.\n",
      "Converted 04_data_core.ipynb.\n",
      "Converted 05_data_source.ipynb.\n",
      "Converted 06_vision_core.ipynb.\n",
      "Converted 07_pets_tutorial-meta.ipynb.\n",
      "Converted 07_pets_tutorial.ipynb.\n",
      "Converted 08_vision_augment.ipynb.\n",
      "Converted 10_layers.ipynb.\n",
      "Converted 11_optimizer.ipynb.\n",
      "Converted 12_learner.ipynb.\n",
      "Converted 13_callback_schedule.ipynb.\n",
      "Converted 14_callback_hook.ipynb.\n",
      "Converted 15_callback_progress.ipynb.\n",
      "Converted 16_callback_tracker.ipynb.\n",
      "Converted 17_callback_fp16.ipynb.\n",
      "Converted 90_notebook_core.ipynb.\n",
      "Converted 91_notebook_export.ipynb.\n",
      "Converted 92_notebook_showdoc.ipynb.\n",
      "Converted 93_notebook_export2html.ipynb.\n",
      "Converted 94_index.ipynb.\n",
      "Converted 95_synth_learner.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from local.notebook.export import notebook2script\n",
    "notebook2script(all_fs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
