{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "# export\n",
    "from local.imports import *\n",
    "from local.notebook.core import *\n",
    "import nbformat,inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp notebook.export\n",
    "# default_cls_lvl 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting notebooks to modules\n",
    "\n",
    "> The functions that transform the dev notebooks in the fastai library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading a notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What's a notebook?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A jupyter notebook is a json file behind the scenes. We can just read it with the json module, which will return a nested dictionary of dictionaries/lists of dictionaries, but there are some small differences between reading the json and using the tools from `nbformat` so we'll use this one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def read_nb(fname):\n",
    "    \"Read the notebook in `fname`.\"\n",
    "    with open(Path(fname),'r') as f: return nbformat.reads(f.read(), as_version=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`fname` can be a string or a pathlib object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_nb = read_nb('91_notebook_export.ipynb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The root has four keys: `cells` contains the cells of the notebook, `metadata` some stuff around the version of python used to execute the notebook, `nbformat` and `nbformat_minor` the version of nbformat. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['cells', 'metadata', 'nbformat', 'nbformat_minor'])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_nb.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'kernelspec': {'display_name': 'Python 3',\n",
       "  'language': 'python',\n",
       "  'name': 'python3'},\n",
       " 'language_info': {'codemirror_mode': {'name': 'ipython', 'version': 3},\n",
       "  'file_extension': '.py',\n",
       "  'mimetype': 'text/x-python',\n",
       "  'name': 'python',\n",
       "  'nbconvert_exporter': 'python',\n",
       "  'pygments_lexer': 'ipython3',\n",
       "  'version': '3.7.1'}}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_nb['metadata']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.2'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"{test_nb['nbformat']}.{test_nb['nbformat_minor']}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cells key then contains a list of cells. Each one is a new dictionary that contains entries like the type (code or markdown), the source (what is written in the cell) and the output (for code cells)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cell_type': 'code',\n",
       " 'execution_count': 1,\n",
       " 'metadata': {'hide_input': False},\n",
       " 'outputs': [],\n",
       " 'source': '# export\\nfrom local.imports import *\\nfrom local.notebook.core import *\\nimport nbformat,inspect'}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_nb['cells'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def check_re(cell, pat):\n",
    "    if cell['cell_type'] != 'code': return False\n",
    "    return re.search(pat, cell['source'], re.IGNORECASE | re.MULTILINE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell = test_nb['cells'][0].copy()\n",
    "assert check_re(cell, '# export') is not None\n",
    "assert check_re(cell, '# bla') is None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def is_export(cell, default):\n",
    "    \"Check if `cell` is to be exported and returns the name of the module.\"\n",
    "    if check_re(cell, r'^\\s*#\\s*exports?\\s*$'): \n",
    "        if default is None: \n",
    "            set_trace()\n",
    "            print(f\"This cell doesn't have an export destination and was ignored:\\n{cell['source'][1]}\")\n",
    "        return default\n",
    "    tst = check_re(cell, r'^\\s*#\\s*exports?\\s*(\\S+)\\s*$')\n",
    "    return os.path.sep.join(tst.groups()[0].split('.')) if tst else None "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cells to export are marked with an `#export` or `#exports` code, potentially with a module name where we want it exported. The default is given in a cell of the form `#default_exp bla` inside the notebook (usually at the top), though in this function, it needs the be passed (the final script will read the whole notebook to find it)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell = test_nb['cells'][0].copy()\n",
    "assert is_export(cell, 'export') == 'export'\n",
    "cell['source'] = \"# exports\" \n",
    "assert is_export(cell, 'export') == 'export'\n",
    "cell['source'] = \"# export mod\" \n",
    "assert is_export(cell, 'export') == 'mod'\n",
    "cell['source'] = \"# export mod.file\" \n",
    "assert is_export(cell, 'export') == 'mod/file'\n",
    "cell['source'] = \"# expt mod.file\"\n",
    "assert is_export(cell, 'export') is None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def find_default_export(cells):\n",
    "    \"Find in `cells` the default export module.\"\n",
    "    for cell in cells:\n",
    "        tst = check_re(cell, r'^\\s*#\\s*default_exp\\s*(\\S*)\\s*$')\n",
    "        if tst: return tst.groups()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stops at the first cell containing a `#default_exp` code and return the value behind. Returns `None` if there are no cell with that code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert find_default_export(test_nb['cells']) == 'notebook.export'\n",
    "assert find_default_export(test_nb['cells'][2:]) is None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exporting notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're now ready to export notebooks!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def _create_mod_file(fname, nb_path):\n",
    "    \"Create a module file for `fname`.\"\n",
    "    fname.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with open(fname, 'w') as f: \n",
    "        f.write(f\"#AUTOGENERATED! DO NOT EDIT! File to edit: dev/{nb_path.name} (unless otherwise specified).\")\n",
    "        f.write('\\n\\n__all__ = []')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def _not_private(n):\n",
    "    for t in n.split('.'):\n",
    "        if t.startswith('_'): return False\n",
    "    return True\n",
    "\n",
    "def export_names(code, func_only=False):\n",
    "    \"Find the names of the objects, functions or classes defined in `code` that are exported.\"\n",
    "    #Format monkey-patches with @patch\n",
    "    code = re.sub(r'@patch\\s*def\\s+([^\\(\\s]*)\\s*\\([^:]*:\\s*([^,\\)\\s]*)\\s*(?:,|\\))', r'\\2.\\1 = ', code)\n",
    "    names = re.findall(r'^(?:def|class)\\s+([^\\(\\s]*)\\s*(?:\\(|:)', code, re.MULTILINE)\n",
    "    if not func_only: names += re.findall(r'^([^\\(\\s]*)\\s*=', code, re.MULTILINE)\n",
    "    return [n for n in names if _not_private(n)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function only picks the zero-indented objects, functions or classes (we don't want the class methods for instance) and excludes private names (that begin with `_`). It only returns func and class names when `func_only=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert export_names(\"def my_func(x):\\n  pass\\nclass MyClass():\") == [\"my_func\", \"MyClass\"]\n",
    "#Indented funcs are ignored (funcs inside a class)\n",
    "assert export_names(\"  def my_func(x):\\n  pass\\nclass MyClass():\") == [\"MyClass\"]\n",
    "#Private funcs are ignored\n",
    "assert export_names(\"def _my_func():\\n  pass\\nclass MyClass():\") == [\"MyClass\"]\n",
    "#trailing spaces\n",
    "assert export_names(\"def my_func ():\\n  pass\\nclass MyClass():\") == [\"my_func\", \"MyClass\"]\n",
    "#class without parenthesis\n",
    "assert export_names(\"def my_func ():\\n  pass\\nclass MyClass:\") == [\"my_func\", \"MyClass\"]\n",
    "#object and funcs\n",
    "assert export_names(\"def my_func ():\\n  pass\\ndefault_bla = []:\") == [\"my_func\", \"default_bla\"]\n",
    "assert export_names(\"def my_func ():\\n  pass\\ndefault_bla = []:\", func_only=True) == [\"my_func\"]\n",
    "#Private objects are ignored\n",
    "assert export_names(\"def my_func ():\\n  pass\\n_default_bla = []:\") == [\"my_func\"]\n",
    "#Objects with dots are privates if one part is private\n",
    "assert export_names(\"def my_func ():\\n  pass\\ndefault.bla = []:\") == [\"my_func\", \"default.bla\"]\n",
    "assert export_names(\"def my_func ():\\n  pass\\ndefault._bla = []:\") == [\"my_func\"]\n",
    "#Monkey-path with @patch are properly renamed\n",
    "assert export_names(\"@patch\\ndef my_func(x:Class):\\n  pass\") == [\"Class.my_func\"]\n",
    "assert export_names(\"some code\\n@patch\\ndef my_func(x:Class, y):\\n  pass\") == [\"Class.my_func\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def extra_add(code):\n",
    "    \"Catch adds to `__all__` required by a cell with `_all_=`\"\n",
    "    pat = re.compile('^_all_\\s*=\\s*\\[([^\\]]*)\\]', re.MULTILINE)\n",
    "    if re.search(pat, code):\n",
    "        names = re.search(pat, code).groups()[0]\n",
    "        names = re.sub('\\s*,\\s*', ',', names)\n",
    "        names = names.replace('\"', \"'\")\n",
    "        code = re.sub(pat, '', code)\n",
    "        code = re.sub(r'([^\\n]|^)\\n*$', r'\\1', code)\n",
    "        return names.split(','),re.sub(pat, '', code)\n",
    "    return [],code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert extra_add('_all_ = [\"func\", \"func1\", \"func2\"]') == ([\"'func'\", \"'func1'\", \"'func2'\"],'')\n",
    "assert extra_add('_all_ = [\"func\",   \"func1\" , \"func2\"]') ==  ([\"'func'\", \"'func1'\", \"'func2'\"],'')\n",
    "assert extra_add(\"_all_ = ['func','func1', 'func2']\\n\") ==  ([\"'func'\", \"'func1'\", \"'func2'\"],'')\n",
    "assert extra_add('code\\n\\n_all_ = [\"func\", \"func1\", \"func2\"]') == ([\"'func'\", \"'func1'\", \"'func2'\"],'code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _add2add(fname, names, line_width=120):\n",
    "    if len(names) == 0: return\n",
    "    with open(fname, 'r') as f: text = f.read()\n",
    "    tw = TextWrapper(width=120, initial_indent='', subsequent_indent=' '*11, break_long_words=False)\n",
    "    re_all = re.search(r'__all__\\s*=\\s*\\[([^\\]]*)\\]', text)\n",
    "    start,end = re_all.start(),re_all.end()\n",
    "    text_all = tw.wrap(f\"{text[start:end-1]}{'' if text[end-2]=='[' else ', '}{', '.join(names)}]\")\n",
    "    with open(fname, 'w') as f: f.write(text[:start] + '\\n'.join(text_all) + text[end:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = 'test_add.txt'\n",
    "with open(fname, 'w') as f: f.write(\"Bla\\n__all__ = [my_file, MyClas]\\nBli\")\n",
    "_add2add(fname, ['new_function'])\n",
    "with open(fname, 'r') as f: \n",
    "    assert f.read() == \"Bla\\n__all__ = [my_file, MyClas, new_function]\\nBli\"\n",
    "_add2add(fname, [f'new_function{i}' for i in range(10)])\n",
    "with open(fname, 'r') as f: \n",
    "    assert f.read() == \"\"\"Bla\n",
    "__all__ = [my_file, MyClas, new_function, new_function0, new_function1, new_function2, new_function3, new_function4,\n",
    "           new_function5, new_function6, new_function7, new_function8, new_function9]\n",
    "Bli\"\"\"\n",
    "os.remove(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def _relative_import(name, fname):\n",
    "    mods = name.split('.')\n",
    "    splits = str(fname).split(os.path.sep)\n",
    "    if mods[0] not in splits: return name\n",
    "    splits = splits[splits.index(mods[0]):]\n",
    "    while splits[0] == mods[0]: splits,mods = splits[1:],mods[1:]\n",
    "    return '.' * (len(splits)) + '.'.join(mods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert _relative_import('local.core', Path('local')/'data.py') == '.core'\n",
    "assert _relative_import('local.core', Path('local')/'vision'/'data.py') == '..core'\n",
    "assert _relative_import('local.vision.transform', Path('local')/'vision'/'data.py') == '.transform'\n",
    "assert _relative_import('local.notebook.core', Path('local')/'data'/'external.py') == '..notebook.core'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def _deal_import(code_lines, fname):\n",
    "    pat = re.compile(r'from (local.\\S*) import (\\S*)$')\n",
    "    lines = []\n",
    "    for line in code_lines:\n",
    "        line = re.sub('_'+'file_', '__'+'file__', line) #Need to break _file_ or that line will be treated\n",
    "        match = re.match(pat, line)\n",
    "        if match: lines.append(f\"from {_relative_import(match.groups()[0], fname)} import {match.groups()[1]}\")\n",
    "        else: lines.append(line)\n",
    "    return lines                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#Tricking jupyter notebook to have a __file__ attribute. All _file_ will be replaced by __file__\n",
    "_file_ = Path('local').absolute()/'notebook'/'export.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _get_index():\n",
    "    if not (Path(_file_).parent/'index.txt').exists(): return {}\n",
    "    return json.load(open(Path(_file_).parent/'index.txt', 'r'))\n",
    "\n",
    "def _save_index(index): json.dump(index, open(Path(_file_).parent/'index.txt', 'w'), indent=2)\n",
    "def _reset_index():\n",
    "    if (Path(_file_).parent/'index.txt').exists():\n",
    "        os.remove(Path(_file_).parent/'index.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "ind,ind_bak = Path(_file_).parent/'index.txt',Path(_file_).parent/'index.bak'\n",
    "if ind.exists(): shutil.move(ind, ind_bak)\n",
    "assert _get_index() == {}\n",
    "_save_index({'foo':'bar'})\n",
    "assert _get_index() == {'foo':'bar'}\n",
    "if ind_bak.exists(): shutil.move(ind_bak, ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "def _notebook2script(fname):\n",
    "    \"Finds cells starting with `#export` and puts them into a new module\"\n",
    "    fname = Path(fname)\n",
    "    nb = read_nb(fname)\n",
    "    default = find_default_export(nb['cells'])\n",
    "    if default is not None: \n",
    "        default = os.path.sep.join(default.split('.'))\n",
    "        _create_mod_file(Path.cwd()/'local'/f'{default}.py', fname)\n",
    "    index = _get_index()\n",
    "    exports = [is_export(c, default) for c in nb['cells']]\n",
    "    cells = [(c,e) for (c,e) in zip(nb['cells'],exports) if e is not None]\n",
    "    for (c,e) in cells:\n",
    "        fname_out = Path.cwd()/'local'/f'{e}.py'\n",
    "        orig = '' if e==default else f'#Comes from {fname.name}.\\n'\n",
    "        code = '\\n\\n' + orig + '\\n'.join(_deal_import(c['source'].split('\\n')[1:], fname_out))\n",
    "        # remove trailing spaces\n",
    "        names = export_names(code)\n",
    "        extra,code = extra_add(code)\n",
    "        _add2add(fname_out, [f\"'{f}'\" for f in names if '.' not in f] + extra)\n",
    "        index.update({f: fname.name for f in names})\n",
    "        code = re.sub(r' +$', '', code, flags=re.MULTILINE)\n",
    "        with open(fname_out, 'a') as f: f.write(code)\n",
    "    _save_index(index)\n",
    "    print(f\"Converted {fname}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 92_notebook_showdoc.ipynb.\n"
     ]
    }
   ],
   "source": [
    "_notebook2script('92_notebook_showdoc.ipynb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "def _get_sorted_files(all_fs: Union[bool,str], up_to=None):\n",
    "    \"Return the list of files corresponding to `g` in the current dir.\"\n",
    "    if (all_fs==True): ret = glob.glob('*.ipynb') # Checks both that is bool type and that is True\n",
    "    else: ret = glob.glob(all_fs) if isinstance(g,str) else []\n",
    "    if len(ret)==0: print('WARNING: No files found')\n",
    "    ret = [f for f in ret if not f.startswith('_')]\n",
    "    if up_to is not None: ret = [f for f in ret if str(f)<=str(up_to)]\n",
    "    return sorted(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "def notebook2script(fname=None, all_fs=None, up_to=None):\n",
    "    \"Convert `fname` or all the notebook satisfying `all_fs`.\"\n",
    "    # initial checks\n",
    "    assert fname or all_fs\n",
    "    if all_fs: _reset_index()\n",
    "    if (all_fs is None) and (up_to is not None): all_fs=True # Enable allFiles if upTo is present\n",
    "    fnames = _get_sorted_files(all_fs, up_to=up_to) if all_fs else [fname]\n",
    "    [_notebook2script(f) for f in fnames]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finds cells starting with `#export` and puts them into the appropriate module.\n",
    "* `fname`: the filename of one notebook to convert\n",
    "* `all_fs`: `True` if you want to convert all notebook files in the folder or a glob expression\n",
    "* `up_to`: converts all notebooks respecting the previous arg up to a certain number\n",
    "\n",
    "Examples of use in console:\n",
    "```\n",
    "notebook2script                                 # Parse all files\n",
    "notebook2script --fname 00_export.ipynb         # Parse 00_export.ipynb\n",
    "notebook2script --all_fs=nb*                    # Parse all files starting with nb*\n",
    "notebook2script --up_to=10                      # Parse all files with (name<='10')\n",
    "notebook2script --all_fs=*_*.ipynb --up_to=10   # Parse all files with an '_' and (name<='10')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the way back to notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def get_name(obj):\n",
    "    \"Get the name of `obj`\"\n",
    "    if hasattr(obj, '__name__'):       return obj.__name__\n",
    "    elif getattr(obj, '_name', False): return obj._name\n",
    "    elif hasattr(obj,'__origin__'):    return str(obj.__origin__).split('.')[-1] #for types\n",
    "    else:                              return str(obj).split('.')[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from local.data.pipeline import *\n",
    "assert get_name(Pipeline) == 'Pipeline'\n",
    "assert get_name(Pipeline.composed) == 'composed'\n",
    "assert get_name(Union[Tensor, float]) == 'Union'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def qual_name(obj):\n",
    "    \"Get the qualified name of `obj`\"\n",
    "    if hasattr(obj,'__qualname__'): return obj.__qualname__\n",
    "    if inspect.ismethod(obj):       return f\"{get_name(obj.__self__)}.{get_name(fn)}\"\n",
    "    return get_name(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert qual_name(Pipeline) == 'Pipeline'\n",
    "assert qual_name(Pipeline.composed) == 'Pipeline.composed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def source_nb(func, is_name=None, return_all=False):\n",
    "    \"Return the name of the notebook where `func` was defined\"\n",
    "    is_name = is_name or isinstance(func, str)\n",
    "    index = _get_index()\n",
    "    name = func if is_name else qual_name(func)\n",
    "    while len(name) > 0:\n",
    "        if name in index: return (name,index[name]) if return_all else index[name]\n",
    "        name = '.'.join(name.split('.')[:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can either pass an object or its name (by default `is_name` will look if `func` is a string or not, but you can override if there is some inconsistent behavior). \n",
    "\n",
    "If passed a method of a class, the function will return the notebook in which the largest part of the function was defined in case there is a monkey-matching that defines `class.method` in a different notebook than `class`. If `return_all=True`, the function will return a tuple with the name by which the function was found and the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from local.data.pipeline import Transform\n",
    "from local.test import test_fail\n",
    "from local.core import opt_call\n",
    "\n",
    "assert source_nb(test_fail) == '00_test.ipynb'\n",
    "assert source_nb(Transform) == '02_data_pipeline.ipynb'\n",
    "assert source_nb(Transform.create) == '02_data_pipeline.ipynb'\n",
    "#opt_call is in the core module but defined in 02\n",
    "assert source_nb(opt_call) == '02_data_pipeline.ipynb'\n",
    "assert source_nb(Tensor) is None\n",
    "#Added through a monkey-patch\n",
    "assert source_nb('Path.ls') == '01_core.ipynb'\n",
    "\n",
    "#Test with name\n",
    "assert source_nb('Pipeline') == '02_data_pipeline.ipynb'\n",
    "assert source_nb('Pipeline.decode') == '02_data_pipeline.ipynb'\n",
    "\n",
    "#Test return_all\n",
    "assert source_nb(Pipeline, return_all=True) == ('Pipeline','02_data_pipeline.ipynb')\n",
    "assert source_nb(Pipeline.decode, return_all=True) == ('Pipeline','02_data_pipeline.ipynb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_test.ipynb.\n",
      "Converted 01_core.ipynb.\n",
      "Converted 02_data_pipeline.ipynb.\n",
      "Converted 03_data_external.ipynb.\n",
      "Converted 04_data_core.ipynb.\n",
      "Converted 05_data_source.ipynb.\n",
      "Converted 06_vision_core.ipynb.\n",
      "Converted 07_pets_tutorial.ipynb.\n",
      "Converted 08_augmentation.ipynb.\n",
      "Converted 10_layers.ipynb.\n",
      "Converted 11_optimizer.ipynb.\n",
      "Converted 12_learner.ipynb.\n",
      "Converted 90_notebook_core.ipynb.\n",
      "Converted 91_notebook_export.ipynb.\n",
      "Converted 92_notebook_showdoc.ipynb.\n",
      "Converted 93_notebook_export2html.ipynb.\n",
      "Converted 94_index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "notebook2script(all_fs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
